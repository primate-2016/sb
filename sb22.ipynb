{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe5d5a9-d03b-407c-94f8-cb4c68414614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting alpha_vantage\n",
      "  Downloading alpha_vantage-2.3.1-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from alpha_vantage) (2.27.1)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from alpha_vantage) (3.8.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from aiohttp->alpha_vantage) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from aiohttp->alpha_vantage) (4.0.2)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from aiohttp->alpha_vantage) (0.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from aiohttp->alpha_vantage) (4.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from aiohttp->alpha_vantage) (6.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from aiohttp->alpha_vantage) (21.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from aiohttp->alpha_vantage) (2.0.12)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from aiohttp->alpha_vantage) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from aiohttp->alpha_vantage) (1.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->alpha_vantage) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->alpha_vantage) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->alpha_vantage) (3.3)\n",
      "Installing collected packages: alpha_vantage\n",
      "Successfully installed alpha_vantage-2.3.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "!pip install alpha_vantage\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from alpha_vantage.techindicators import TechIndicators\n",
    "from alpha_vantage.sectorperformance import SectorPerformances\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import os\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da29c47-15fb-45a2-babb-c8cd1f51a690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (22.0.4)\n",
      "Collecting pip\n",
      "  Downloading pip-22.3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.0.4\n",
      "    Uninstalling pip-22.0.4:\n",
      "      Successfully uninstalled pip-22.0.4\n",
      "Successfully installed pip-22.3.1\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (60.10.0)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-65.6.3-py3-none-any.whl (1.2 MB)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (0.37.1)\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.38.4-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: wheel, setuptools\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.37.1\n",
      "    Uninstalling wheel-0.37.1:\n",
      "      Successfully uninstalled wheel-0.37.1\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 60.10.0\n",
      "    Uninstalling setuptools-60.10.0:\n",
      "      Successfully uninstalled setuptools-60.10.0\n",
      "Successfully installed setuptools-65.6.3 wheel-0.38.4\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Looking in links: https://download.pytorch.org/whl/cpu/torch_stable.html\n",
      "Collecting torch==1.12+cpu\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-1.12.0%2Bcpu-cp37-cp37m-linux_x86_64.whl (189.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.1/189.1 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.13.0+cpu\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.13.0%2Bcpu-cp37-cp37m-linux_x86_64.whl (13.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchtext==0.13.0\n",
      "  Downloading torchtext-0.13.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torch==1.12+cpu) (4.1.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torchvision==0.13.0+cpu) (2.27.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torchvision==0.13.0+cpu) (9.0.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torchvision==0.13.0+cpu) (1.21.5)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torchtext==0.13.0) (4.63.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->torchvision==0.13.0+cpu) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->torchvision==0.13.0+cpu) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->torchvision==0.13.0+cpu) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->torchvision==0.13.0+cpu) (3.3)\n",
      "Installing collected packages: torch, torchvision, torchtext\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.5.1\n",
      "    Uninstalling torch-1.5.1:\n",
      "      Successfully uninstalled torch-1.5.1\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.6.1\n",
      "    Uninstalling torchvision-0.6.1:\n",
      "      Successfully uninstalled torchvision-0.6.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torcheia 1.0.0 requires torch==1.5.1, but you have torch 1.12.0+cpu which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-1.12.0+cpu torchtext-0.13.0 torchvision-0.13.0+cpu\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting autogluon\n",
      "  Downloading autogluon-0.6.1-py3-none-any.whl (9.8 kB)\n",
      "Collecting autogluon.timeseries[all]==0.6.1\n",
      "  Downloading autogluon.timeseries-0.6.1-py3-none-any.whl (103 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting autogluon.text==0.6.1\n",
      "  Downloading autogluon.text-0.6.1-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autogluon.tabular[all]==0.6.1\n",
      "  Downloading autogluon.tabular-0.6.1-py3-none-any.whl (286 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.0/286.0 kB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autogluon.multimodal==0.6.1\n",
      "  Downloading autogluon.multimodal-0.6.1-py3-none-any.whl (289 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.7/289.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autogluon.features==0.6.1\n",
      "  Downloading autogluon.features-0.6.1-py3-none-any.whl (59 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autogluon.vision==0.6.1\n",
      "  Downloading autogluon.vision-0.6.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting autogluon.core[all]==0.6.1\n",
      "  Downloading autogluon.core-0.6.1-py3-none-any.whl (226 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.6/226.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.38.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (4.63.0)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (1.26.35)\n",
      "Requirement already satisfied: scipy<1.10.0,>=1.5.4 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (1.7.3)\n",
      "Collecting distributed<=2021.11.2,>=2021.09.1\n",
      "  Downloading distributed-2021.11.2-py3-none-any.whl (802 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.2/802.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn<1.2,>=1.0.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (1.0.2)\n",
      "Collecting autogluon.common==0.6.1\n",
      "  Downloading autogluon.common-0.6.1-py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.5/41.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dask<=2021.11.2,>=2021.09.1\n",
      "  Downloading dask-2021.11.2-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.24,>=1.21 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (1.21.5)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (2.27.1)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (3.5.1)\n",
      "Requirement already satisfied: pandas!=1.4.0,<1.6,>=1.2.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from autogluon.core[all]==0.6.1->autogluon) (1.3.5)\n",
      "Collecting hyperopt<0.2.8,>=0.2.7\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting ray[tune]<2.1,>=2.0\n",
      "  Downloading ray-2.0.1-cp37-cp37m-manylinux2014_x86_64.whl (60.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil<6,>=5.7.3 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from autogluon.features==0.6.1->autogluon) (5.9.0)\n",
      "Collecting omegaconf<2.2.0,>=2.1.1\n",
      "  Downloading omegaconf-2.1.2-py3-none-any.whl (74 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting openmim<=0.2.1,>0.1.5\n",
      "  Downloading openmim-0.2.1-py2.py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting text-unidecode<=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch<1.13,>=1.9 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (1.12.0+cpu)\n",
      "Collecting nptyping<1.5.0,>=1.4.4\n",
      "  Downloading nptyping-1.4.4-py3-none-any.whl (31 kB)\n",
      "Collecting torchmetrics<0.9.0,>=0.8.0\n",
      "  Downloading torchmetrics-0.8.2-py3-none-any.whl (409 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.8/409.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit-image<0.20.0,>=0.19.1\n",
      "  Downloading scikit_image-0.19.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (13.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchvision<0.14.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (0.13.0+cpu)\n",
      "Collecting nlpaug<=1.1.10,>=1.1.10\n",
      "  Downloading nlpaug-1.1.10-py3-none-any.whl (410 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.8/410.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting seqeval<=1.2.2\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting Pillow<=9.4.0,>=9.3.0\n",
      "  Downloading Pillow-9.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pytorch-metric-learning<1.4.0,>=1.3.0\n",
      "  Downloading pytorch_metric_learning-1.3.2-py3-none-any.whl (109 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.4/109.4 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting accelerate<0.14,>=0.9\n",
      "  Downloading accelerate-0.13.2-py3-none-any.whl (148 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.8/148.8 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytorch-lightning<1.8.0,>=1.7.4\n",
      "  Downloading pytorch_lightning-1.7.7-py3-none-any.whl (708 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m708.1/708.1 kB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting smart-open<5.3.0,>=5.2.1\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchtext<0.14.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (0.13.0)\n",
      "Requirement already satisfied: jsonschema<=4.8.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (3.2.0)\n",
      "Requirement already satisfied: defusedxml<=0.7.1,>=0.7.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from autogluon.multimodal==0.6.1->autogluon) (0.7.1)\n",
      "Collecting timm<0.7.0\n",
      "  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fairscale<=0.4.6,>=0.4.5\n",
      "  Downloading fairscale-0.4.6.tar.gz (248 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.2/248.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sentencepiece<0.2.0,>=0.1.95\n",
      "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting transformers<4.24.0,>=4.23.0\n",
      "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nltk<4.0.0,>=3.4.5\n",
      "  Downloading nltk-3.8-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting albumentations<=1.2.0,>=1.1.0\n",
      "  Downloading albumentations-1.2.0-py3-none-any.whl (113 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.5/113.5 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting evaluate<=0.3.0\n",
      "  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting networkx<3.0,>=2.3\n",
      "  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting lightgbm<3.4,>=3.3\n",
      "  Downloading lightgbm-3.3.3-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting catboost<1.2,>=1.0\n",
      "  Downloading catboost-1.1.1-cp37-none-manylinux1_x86_64.whl (76.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting fastai<2.8,>=2.3.1\n",
      "  Downloading fastai-2.7.10-py3-none-any.whl (240 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.9/240.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xgboost<1.8,>=1.6\n",
      "  Downloading xgboost-1.6.2-py3-none-manylinux2014_x86_64.whl (255.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.9/255.9 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting statsmodels~=0.13.0\n",
      "  Downloading statsmodels-0.13.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib~=1.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from autogluon.timeseries[all]==0.6.1->autogluon) (1.1.0)\n",
      "Collecting gluonts~=0.11.0\n",
      "  Downloading gluonts-0.11.6-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting psutil<6,>=5.7.3\n",
      "  Downloading psutil-5.8.0-cp37-cp37m-manylinux2010_x86_64.whl (296 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.3/296.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tbats~=1.1\n",
      "  Downloading tbats-1.1.2-py3-none-any.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pmdarima~=1.8.2\n",
      "  Downloading pmdarima-1.8.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sktime<0.14,>=0.13.1\n",
      "  Downloading sktime-0.13.4-py3-none-any.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting gluoncv<0.10.6,>=0.10.5\n",
      "  Downloading gluoncv-0.10.5.post0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from autogluon.common==0.6.1->autogluon.core[all]==0.6.1->autogluon) (65.6.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from accelerate<0.14,>=0.9->autogluon.multimodal==0.6.1->autogluon) (21.3)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from accelerate<0.14,>=0.9->autogluon.multimodal==0.6.1->autogluon) (5.4.1)\n",
      "Collecting opencv-python-headless>=4.1.1\n",
      "  Downloading opencv_python_headless-4.7.0.68-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting qudida>=0.0.4\n",
      "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Collecting albumentations<=1.2.0,>=1.1.0\n",
      "  Downloading albumentations-1.1.0-py3-none-any.whl (102 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.4/102.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.6.1->autogluon) (1.16.0)\n",
      "Requirement already satisfied: graphviz in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.6.1->autogluon) (0.13.2)\n",
      "Requirement already satisfied: plotly in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from catboost<1.2,>=1.0->autogluon.tabular[all]==0.6.1->autogluon) (5.6.0)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (2.0.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (0.11.2)\n",
      "Requirement already satisfied: partd>=0.3.10 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (2022.2.0)\n",
      "Requirement already satisfied: click>=6.6 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (8.0.4)\n",
      "Collecting tblib>=1.6.0\n",
      "  Downloading tblib-1.7.0-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: tornado>=5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (6.1)\n",
      "Collecting msgpack>=0.6.0\n",
      "  Downloading msgpack-1.0.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.8/299.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting zict>=0.1.3\n",
      "  Downloading zict-2.2.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (3.0.3)\n",
      "Collecting sortedcontainers!=2.0.0,!=2.0.1\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting datasets>=2.0.0\n",
      "  Downloading datasets-2.8.0-py3-none-any.whl (452 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.9/452.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.1/213.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: dill in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (0.3.4)\n",
      "Collecting huggingface-hub>=0.7.0\n",
      "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (0.70.12.2)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (4.11.3)\n",
      "Collecting fastcore<1.6,>=1.4.5\n",
      "  Downloading fastcore-1.5.27-py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pip in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==0.6.1->autogluon) (22.3.1)\n",
      "Collecting spacy<4\n",
      "  Downloading spacy-3.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting fastdownload<2,>=0.0.5\n",
      "  Downloading fastdownload-0.0.7-py3-none-any.whl (12 kB)\n",
      "Collecting fastprogress>=0.2.4\n",
      "  Downloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: opencv-python in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from gluoncv<0.10.6,>=0.10.5->autogluon.vision==0.6.1->autogluon) (4.5.1.48)\n",
      "Collecting yacs\n",
      "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting autocfg\n",
      "  Downloading autocfg-0.0.8-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic~=1.7\n",
      "  Downloading pydantic-1.10.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions~=4.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from gluonts~=0.11.0->autogluon.timeseries[all]==0.6.1->autogluon) (4.1.1)\n",
      "Requirement already satisfied: py4j in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.6.1->autogluon) (0.10.9.5)\n",
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==0.6.1->autogluon) (0.18.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from jsonschema<=4.8.0->autogluon.multimodal==0.6.1->autogluon) (21.4.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from jsonschema<=4.8.0->autogluon.multimodal==0.6.1->autogluon) (0.18.1)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from lightgbm<3.4,>=3.3->autogluon.tabular[all]==0.6.1->autogluon) (0.38.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==0.6.1->autogluon) (2022.3.15)\n",
      "Collecting typish>=1.7.0\n",
      "  Downloading typish-1.9.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting antlr4-python3-runtime==4.8\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting model-index\n",
      "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
      "Collecting rich\n",
      "  Downloading rich-13.0.0-py3-none-any.whl (238 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.1/238.1 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: colorama in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from openmim<=0.2.1,>0.1.5->autogluon.multimodal==0.6.1->autogluon) (0.4.3)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from pandas!=1.4.0,<1.6,>=1.2.5->autogluon.core[all]==0.6.1->autogluon) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from pandas!=1.4.0,<1.6,>=1.2.5->autogluon.core[all]==0.6.1->autogluon) (2.8.2)\n",
      "Collecting Cython!=0.29.18,>=0.29\n",
      "  Downloading Cython-0.29.32-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from pmdarima~=1.8.2->autogluon.timeseries[all]==0.6.1->autogluon) (1.26.8)\n",
      "Collecting pyDeprecate>=0.3.1\n",
      "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "Collecting tensorboard>=2.9.1\n",
      "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf<4.0.0,>=3.15.3 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from ray[tune]<2.1,>=2.0->autogluon.core[all]==0.6.1->autogluon) (3.19.4)\n",
      "Collecting grpcio<=1.43.0,>=1.32.0\n",
      "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting virtualenv\n",
      "  Downloading virtualenv-20.17.1-py3-none-any.whl (8.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from ray[tune]<2.1,>=2.0->autogluon.core[all]==0.6.1->autogluon) (3.6.0)\n",
      "Requirement already satisfied: frozenlist in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from ray[tune]<2.1,>=2.0->autogluon.core[all]==0.6.1->autogluon) (1.3.0)\n",
      "Requirement already satisfied: aiosignal in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from ray[tune]<2.1,>=2.0->autogluon.core[all]==0.6.1->autogluon) (1.2.0)\n",
      "Collecting tensorboardX>=1.9\n",
      "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->autogluon.core[all]==0.6.1->autogluon) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->autogluon.core[all]==0.6.1->autogluon) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->autogluon.core[all]==0.6.1->autogluon) (2021.10.8)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from scikit-image<0.20.0,>=0.19.1->autogluon.multimodal==0.6.1->autogluon) (2.16.1)\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2021.11.2-py3-none-any.whl (178 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from scikit-learn<1.2,>=1.0.0->autogluon.core[all]==0.6.1->autogluon) (3.1.0)\n",
      "Collecting deprecated>=1.2.13\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: numba>=0.53 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from sktime<0.14,>=0.13.1->autogluon.timeseries[all]==0.6.1->autogluon) (0.55.1)\n",
      "Collecting patsy>=0.5.2\n",
      "  Downloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.8/233.8 kB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers<4.24.0,>=4.23.0->autogluon.multimodal==0.6.1->autogluon) (0.11.6)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from boto3->autogluon.core[all]==0.6.1->autogluon) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from boto3->autogluon.core[all]==0.6.1->autogluon) (0.6.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.35 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from boto3->autogluon.core[all]==0.6.1->autogluon) (1.29.35)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from matplotlib->autogluon.core[all]==0.6.1->autogluon) (1.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from matplotlib->autogluon.core[all]==0.6.1->autogluon) (4.31.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from matplotlib->autogluon.core[all]==0.6.1->autogluon) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from matplotlib->autogluon.core[all]==0.6.1->autogluon) (3.0.7)\n",
      "Collecting pyarrow>=6.0.0\n",
      "  Downloading pyarrow-10.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.0/36.0 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from datasets>=2.0.0->evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (3.8.1)\n",
      "Collecting wrapt<2,>=1.10\n",
      "  Downloading wrapt-1.14.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (75 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.2/75.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from numba>=0.53->sktime<0.14,>=0.13.1->autogluon.timeseries[all]==0.6.1->autogluon) (0.38.0)\n",
      "Requirement already satisfied: locket in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from partd>=0.3.10->dask<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (0.2.1)\n",
      "Collecting typing-extensions~=4.0\n",
      "  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Downloading pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.6/126.6 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting spacy<4\n",
      "  Downloading spacy-3.4.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting typer<0.5.0,>=0.3.0\n",
      "  Downloading typer-0.4.2-py3-none-any.whl (27 kB)\n",
      "Collecting spacy<4\n",
      "  Downloading spacy-3.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydantic~=1.7\n",
      "  Downloading pydantic-1.9.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting spacy<4\n",
      "  Downloading spacy-3.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.3.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m102.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydantic~=1.7\n",
      "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting thinc<8.1.0,>=8.0.14\n",
      "  Downloading thinc-8.0.17-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.6/660.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting spacy<4\n",
      "  Downloading spacy-3.3.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m128.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.6/181.6 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (490 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m490.0/490.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.9\n",
      "  Downloading spacy_legacy-3.0.11-py2.py3-none-any.whl (24 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting spacy<4\n",
      "  Downloading spacy-3.2.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
      "Collecting spacy<4\n",
      "  Downloading spacy-3.2.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.2.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.2.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.2.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.2.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.1.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.1.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m125.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.1.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.1.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.1.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting typer<0.4.0,>=0.3.0\n",
      "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
      "Collecting spacy<4\n",
      "  Downloading spacy-3.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.0.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.0.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.0.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.0.6-cp37-cp37m-manylinux2014_x86_64.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydantic~=1.7\n",
      "  Downloading pydantic-1.7.4-cp37-cp37m-manylinux2014_x86_64.whl (9.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m106.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting spacy<4\n",
      "  Downloading spacy-3.0.5-cp37-cp37m-manylinux2014_x86_64.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.0.4-cp37-cp37m-manylinux2014_x86_64.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.0.3-cp37-cp37m-manylinux2014_x86_64.whl (12.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from importlib-metadata->evaluate<=0.3.0->autogluon.multimodal==0.6.1->autogluon) (3.7.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.15.0-py2.py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.0/177.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (2.0.3)\n",
      "Collecting heapdict\n",
      "  Downloading HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from jinja2->distributed<=2021.11.2,>=2021.09.1->autogluon.core[all]==0.6.1->autogluon) (2.1.1)\n",
      "Collecting ordered-set\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from plotly->catboost<1.2,>=1.0->autogluon.tabular[all]==0.6.1->autogluon) (8.0.1)\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m644.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from rich->openmim<=0.2.1,>0.1.5->autogluon.multimodal==0.6.1->autogluon) (2.11.2)\n",
      "Collecting distlib<1,>=0.3.6\n",
      "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting platformdirs<3,>=2.4\n",
      "  Downloading platformdirs-2.6.2-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->pytorch-lightning<1.8.0,>=1.7.4->autogluon.multimodal==0.6.1->autogluon) (4.7.2)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting thinc<8.1.0,>=8.0.0\n",
      "  Downloading thinc-8.0.16-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.6/660.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading thinc-8.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (653 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m653.3/653.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading thinc-8.0.14-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (652 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m652.9/652.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading thinc-8.0.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.2/628.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading thinc-8.0.12-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.2/628.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading thinc-8.0.11-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (627 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.0/628.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading thinc-8.0.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (623 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m623.7/623.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading thinc-8.0.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (623 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m623.7/623.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading thinc-8.0.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (621 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m621.1/621.1 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading thinc-8.0.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (619 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.0/620.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading thinc-8.0.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (618 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m618.6/618.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading thinc-8.0.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (618 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m618.6/618.6 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading thinc-8.0.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (618 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m618.6/618.6 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading thinc-8.0.3-cp37-cp37m-manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading thinc-8.0.2-cp37-cp37m-manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading thinc-8.0.1-cp37-cp37m-manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading thinc-8.0.0-cp37-cp37m-manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of tensorboard-plugin-wit to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.2/781.2 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of tensorboard-data-server to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.0-py3-none-manylinux2010_x86_64.whl (3.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of tenacity to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.1.0-py3-none-any.whl (23 kB)\n",
      "INFO: pip is looking at multiple versions of srsly to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting srsly<3.0.0,>=2.4.0\n",
      "  Downloading srsly-2.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (458 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m458.8/458.8 kB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of spacy-legacy to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.0\n",
      "  Downloading spacy_legacy-3.0.10-py2.py3-none-any.whl (21 kB)\n",
      "INFO: pip is looking at multiple versions of pygments to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pygments<3.0.0,>=2.6.0\n",
      "  Using cached Pygments-2.13.0-py3-none-any.whl (1.1 MB)\n",
      "INFO: pip is looking at multiple versions of pyarrow to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pyarrow>=6.0.0\n",
      "  Downloading pyarrow-10.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.4/35.4 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of preshed to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.7-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.6/126.6 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of platformdirs to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting platformdirs<3,>=2.4\n",
      "  Downloading platformdirs-2.6.1-py3-none-any.whl (14 kB)\n",
      "  Downloading platformdirs-2.6.0-py3-none-any.whl (14 kB)\n",
      "INFO: pip is looking at multiple versions of murmurhash to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.8-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "INFO: pip is looking at multiple versions of markupsafe to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-2.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "INFO: pip is looking at multiple versions of markdown to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of llvmlite to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llvmlite<0.39,>=0.38.0rc1\n",
      "  Downloading llvmlite-0.38.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of google-auth-oauthlib to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.5-py2.py3-none-any.whl (18 kB)\n",
      "INFO: pip is looking at multiple versions of google-auth to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.14.1-py2.py3-none-any.whl (175 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of distlib to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of cymem to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\n",
      "INFO: pip is looking at multiple versions of commonmark to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting commonmark<0.10.0,>=0.9.0\n",
      "  Downloading commonmark-0.9.0-py2.py3-none-any.whl (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of catalogue to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting catalogue<2.1.0,>=2.0.1\n",
      "  Downloading catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
      "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
      "  Downloading catalogue-2.0.5-py3-none-any.whl (17 kB)\n",
      "  Downloading catalogue-2.0.4-py3-none-any.whl (16 kB)\n",
      "  Downloading catalogue-2.0.3-py3-none-any.whl (16 kB)\n",
      "  Downloading catalogue-2.0.2-py3-none-any.whl (9.6 kB)\n",
      "  Downloading catalogue-2.0.1-py3-none-any.whl (9.6 kB)\n",
      "INFO: pip is looking at multiple versions of blis to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of absl-py to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of yacs to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting yacs\n",
      "  Downloading yacs-0.1.7-py3-none-any.whl (14 kB)\n",
      "INFO: pip is looking at multiple versions of xxhash to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of virtualenv to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting virtualenv\n",
      "  Downloading virtualenv-20.17.0-py3-none-any.whl (8.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of tabulate to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\n",
      "INFO: pip is looking at multiple versions of rich to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting rich\n",
      "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.5/237.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading rich-12.5.1-py3-none-any.whl (235 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.6/235.6 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-12.5.0-py3-none-any.whl (235 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.7/235.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading rich-12.4.4-py3-none-any.whl (232 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.0/232.0 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-12.4.3-py3-none-any.whl (231 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-12.4.2-py3-none-any.whl (231 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading rich-12.4.1-py3-none-any.whl (231 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.8/231.8 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of rich to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading rich-12.4.0-py3-none-any.whl (231 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.6/231.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading rich-12.3.0-py3-none-any.whl (232 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.1/232.1 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-12.2.0-py3-none-any.whl (229 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.8/229.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-12.0.1-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.2/224.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading rich-12.0.0-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.0/224.0 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading rich-11.2.0-py3-none-any.whl (217 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.3/217.3 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-11.1.0-py3-none-any.whl (216 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-11.0.0-py3-none-any.whl (215 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.8/215.8 kB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-10.16.2-py3-none-any.whl (214 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.4/214.4 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-10.16.1-py3-none-any.whl (214 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-10.16.0-py3-none-any.whl (214 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-10.15.2-py3-none-any.whl (214 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.2/214.2 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-10.15.1-py3-none-any.whl (214 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.2/214.2 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-10.15.0-py3-none-any.whl (214 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.2/214.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-10.14.0-py3-none-any.whl (213 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.8/213.8 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-10.13.0-py3-none-any.whl (213 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.4/213.4 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading rich-10.12.0-py3-none-any.whl (212 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.1/212.1 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-10.11.0-py3-none-any.whl (211 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.9/211.9 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-10.10.0-py3-none-any.whl (211 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.2/211.2 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-10.9.0-py3-none-any.whl (211 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.2/211.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading rich-10.8.0-py3-none-any.whl (210 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.8/210.8 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-10.7.0-py3-none-any.whl (209 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-10.6.0-py3-none-any.whl (208 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.6/208.6 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-10.5.0-py3-none-any.whl (207 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.7/207.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading rich-10.4.0-py3-none-any.whl (206 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.5/206.5 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-10.3.0-py3-none-any.whl (205 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.2/205.2 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-10.2.2-py3-none-any.whl (203 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.7/203.7 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-10.2.1-py3-none-any.whl (203 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.9/203.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading rich-10.2.0-py3-none-any.whl (203 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.6/203.6 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-10.1.0-py3-none-any.whl (201 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading rich-10.0.1-py3-none-any.whl (201 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-10.0.0-py3-none-any.whl (201 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.13.0-py3-none-any.whl (197 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.3/197.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.12.4-py3-none-any.whl (197 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.6/197.6 kB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.12.3-py3-none-any.whl (196 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.6/196.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.12.2-py3-none-any.whl (196 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.6/196.6 kB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.12.1-py3-none-any.whl (196 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.5/196.5 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.12.0-py3-none-any.whl (196 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.11.1-py3-none-any.whl (195 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.6/195.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.11.0-py3-none-any.whl (195 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.6/195.6 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.10.0-py3-none-any.whl (188 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.0/188.0 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.9.0-py3-none-any.whl (187 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.8/187.8 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.8.2-py3-none-any.whl (186 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.3/186.3 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.8.1-py3-none-any.whl (186 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.3/186.3 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.8.0-py3-none-any.whl (186 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.3/186.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.7.0-py3-none-any.whl (185 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.2/185.2 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.6.2-py3-none-any.whl (182 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.5/182.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.6.1-py3-none-any.whl (182 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.6.0-py3-none-any.whl (182 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.5.1-py3-none-any.whl (180 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.4/180.4 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.5.0-py3-none-any.whl (180 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.4/180.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.4.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.5/179.5 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.3.0-py3-none-any.whl (166 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.2.0-py3-none-any.whl (164 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.5/164.5 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.1.0-py3-none-any.whl (161 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.5/161.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.0.1-py3-none-any.whl (160 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-9.0.0-py3-none-any.whl (160 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.0/160.0 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-8.0.0-py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading rich-7.1.0-py3-none-any.whl (153 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.5/153.5 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-7.0.0-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-6.2.0-py3-none-any.whl (150 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.0/150.0 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-6.1.2-py3-none-any.whl (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-6.1.1-py3-none-any.whl (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.5/149.5 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-6.1.0-py3-none-any.whl (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.5/149.5 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-6.0.0-py3-none-any.whl (146 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.3/146.3 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-5.2.1-py3-none-any.whl (145 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.4/145.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-5.2.0-py3-none-any.whl (145 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.4/145.4 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-5.1.2-py3-none-any.whl (144 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.4/144.4 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-5.1.1-py3-none-any.whl (144 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.3/144.3 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-5.1.0-py3-none-any.whl (144 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.6/144.6 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-5.0.0-py3-none-any.whl (141 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.7/141.7 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-4.2.2-py3-none-any.whl (141 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.7/141.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading rich-4.2.1-py3-none-any.whl (142 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.0/142.0 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-4.2.0-py3-none-any.whl (141 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.7/141.7 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-4.1.0-py3-none-any.whl (141 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.4/141.4 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-4.0.0-py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.8/140.8 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-3.4.1-py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.5/140.5 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-3.4.0-py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.5/140.5 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-3.3.2-py3-none-any.whl (137 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.0/137.0 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-3.3.1-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.5/135.5 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-3.3.0-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.4/135.4 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-3.2.0-py3-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.1/134.1 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-3.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-3.0.5-py3-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-3.0.4-py3-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-3.0.3-py3-none-any.whl (131 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.7/131.7 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-3.0.2-py3-none-any.whl (131 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.3/131.3 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-3.0.1-py3-none-any.whl (130 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-3.0.0-py3-none-any.whl (130 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.3/130.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading rich-2.3.1-py3-none-any.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.6/129.6 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-2.3.0-py3-none-any.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.6/129.6 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-2.2.6-py3-none-any.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.2/129.2 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-2.2.5-py3-none-any.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-2.2.4-py3-none-any.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.0/129.0 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-2.2.3-py3-none-any.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.7/129.7 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-2.2.2-py3-none-any.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.7/129.7 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-2.2.1-py3-none-any.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.5/129.5 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-2.2.0-py3-none-any.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.5/129.5 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-2.1.0-py3-none-any.whl (128 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.8/128.8 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-2.0.1-py3-none-any.whl (128 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading rich-2.0.0-py3-none-any.whl (128 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-1.3.1-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-1.3.0-py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-1.2.3-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-1.2.2-py3-none-any.whl (122 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.1/122.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-1.2.1-py3-none-any.whl (122 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.1/122.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-1.2.0-py3-none-any.whl (122 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.1/122.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading rich-1.1.9-py3-none-any.whl (122 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/122.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-1.1.8-py3-none-any.whl (122 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/122.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-1.1.7-py3-none-any.whl (122 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.7/122.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading rich-1.1.6-py3-none-any.whl (122 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.3/122.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading rich-1.1.5-py3-none-any.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.9/120.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-1.1.4-py3-none-any.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.9/120.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-1.1.3-py3-none-any.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.6/120.6 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-1.1.2-py3-none-any.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.6/120.6 kB\u001b[0m \u001b[31m861.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading rich-1.1.1-py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-1.1.0-py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-1.0.3-py3-none-any.whl (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading rich-1.0.2-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-1.0.1-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-1.0.0-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.8.13-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.1/116.1 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.8.12-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.5/116.5 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.8.11-py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.8.10-py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.8.9-py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.4/118.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.8.8-py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.2/118.2 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.8.7-py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.2/118.2 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.8.6-py3-none-any.whl (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.6/117.6 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.8.5-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.5/116.5 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.8.4-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.8.3-py3-none-any.whl (111 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.8.2-py3-none-any.whl (111 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.4/111.4 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.8.1-py3-none-any.whl (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.1/112.1 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.8.0-py3-none-any.whl (110 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.9/110.9 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.7.2-py3-none-any.whl (105 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.7.1-py3-none-any.whl (105 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.7.0-py3-none-any.whl (105 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.6/105.6 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.6.0-py3-none-any.whl (95 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.9/95.9 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.5.0-py3-none-any.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.5/94.5 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.4.1-py3-none-any.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.5/94.5 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.4.0-py3-none-any.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.4/94.4 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.3.3-py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.3.2-py3-none-any.whl (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.3.1-py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.3.0-py3-none-any.whl (82 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.8/82.8 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.2.3-py3-none-any.whl (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.4/80.4 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.2.2-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.7/81.7 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.2.1-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.7/81.7 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Downloading rich-0.2.0-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of py4j to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting py4j\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of catalogue to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading py4j-0.10.9.6-py2.py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.5/199.5 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of portalocker to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n",
      "  Downloading portalocker-2.5.0-py2.py3-none-any.whl (15 kB)\n",
      "INFO: pip is looking at multiple versions of plotly to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.11.0-py2.py3-none-any.whl (15.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of platformdirs to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading plotly-5.10.0-py2.py3-none-any.whl (15.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.7.0.68-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess\n",
      "  Using cached multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
      "Collecting dill\n",
      "  Using cached dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "INFO: pip is looking at multiple versions of dill to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.13-py37-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of model-index to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting model-index\n",
      "  Downloading model_index-0.1.10-py3-none-any.whl (33 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading model_index-0.1.9-py3-none-any.whl (33 kB)\n",
      "INFO: pip is looking at multiple versions of jinja2 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting jinja2\n",
      "  Using cached Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "INFO: pip is looking at multiple versions of tensorboard-plugin-wit to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of tensorboard-data-server to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of tenacity to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of srsly to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of spacy-legacy to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of pygments to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of pyarrow to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of preshed to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of murmurhash to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of markupsafe to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of markdown to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of llvmlite to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of google-auth-oauthlib to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of google-auth to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of distlib to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of cymem to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of commonmark to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of blis to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of absl-py to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of yacs to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of xxhash to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of virtualenv to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of tabulate to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of py4j to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading Jinja2-3.1.1-py3-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of graphviz to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of portalocker to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading graphviz-0.20-py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of future to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.2/829.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of plotly to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading future-0.18.1.tar.gz (828 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m828.4/828.4 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of filelock to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
      "INFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading filelock-3.8.2-py3-none-any.whl (10 kB)\n",
      "INFO: pip is looking at multiple versions of colorama to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
      "INFO: pip is looking at multiple versions of autocfg to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting autocfg\n",
      "  Downloading autocfg-0.0.7-py3-none-any.whl (13 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of model-index to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading autocfg-0.0.6-py2.py3-none-any.whl (13 kB)\n",
      "INFO: pip is looking at multiple versions of frozenlist to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting frozenlist\n",
      "  Downloading frozenlist-1.3.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (148 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.0/148.0 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of jinja2 to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading frozenlist-1.3.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (148 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.0/148.0 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of aiosignal to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting aiosignal\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of graphviz to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "INFO: pip is looking at multiple versions of zict to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting zict>=0.1.3\n",
      "  Downloading zict-2.1.0-py3-none-any.whl (11 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of future to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading zict-2.0.0-py3-none-any.whl (10 kB)\n",
      "INFO: pip is looking at multiple versions of wheel to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting wheel\n",
      "  Using cached wheel-0.38.4-py3-none-any.whl (36 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of filelock to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading wheel-0.38.3-py3-none-any.whl (36 kB)\n",
      "INFO: pip is looking at multiple versions of urllib3 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting urllib3\n",
      "  Using cached urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of colorama to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.4/140.4 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of typish to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting typish>=1.7.0\n",
      "  Downloading typish-1.9.2-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of autocfg to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading typish-1.9.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of typing-extensions to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting typing-extensions~=4.0\n",
      "  Downloading typing_extensions-4.3.0-py3-none-any.whl (25 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of frozenlist to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of aiosignal to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of tornado to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tornado>=5\n",
      "  Using cached tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of zict to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m428.5/428.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of wheel to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of urllib3 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of toolz to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting toolz>=0.8.2\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of typish to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading toolz-0.11.2-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of typing-extensions to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of tokenizers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of tornado to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of tifffile to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2021.10.12-py3-none-any.whl (175 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.0/175.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of toolz to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading tifffile-2021.10.10-py3-none-any.whl (174 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.9/174.9 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of threadpoolctl to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "INFO: pip is looking at multiple versions of tokenizers to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of tensorboardx to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorboardX>=1.9\n",
      "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of tifffile to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of tensorboard to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorboard>=2.9.1\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of threadpoolctl to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of tblib to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tblib>=1.6.0\n",
      "  Downloading tblib-1.6.0-py2.py3-none-any.whl (12 kB)\n",
      "INFO: pip is looking at multiple versions of tensorboardx to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of pydantic to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pydantic~=1.7\n",
      "  Downloading pydantic-1.7.3-cp37-cp37m-manylinux2014_x86_64.whl (9.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of tensorboard to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading pydantic-1.7.2-cp37-cp37m-manylinux2014_x86_64.whl (9.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of tblib to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading pydantic-1.7.1-cp37-cp37m-manylinux2014_x86_64.whl (9.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "INFO: pip is looking at multiple versions of importlib-metadata to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting importlib-metadata\n",
      "  Using cached importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
      "INFO: pip is looking at multiple versions of pydantic to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading importlib_metadata-5.1.0-py3-none-any.whl (21 kB)\n",
      "  Downloading importlib_metadata-5.0.0-py3-none-any.whl (21 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))': /packages/d2/a2/8c239dc898138f208dd14b441b196e7b3032b94d3137d9d8453e186967fc/importlib_metadata-4.12.0-py3-none-any.whl\u001b[0m\u001b[33m\n",
      "\u001b[0m  Downloading importlib_metadata-4.12.0-py3-none-any.whl (21 kB)\n",
      "  Downloading importlib_metadata-4.11.4-py3-none-any.whl (18 kB)\n",
      "  Downloading importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
      "INFO: pip is looking at multiple versions of importlib-metadata to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading importlib_metadata-4.11.2-py3-none-any.whl (17 kB)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U pip\n",
    "!pip3 install -U setuptools wheel\n",
    "\n",
    "# CPU version of pytorch has smaller footprint - see installation instructions in\n",
    "# pytorch documentation - https://pytorch.org/get-started/locally/\n",
    "!pip3 install torch==1.12+cpu torchvision==0.13.0+cpu torchtext==0.13.0 -f https://download.pytorch.org/whl/cpu/torch_stable.html\n",
    "\n",
    "!pip3 install autogluon\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f8f29b-5943-4cfc-9f0b-963abcbc0cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca8eeca7-2e2d-4232-bf8c-61b0da4def55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API_KEY = os.getenv('API_KEY')\n",
    "API_KEY = '9M60VHUB93B1UIWI'\n",
    "symbol = 'BMW.FRK'\n",
    "pcent_change_to_buy_on = 1.5\n",
    "sleep_time = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5f3bf505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get sector overview for stock\n",
    "# url = f'https://www.alphavantage.co/query?function=OVERVIEW&symbol={symbol}&apikey={API_KEY}'\n",
    "# r = requests.get(url)\n",
    "# sector = r.json()['Sector']\n",
    "# data = r.json()\n",
    "# print(sector)\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "fda2fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ***************Sentiment would be a good source but can't seem to get more than 50 items from the API so won't go back\n",
    "# # far enough???????\n",
    "# # replace the \"demo\" apikey below with your own key from https://www.alphavantage.co/support/#api-key\n",
    "# # url = f'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers={symbol}&apikey={API_KEY}\n",
    "# url = f'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers={symbol}&time_from=20040825T0130&apikey={API_KEY}'\n",
    "# print(url)\n",
    "# r = requests.get(url)\n",
    "\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b6e3a27a-725a-4ff0-8093-48f7a3c22a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get json object with the intraday data and another with  the call's metadata\n",
    "# For the default date string index behavior\n",
    "# ts = TimeSeries(key=API_KEY, output_format='pandas', indexing_type='integer')\n",
    "# ts_data, ts_meta_data = ts.get_intraday(symbol, interval='1min', outputsize='full')\n",
    "\n",
    "\n",
    "# ts_data['4. close'].plot()\n",
    "# plt.title(f'Intraday Times Series for the {symbol} stock (1 min)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50321556-61d2-4424-8bcf-c5a256dbcce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted daily data\n",
    "ts = TimeSeries(key=API_KEY, output_format='pandas', indexing_type='integer')\n",
    "ts_data, ts_meta_data = ts.get_daily_adjusted(symbol, outputsize='full')\n",
    "\n",
    "\n",
    "# ts_data['4. close'].plot()\n",
    "# plt.title('Intraday Times Series for the GOOGL stock (1 min)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d180864-2979-4d73-b2b7-fc36c7578314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93c7ac35-6711-4dad-b71b-e6211827b528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. adjusted close</th>\n",
       "      <th>6. volume</th>\n",
       "      <th>7. dividend amount</th>\n",
       "      <th>8. split coefficient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4566</th>\n",
       "      <td>2005-01-07</td>\n",
       "      <td>34.60</td>\n",
       "      <td>34.72</td>\n",
       "      <td>34.30</td>\n",
       "      <td>34.57</td>\n",
       "      <td>21.4574</td>\n",
       "      <td>280363.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4567</th>\n",
       "      <td>2005-01-06</td>\n",
       "      <td>34.55</td>\n",
       "      <td>34.90</td>\n",
       "      <td>34.53</td>\n",
       "      <td>34.70</td>\n",
       "      <td>21.5381</td>\n",
       "      <td>250466.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4568</th>\n",
       "      <td>2005-01-05</td>\n",
       "      <td>34.20</td>\n",
       "      <td>34.70</td>\n",
       "      <td>34.15</td>\n",
       "      <td>34.65</td>\n",
       "      <td>21.5071</td>\n",
       "      <td>734946.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4569</th>\n",
       "      <td>2005-01-04</td>\n",
       "      <td>33.70</td>\n",
       "      <td>34.48</td>\n",
       "      <td>33.67</td>\n",
       "      <td>34.39</td>\n",
       "      <td>21.3457</td>\n",
       "      <td>567720.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4570</th>\n",
       "      <td>2005-01-03</td>\n",
       "      <td>33.30</td>\n",
       "      <td>33.80</td>\n",
       "      <td>33.30</td>\n",
       "      <td>33.75</td>\n",
       "      <td>20.9485</td>\n",
       "      <td>246820.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  1. open  2. high  3. low  4. close  5. adjusted close  \\\n",
       "index                                                                      \n",
       "4566   2005-01-07    34.60    34.72   34.30     34.57            21.4574   \n",
       "4567   2005-01-06    34.55    34.90   34.53     34.70            21.5381   \n",
       "4568   2005-01-05    34.20    34.70   34.15     34.65            21.5071   \n",
       "4569   2005-01-04    33.70    34.48   33.67     34.39            21.3457   \n",
       "4570   2005-01-03    33.30    33.80   33.30     33.75            20.9485   \n",
       "\n",
       "       6. volume  7. dividend amount  8. split coefficient  \n",
       "index                                                       \n",
       "4566    280363.0                 0.0                   1.0  \n",
       "4567    250466.0                 0.0                   1.0  \n",
       "4568    734946.0                 0.0                   1.0  \n",
       "4569    567720.0                 0.0                   1.0  \n",
       "4570    246820.0                 0.0                   1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_data = ts_data\n",
    "adjusted_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e469caf1-30e1-4ba1-944a-75d992d73ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the percent change for each day\n",
    "adjusted_data['day_pcent_change'] = 100 * ((ts_data['4. close'] - ts_data['1. open']) / ts_data['1. open'])\n",
    "\n",
    "\n",
    "# ******need to predict whether price for tomorrow will go up by 2% or greater - so need label - buy - 0 or 1\n",
    "# today's close data will be used to predict whether to buy tomorrow\n",
    "# so model cannot have the most recent row in it, since that would be today's data\n",
    "# from which tomorrow's prediction will be made\n",
    "\n",
    "# shift all the next days data by one which will be used to determine whether it should have been bought or not\n",
    "adjusted_data['next_days_pcent_change'] = adjusted_data['day_pcent_change'].shift(+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b985068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the label - binary classification of whether to buy or not based on whether the stock went up 2% or more\n",
    "# that day\n",
    "\n",
    "def buy_or_not(row):\n",
    "    if row.next_days_pcent_change >= pcent_change_to_buy_on:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "adjusted_data['buy_tomorrow'] = adjusted_data.apply(buy_or_not, axis='columns')\n",
    "\n",
    "# next_days_pcent_change will pollute the data set so drop it\n",
    "\n",
    "adjusted_data.drop(columns='next_days_pcent_change',\n",
    "                  inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7642421-0603-4f5c-ac8c-55225938ca85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WMA_5</th>\n",
       "      <th>WMA_10</th>\n",
       "      <th>WMA_20</th>\n",
       "      <th>WMA_40</th>\n",
       "      <th>WMA_80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4567.000000</td>\n",
       "      <td>4562.000000</td>\n",
       "      <td>4552.000000</td>\n",
       "      <td>4532.000000</td>\n",
       "      <td>4492.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>51.433204</td>\n",
       "      <td>51.443447</td>\n",
       "      <td>51.464849</td>\n",
       "      <td>51.508324</td>\n",
       "      <td>51.599924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.558871</td>\n",
       "      <td>22.533828</td>\n",
       "      <td>22.483755</td>\n",
       "      <td>22.381686</td>\n",
       "      <td>22.191139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.127500</td>\n",
       "      <td>12.280200</td>\n",
       "      <td>12.566200</td>\n",
       "      <td>13.270200</td>\n",
       "      <td>13.574300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.764950</td>\n",
       "      <td>27.832625</td>\n",
       "      <td>27.804425</td>\n",
       "      <td>27.830400</td>\n",
       "      <td>27.980025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.902700</td>\n",
       "      <td>56.262750</td>\n",
       "      <td>56.873150</td>\n",
       "      <td>57.046050</td>\n",
       "      <td>56.546300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.579600</td>\n",
       "      <td>70.619900</td>\n",
       "      <td>70.569975</td>\n",
       "      <td>70.590000</td>\n",
       "      <td>70.584525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>98.884000</td>\n",
       "      <td>98.297600</td>\n",
       "      <td>96.555600</td>\n",
       "      <td>94.075400</td>\n",
       "      <td>92.770000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             WMA_5       WMA_10       WMA_20       WMA_40       WMA_80\n",
       "count  4567.000000  4562.000000  4552.000000  4532.000000  4492.000000\n",
       "mean     51.433204    51.443447    51.464849    51.508324    51.599924\n",
       "std      22.558871    22.533828    22.483755    22.381686    22.191139\n",
       "min      12.127500    12.280200    12.566200    13.270200    13.574300\n",
       "25%      27.764950    27.832625    27.804425    27.830400    27.980025\n",
       "50%      55.902700    56.262750    56.873150    57.046050    56.546300\n",
       "75%      70.579600    70.619900    70.569975    70.590000    70.584525\n",
       "max      98.884000    98.297600    96.555600    94.075400    92.770000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# technical indicators - some of these are premium\n",
    "ti = TechIndicators(key=API_KEY, output_format='pandas')\n",
    "wma = [5, 10, 20, 40, 80]\n",
    "\n",
    "# def concat_wma_df(df, period):\n",
    "#     '''\n",
    "#     concatenate the pandas dataframes being passed into the function\n",
    "#     '''\n",
    "    \n",
    "wma_data = pd.DataFrame()\n",
    "\n",
    "for period in wma:\n",
    "    \n",
    "    sleep(sleep_time) # avoid breaching the API request rate limit\n",
    "    ti_data, ti_meta_data = ti.get_wma(symbol, interval='daily', time_period=period)\n",
    "    wma_data[f'WMA_{period}'] = ti_data['WMA']\n",
    "\n",
    "    \n",
    "wma_data.describe() \n",
    "\n",
    "# *********get the resistance figures for the MAs?\n",
    "# need to understand the relevance of the MAs better and what predictive power they are supposed to be happened so it can be represented properly\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ti_data.plot()\n",
    "# plt.title('WMA indicator for  GOOGL stock (60 min)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b45c8c06-af57-4d07-adfe-1c75dcbe1430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>WMA_5</th>\n",
       "      <th>WMA_10</th>\n",
       "      <th>WMA_20</th>\n",
       "      <th>WMA_40</th>\n",
       "      <th>WMA_80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>83.6173</td>\n",
       "      <td>83.6222</td>\n",
       "      <td>83.6899</td>\n",
       "      <td>83.9181</td>\n",
       "      <td>81.7652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>83.7027</td>\n",
       "      <td>83.6471</td>\n",
       "      <td>83.7578</td>\n",
       "      <td>83.9223</td>\n",
       "      <td>81.6605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>83.5607</td>\n",
       "      <td>83.5398</td>\n",
       "      <td>83.7701</td>\n",
       "      <td>83.8882</td>\n",
       "      <td>81.5359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>83.7067</td>\n",
       "      <td>83.5889</td>\n",
       "      <td>83.8623</td>\n",
       "      <td>83.8883</td>\n",
       "      <td>81.4272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>83.6487</td>\n",
       "      <td>83.5449</td>\n",
       "      <td>83.8986</td>\n",
       "      <td>83.8549</td>\n",
       "      <td>81.3006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    WMA_5   WMA_10   WMA_20   WMA_40   WMA_80\n",
       "0 2022-12-30  83.6173  83.6222  83.6899  83.9181  81.7652\n",
       "1 2022-12-29  83.7027  83.6471  83.7578  83.9223  81.6605\n",
       "2 2022-12-28  83.5607  83.5398  83.7701  83.8882  81.5359\n",
       "3 2022-12-27  83.7067  83.5889  83.8623  83.8883  81.4272\n",
       "4 2022-12-23  83.6487  83.5449  83.8986  83.8549  81.3006"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tech indicator data is received in the reverse order to price data so reverse it\n",
    "rev_wma_data = wma_data[::-1]\n",
    "rev_wma_data.reset_index(inplace=True)\n",
    "\n",
    "# rev_ti_data.drop(index=rev_ti_data.index[0], \n",
    "#         axis=0, \n",
    "#         inplace=True)\n",
    "rev_wma_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2307cc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for period in wma:\n",
    "    adjusted_data[f'WMA_{period}'] = rev_wma_data[f'WMA_{period}']\n",
    "#     these should be percentage diff to close as well?\n",
    "    adjusted_data[f'WMA_{period}_pcent_diff_to_close'] = (adjusted_data['4. close'] - adjusted_data[f'WMA_{period}']) / adjusted_data['4. close']\n",
    "    adjusted_data[f'WMA_{period}_pcent_diff_to_open'] = (adjusted_data['1. open'] - adjusted_data[f'WMA_{period}']) / adjusted_data['4. close']\n",
    "    adjusted_data.drop(columns=f'WMA_{period}', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b97ae181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. adjusted close</th>\n",
       "      <th>6. volume</th>\n",
       "      <th>7. dividend amount</th>\n",
       "      <th>8. split coefficient</th>\n",
       "      <th>day_pcent_change</th>\n",
       "      <th>...</th>\n",
       "      <th>WMA_5_pcent_diff_to_close</th>\n",
       "      <th>WMA_5_pcent_diff_to_open</th>\n",
       "      <th>WMA_10_pcent_diff_to_close</th>\n",
       "      <th>WMA_10_pcent_diff_to_open</th>\n",
       "      <th>WMA_20_pcent_diff_to_close</th>\n",
       "      <th>WMA_20_pcent_diff_to_open</th>\n",
       "      <th>WMA_40_pcent_diff_to_close</th>\n",
       "      <th>WMA_40_pcent_diff_to_open</th>\n",
       "      <th>WMA_80_pcent_diff_to_close</th>\n",
       "      <th>WMA_80_pcent_diff_to_open</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>83.41</td>\n",
       "      <td>83.72</td>\n",
       "      <td>83.24</td>\n",
       "      <td>83.65</td>\n",
       "      <td>83.65</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.287735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.002854</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>-0.001613</td>\n",
       "      <td>-0.002972</td>\n",
       "      <td>-0.005841</td>\n",
       "      <td>-0.002449</td>\n",
       "      <td>-0.005319</td>\n",
       "      <td>0.028086</td>\n",
       "      <td>0.025217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-22</td>\n",
       "      <td>84.20</td>\n",
       "      <td>84.20</td>\n",
       "      <td>83.01</td>\n",
       "      <td>83.29</td>\n",
       "      <td>83.29</td>\n",
       "      <td>443.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.080760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003650</td>\n",
       "      <td>0.007276</td>\n",
       "      <td>-0.003178</td>\n",
       "      <td>0.007748</td>\n",
       "      <td>-0.007997</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>-0.006450</td>\n",
       "      <td>0.004476</td>\n",
       "      <td>0.025379</td>\n",
       "      <td>0.036304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-21</td>\n",
       "      <td>83.21</td>\n",
       "      <td>84.20</td>\n",
       "      <td>83.21</td>\n",
       "      <td>84.04</td>\n",
       "      <td>84.04</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004918</td>\n",
       "      <td>-0.004958</td>\n",
       "      <td>0.004976</td>\n",
       "      <td>-0.004900</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>-0.010019</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>-0.007173</td>\n",
       "      <td>0.035488</td>\n",
       "      <td>0.025612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-20</td>\n",
       "      <td>82.17</td>\n",
       "      <td>83.75</td>\n",
       "      <td>82.17</td>\n",
       "      <td>83.75</td>\n",
       "      <td>83.75</td>\n",
       "      <td>742.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.922843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004433</td>\n",
       "      <td>-0.014432</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>-0.016684</td>\n",
       "      <td>-0.003890</td>\n",
       "      <td>-0.022756</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.018934</td>\n",
       "      <td>0.033823</td>\n",
       "      <td>0.014958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>82.66</td>\n",
       "      <td>83.86</td>\n",
       "      <td>82.66</td>\n",
       "      <td>83.70</td>\n",
       "      <td>83.70</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.258166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005305</td>\n",
       "      <td>-0.007121</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>-0.011141</td>\n",
       "      <td>-0.005119</td>\n",
       "      <td>-0.017545</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>-0.012485</td>\n",
       "      <td>0.034876</td>\n",
       "      <td>0.022450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  1. open  2. high  3. low  4. close  5. adjusted close  \\\n",
       "index                                                                      \n",
       "0      2022-12-23    83.41    83.72   83.24     83.65              83.65   \n",
       "1      2022-12-22    84.20    84.20   83.01     83.29              83.29   \n",
       "2      2022-12-21    83.21    84.20   83.21     84.04              84.04   \n",
       "3      2022-12-20    82.17    83.75   82.17     83.75              83.75   \n",
       "4      2022-12-19    82.66    83.86   82.66     83.70              83.70   \n",
       "\n",
       "       6. volume  7. dividend amount  8. split coefficient  day_pcent_change  \\\n",
       "index                                                                          \n",
       "0          431.0                 0.0                   1.0          0.287735   \n",
       "1          443.0                 0.0                   1.0         -1.080760   \n",
       "2           60.0                 0.0                   1.0          0.997476   \n",
       "3          742.0                 0.0                   1.0          1.922843   \n",
       "4          281.0                 0.0                   1.0          1.258166   \n",
       "\n",
       "       ...  WMA_5_pcent_diff_to_close  WMA_5_pcent_diff_to_open  \\\n",
       "index  ...                                                        \n",
       "0      ...                   0.000016                 -0.002854   \n",
       "1      ...                  -0.003650                  0.007276   \n",
       "2      ...                   0.004918                 -0.004958   \n",
       "3      ...                   0.004433                 -0.014432   \n",
       "4      ...                   0.005305                 -0.007121   \n",
       "\n",
       "       WMA_10_pcent_diff_to_close  WMA_10_pcent_diff_to_open  \\\n",
       "index                                                          \n",
       "0                        0.001256                  -0.001613   \n",
       "1                       -0.003178                   0.007748   \n",
       "2                        0.004976                  -0.004900   \n",
       "3                        0.002181                  -0.016684   \n",
       "4                        0.001284                  -0.011141   \n",
       "\n",
       "       WMA_20_pcent_diff_to_close  WMA_20_pcent_diff_to_open  \\\n",
       "index                                                          \n",
       "0                       -0.002972                  -0.005841   \n",
       "1                       -0.007997                   0.002928   \n",
       "2                       -0.000143                  -0.010019   \n",
       "3                       -0.003890                  -0.022756   \n",
       "4                       -0.005119                  -0.017545   \n",
       "\n",
       "       WMA_40_pcent_diff_to_close  WMA_40_pcent_diff_to_open  \\\n",
       "index                                                          \n",
       "0                       -0.002449                  -0.005319   \n",
       "1                       -0.006450                   0.004476   \n",
       "2                        0.002703                  -0.007173   \n",
       "3                       -0.000068                  -0.018934   \n",
       "4                       -0.000060                  -0.012485   \n",
       "\n",
       "       WMA_80_pcent_diff_to_close  WMA_80_pcent_diff_to_open  \n",
       "index                                                         \n",
       "0                        0.028086                   0.025217  \n",
       "1                        0.025379                   0.036304  \n",
       "2                        0.035488                   0.025612  \n",
       "3                        0.033823                   0.014958  \n",
       "4                        0.034876                   0.022450  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f447463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************\n",
    "# Now get bollinger band details - need to study this more and figure out what it means\n",
    "# https://www.tradingview.com/support/solutions/43000501972-bollinger-bands-width-bbw/\n",
    "\n",
    "# calculate the bollinger band width then look at it the difference over the last 6 months\n",
    "# Bollinger Bands Width = (Upper Band - Lower Band) / Middle Band\n",
    "\n",
    "# look for: The low volatility period is followed by a surge in volatility and \n",
    "# price breaks through the Upper Band or falls through the Lower Band signifying a \n",
    "# change in the sideways movement and the beginning of a new directional trend.\n",
    "\n",
    "\n",
    "# In a Bullish BBW Squeeze\n",
    "\n",
    "# BBW drops. (In the example below, the threshold is 6% however this changes from security to security and \n",
    "#             timeframe to timeframe)\n",
    "# Price breaks through the Upper Band which starts a new upward trend. Volatility also increases.\n",
    "\n",
    "\n",
    "# In a Bearish BBW Squeeze\n",
    "\n",
    "# BBW drops. (In the example below, the threshold is 9% however this changes from security to \n",
    "#             security and timeframe to timeframe).\n",
    "# Price falls below the Lower Band which starts a new downward trend. Volatility also increases.\n",
    "        \n",
    "bb_data, bb_meta_data = ti.get_bbands(symbol, interval='daily', time_period=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f917e3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Real Upper Band</th>\n",
       "      <th>Real Middle Band</th>\n",
       "      <th>Real Lower Band</th>\n",
       "      <th>bb_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>85.7367</td>\n",
       "      <td>83.9810</td>\n",
       "      <td>82.2253</td>\n",
       "      <td>0.041812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>85.9181</td>\n",
       "      <td>84.0825</td>\n",
       "      <td>82.2469</td>\n",
       "      <td>0.043662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>86.1966</td>\n",
       "      <td>84.1800</td>\n",
       "      <td>82.1634</td>\n",
       "      <td>0.047912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>86.2291</td>\n",
       "      <td>84.2475</td>\n",
       "      <td>82.2659</td>\n",
       "      <td>0.047042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>86.2285</td>\n",
       "      <td>84.2410</td>\n",
       "      <td>82.2535</td>\n",
       "      <td>0.047186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  Real Upper Band  Real Middle Band  Real Lower Band  bb_width\n",
       "0 2022-12-30          85.7367           83.9810          82.2253  0.041812\n",
       "1 2022-12-29          85.9181           84.0825          82.2469  0.043662\n",
       "2 2022-12-28          86.1966           84.1800          82.1634  0.047912\n",
       "3 2022-12-27          86.2291           84.2475          82.2659  0.047042\n",
       "4 2022-12-23          86.2285           84.2410          82.2535  0.047186"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_data['bb_width'] = (bb_data['Real Upper Band'] - bb_data['Real Lower Band']) / bb_data['Real Middle Band']\n",
    "bb_data.reset_index(inplace=True)\n",
    "bb_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "545aa4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_data['bb_width'] = bb_data['bb_width']\n",
    "adjusted_data['bb_upper'] = bb_data['Real Upper Band']\n",
    "adjusted_data['bb_lower'] = bb_data['Real Lower Band']\n",
    "# add the below to percentages like day_pcent_change?\n",
    "adjusted_data['pcent_diff_to_bb_upper'] = (adjusted_data['4. close'] - adjusted_data['bb_upper']) / adjusted_data['4. close']\n",
    "adjusted_data['pcent_diff_to_bb_lower'] = (adjusted_data['4. close'] - adjusted_data['bb_lower']) / adjusted_data['4. close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "98bd65f6-3193-4b51-871f-5efbda9b8f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Don't seem to be able to get this with sufficient historical data\n",
    "# sp = SectorPerformances(key=API_KEY, output_format='pandas')\n",
    "# sp_data, sp_meta_data = sp.get_sector()\n",
    "# sp_data.head()\n",
    "# # sp_data['Rank A: Real-Time Performance'].plot(kind='bar')\n",
    "# # plt.title('Real Time Performance (%) per Sector')\n",
    "# # plt.tight_layout()\n",
    "# # plt.grid()\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "988ca236",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep(sleep_time)\n",
    "macd_data, macd_meta_data = ti.get_macd(symbol, series_type='close', interval='daily')\n",
    "macd_data.reset_index(inplace=True)\n",
    "adjusted_data['macd_signal'] = macd_data['MACD_Signal']\n",
    "adjusted_data['macd_hist'] = macd_data['MACD_Hist']\n",
    "adjusted_data['macd'] = macd_data['MACD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a42f16c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep(sleep_time)\n",
    "stochrsi_data, stochrsi_meta_data = ti.get_stochrsi(symbol, series_type='close', interval='daily', time_period=10, fastkperiod=6, fastdmatype=1)\n",
    "stochrsi_data.reset_index(inplace=True)\n",
    "adjusted_data['stochrsi_fast_k'] = stochrsi_data['FastK']\n",
    "adjusted_data['stochrsi_fast_d'] = stochrsi_data['FastD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1690899",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep(sleep_time)\n",
    "ppo_data, ppo_meta_data = ti.get_ppo(symbol, series_type='close', interval='daily', fastperiod=10, matype=1)\n",
    "ppo_data.reset_index(inplace=True)\n",
    "adjusted_data['ppo'] = ppo_data['PPO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e2f2743-af3b-4411-9f72-23418900258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep(sleep_time)\n",
    "aroo_data, aroo_meta_data = ti.get_aroon(symbol, interval='daily', time_period=14)\n",
    "aroo_data.reset_index(inplace=True)\n",
    "adjusted_data['aroon'] = aroo_data['Aroon Up'] - aroo_data['Aroon Down']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "646a11e9-fcd1-4b31-9679-cdfca772e30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep(sleep_time)\n",
    "minusdi_data, minusdi_meta_data = ti.get_minus_di(symbol, interval='daily', time_period=14)\n",
    "minusdi_data.reset_index(inplace=True)\n",
    "adjusted_data['minus_di'] = minusdi_data['MINUS_DI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6f8662d-c03d-4198-82f3-d4301eb33586",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep(sleep_time)\n",
    "plusdi_data, plusdi_meta_data = ti.get_plus_di(symbol, interval='daily', time_period=14)\n",
    "plusdi_data.reset_index(inplace=True)\n",
    "adjusted_data['plus_di'] = plusdi_data['PLUS_DI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8bcf94e7-7187-4063-8d58-c48651f52de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. adjusted close</th>\n",
       "      <th>6. volume</th>\n",
       "      <th>7. dividend amount</th>\n",
       "      <th>8. split coefficient</th>\n",
       "      <th>day_pcent_change</th>\n",
       "      <th>...</th>\n",
       "      <th>pcent_diff_to_bb_lower</th>\n",
       "      <th>macd_signal</th>\n",
       "      <th>macd_hist</th>\n",
       "      <th>macd</th>\n",
       "      <th>stochrsi_fast_k</th>\n",
       "      <th>stochrsi_fast_d</th>\n",
       "      <th>ppo</th>\n",
       "      <th>aroon</th>\n",
       "      <th>minus_di</th>\n",
       "      <th>plus_di</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>83.60</td>\n",
       "      <td>83.60</td>\n",
       "      <td>83.33</td>\n",
       "      <td>83.37</td>\n",
       "      <td>83.37</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.275120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013730</td>\n",
       "      <td>0.4011</td>\n",
       "      <td>-0.1868</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>13.8567</td>\n",
       "      <td>41.2348</td>\n",
       "      <td>-1.4906</td>\n",
       "      <td>-35.7143</td>\n",
       "      <td>33.5343</td>\n",
       "      <td>15.5017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>83.48</td>\n",
       "      <td>84.06</td>\n",
       "      <td>83.12</td>\n",
       "      <td>84.05</td>\n",
       "      <td>84.05</td>\n",
       "      <td>1684.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.682798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021453</td>\n",
       "      <td>0.4478</td>\n",
       "      <td>-0.1845</td>\n",
       "      <td>0.2634</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>68.6130</td>\n",
       "      <td>-1.2474</td>\n",
       "      <td>-35.7143</td>\n",
       "      <td>35.0363</td>\n",
       "      <td>14.2230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>83.50</td>\n",
       "      <td>83.50</td>\n",
       "      <td>83.21</td>\n",
       "      <td>83.28</td>\n",
       "      <td>83.28</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.263473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013408</td>\n",
       "      <td>0.4940</td>\n",
       "      <td>-0.2410</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>37.2260</td>\n",
       "      <td>-1.1117</td>\n",
       "      <td>-64.2857</td>\n",
       "      <td>32.4979</td>\n",
       "      <td>18.4488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>84.26</td>\n",
       "      <td>84.37</td>\n",
       "      <td>83.86</td>\n",
       "      <td>83.86</td>\n",
       "      <td>83.86</td>\n",
       "      <td>754.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.474721</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019009</td>\n",
       "      <td>0.5542</td>\n",
       "      <td>-0.2399</td>\n",
       "      <td>0.3143</td>\n",
       "      <td>81.1073</td>\n",
       "      <td>74.4519</td>\n",
       "      <td>-0.8960</td>\n",
       "      <td>-71.4286</td>\n",
       "      <td>33.1367</td>\n",
       "      <td>16.2160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>83.41</td>\n",
       "      <td>83.72</td>\n",
       "      <td>83.24</td>\n",
       "      <td>83.65</td>\n",
       "      <td>83.65</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.287735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016695</td>\n",
       "      <td>0.6142</td>\n",
       "      <td>-0.2851</td>\n",
       "      <td>0.3291</td>\n",
       "      <td>72.6758</td>\n",
       "      <td>67.7966</td>\n",
       "      <td>-0.7531</td>\n",
       "      <td>-78.5714</td>\n",
       "      <td>35.4387</td>\n",
       "      <td>14.7623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  1. open  2. high  3. low  4. close  5. adjusted close  \\\n",
       "index                                                                      \n",
       "0      2022-12-30    83.60    83.60   83.33     83.37              83.37   \n",
       "1      2022-12-29    83.48    84.06   83.12     84.05              84.05   \n",
       "2      2022-12-28    83.50    83.50   83.21     83.28              83.28   \n",
       "3      2022-12-27    84.26    84.37   83.86     83.86              83.86   \n",
       "4      2022-12-23    83.41    83.72   83.24     83.65              83.65   \n",
       "\n",
       "       6. volume  7. dividend amount  8. split coefficient  day_pcent_change  \\\n",
       "index                                                                          \n",
       "0           10.0                 0.0                   1.0         -0.275120   \n",
       "1         1684.0                 0.0                   1.0          0.682798   \n",
       "2         1158.0                 0.0                   1.0         -0.263473   \n",
       "3          754.0                 0.0                   1.0         -0.474721   \n",
       "4          431.0                 0.0                   1.0          0.287735   \n",
       "\n",
       "       ...  pcent_diff_to_bb_lower  macd_signal  macd_hist    macd  \\\n",
       "index  ...                                                           \n",
       "0      ...                0.013730       0.4011    -0.1868  0.2143   \n",
       "1      ...                0.021453       0.4478    -0.1845  0.2634   \n",
       "2      ...                0.013408       0.4940    -0.2410  0.2529   \n",
       "3      ...                0.019009       0.5542    -0.2399  0.3143   \n",
       "4      ...                0.016695       0.6142    -0.2851  0.3291   \n",
       "\n",
       "       stochrsi_fast_k  stochrsi_fast_d     ppo    aroon  minus_di  plus_di  \n",
       "index                                                                        \n",
       "0              13.8567          41.2348 -1.4906 -35.7143   33.5343  15.5017  \n",
       "1             100.0000          68.6130 -1.2474 -35.7143   35.0363  14.2230  \n",
       "2               0.0000          37.2260 -1.1117 -64.2857   32.4979  18.4488  \n",
       "3              81.1073          74.4519 -0.8960 -71.4286   33.1367  16.2160  \n",
       "4              72.6758          67.7966 -0.7531 -78.5714   35.4387  14.7623  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78b4929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up NaNs\n",
    "final_data = adjusted_data.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e201bd6-94a6-4e0c-8571-c8b026872eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. adjusted close</th>\n",
       "      <th>6. volume</th>\n",
       "      <th>7. dividend amount</th>\n",
       "      <th>8. split coefficient</th>\n",
       "      <th>day_pcent_change</th>\n",
       "      <th>...</th>\n",
       "      <th>bb_lower</th>\n",
       "      <th>pcent_diff_to_bb_upper</th>\n",
       "      <th>pcent_diff_to_bb_lower</th>\n",
       "      <th>macd_signal</th>\n",
       "      <th>macd_hist</th>\n",
       "      <th>macd</th>\n",
       "      <th>stochrsi_fast_k</th>\n",
       "      <th>stochrsi_fast_d</th>\n",
       "      <th>ppo</th>\n",
       "      <th>aroon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>83.60</td>\n",
       "      <td>83.60</td>\n",
       "      <td>83.33</td>\n",
       "      <td>83.37</td>\n",
       "      <td>83.37</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.275120</td>\n",
       "      <td>...</td>\n",
       "      <td>82.2253</td>\n",
       "      <td>-0.028388</td>\n",
       "      <td>0.013730</td>\n",
       "      <td>0.4011</td>\n",
       "      <td>-0.1868</td>\n",
       "      <td>0.2143</td>\n",
       "      <td>13.8567</td>\n",
       "      <td>41.2348</td>\n",
       "      <td>-1.4906</td>\n",
       "      <td>-35.7143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>83.48</td>\n",
       "      <td>84.06</td>\n",
       "      <td>83.12</td>\n",
       "      <td>84.05</td>\n",
       "      <td>84.05</td>\n",
       "      <td>1684.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.682798</td>\n",
       "      <td>...</td>\n",
       "      <td>82.2469</td>\n",
       "      <td>-0.022226</td>\n",
       "      <td>0.021453</td>\n",
       "      <td>0.4478</td>\n",
       "      <td>-0.1845</td>\n",
       "      <td>0.2634</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>68.6130</td>\n",
       "      <td>-1.2474</td>\n",
       "      <td>-35.7143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>83.50</td>\n",
       "      <td>83.50</td>\n",
       "      <td>83.21</td>\n",
       "      <td>83.28</td>\n",
       "      <td>83.28</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.263473</td>\n",
       "      <td>...</td>\n",
       "      <td>82.1634</td>\n",
       "      <td>-0.035022</td>\n",
       "      <td>0.013408</td>\n",
       "      <td>0.4940</td>\n",
       "      <td>-0.2410</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>37.2260</td>\n",
       "      <td>-1.1117</td>\n",
       "      <td>-64.2857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>84.26</td>\n",
       "      <td>84.37</td>\n",
       "      <td>83.86</td>\n",
       "      <td>83.86</td>\n",
       "      <td>83.86</td>\n",
       "      <td>754.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.474721</td>\n",
       "      <td>...</td>\n",
       "      <td>82.2659</td>\n",
       "      <td>-0.028251</td>\n",
       "      <td>0.019009</td>\n",
       "      <td>0.5542</td>\n",
       "      <td>-0.2399</td>\n",
       "      <td>0.3143</td>\n",
       "      <td>81.1073</td>\n",
       "      <td>74.4519</td>\n",
       "      <td>-0.8960</td>\n",
       "      <td>-71.4286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>83.41</td>\n",
       "      <td>83.72</td>\n",
       "      <td>83.24</td>\n",
       "      <td>83.65</td>\n",
       "      <td>83.65</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.287735</td>\n",
       "      <td>...</td>\n",
       "      <td>82.2535</td>\n",
       "      <td>-0.030825</td>\n",
       "      <td>0.016695</td>\n",
       "      <td>0.6142</td>\n",
       "      <td>-0.2851</td>\n",
       "      <td>0.3291</td>\n",
       "      <td>72.6758</td>\n",
       "      <td>67.7966</td>\n",
       "      <td>-0.7531</td>\n",
       "      <td>-78.5714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  1. open  2. high  3. low  4. close  5. adjusted close  \\\n",
       "0  2022-12-30    83.60    83.60   83.33     83.37              83.37   \n",
       "1  2022-12-29    83.48    84.06   83.12     84.05              84.05   \n",
       "2  2022-12-28    83.50    83.50   83.21     83.28              83.28   \n",
       "3  2022-12-27    84.26    84.37   83.86     83.86              83.86   \n",
       "4  2022-12-23    83.41    83.72   83.24     83.65              83.65   \n",
       "\n",
       "   6. volume  7. dividend amount  8. split coefficient  day_pcent_change  ...  \\\n",
       "0       10.0                 0.0                   1.0         -0.275120  ...   \n",
       "1     1684.0                 0.0                   1.0          0.682798  ...   \n",
       "2     1158.0                 0.0                   1.0         -0.263473  ...   \n",
       "3      754.0                 0.0                   1.0         -0.474721  ...   \n",
       "4      431.0                 0.0                   1.0          0.287735  ...   \n",
       "\n",
       "   bb_lower  pcent_diff_to_bb_upper  pcent_diff_to_bb_lower  macd_signal  \\\n",
       "0   82.2253               -0.028388                0.013730       0.4011   \n",
       "1   82.2469               -0.022226                0.021453       0.4478   \n",
       "2   82.1634               -0.035022                0.013408       0.4940   \n",
       "3   82.2659               -0.028251                0.019009       0.5542   \n",
       "4   82.2535               -0.030825                0.016695       0.6142   \n",
       "\n",
       "   macd_hist    macd  stochrsi_fast_k  stochrsi_fast_d     ppo    aroon  \n",
       "0    -0.1868  0.2143          13.8567          41.2348 -1.4906 -35.7143  \n",
       "1    -0.1845  0.2634         100.0000          68.6130 -1.2474 -35.7143  \n",
       "2    -0.2410  0.2529           0.0000          37.2260 -1.1117 -64.2857  \n",
       "3    -0.2399  0.3143          81.1073          74.4519 -0.8960 -71.4286  \n",
       "4    -0.2851  0.3291          72.6758          67.7966 -0.7531 -78.5714  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce9f3c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't need the dates\n",
    "final_data.drop(columns='index', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5139615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. adjusted close</th>\n",
       "      <th>6. volume</th>\n",
       "      <th>7. dividend amount</th>\n",
       "      <th>8. split coefficient</th>\n",
       "      <th>day_pcent_change</th>\n",
       "      <th>buy_tomorrow</th>\n",
       "      <th>...</th>\n",
       "      <th>bb_lower</th>\n",
       "      <th>pcent_diff_to_bb_upper</th>\n",
       "      <th>pcent_diff_to_bb_lower</th>\n",
       "      <th>macd_signal</th>\n",
       "      <th>macd_hist</th>\n",
       "      <th>macd</th>\n",
       "      <th>stochrsi_fast_k</th>\n",
       "      <th>stochrsi_fast_d</th>\n",
       "      <th>ppo</th>\n",
       "      <th>aroon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83.48</td>\n",
       "      <td>84.06</td>\n",
       "      <td>83.12</td>\n",
       "      <td>84.05</td>\n",
       "      <td>84.05</td>\n",
       "      <td>1684.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.682798</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.2469</td>\n",
       "      <td>-0.022226</td>\n",
       "      <td>0.021453</td>\n",
       "      <td>0.4478</td>\n",
       "      <td>-0.1845</td>\n",
       "      <td>0.2634</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>68.6130</td>\n",
       "      <td>-1.2474</td>\n",
       "      <td>-35.7143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83.50</td>\n",
       "      <td>83.50</td>\n",
       "      <td>83.21</td>\n",
       "      <td>83.28</td>\n",
       "      <td>83.28</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.263473</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.1634</td>\n",
       "      <td>-0.035022</td>\n",
       "      <td>0.013408</td>\n",
       "      <td>0.4940</td>\n",
       "      <td>-0.2410</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>37.2260</td>\n",
       "      <td>-1.1117</td>\n",
       "      <td>-64.2857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84.26</td>\n",
       "      <td>84.37</td>\n",
       "      <td>83.86</td>\n",
       "      <td>83.86</td>\n",
       "      <td>83.86</td>\n",
       "      <td>754.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.474721</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.2659</td>\n",
       "      <td>-0.028251</td>\n",
       "      <td>0.019009</td>\n",
       "      <td>0.5542</td>\n",
       "      <td>-0.2399</td>\n",
       "      <td>0.3143</td>\n",
       "      <td>81.1073</td>\n",
       "      <td>74.4519</td>\n",
       "      <td>-0.8960</td>\n",
       "      <td>-71.4286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83.41</td>\n",
       "      <td>83.72</td>\n",
       "      <td>83.24</td>\n",
       "      <td>83.65</td>\n",
       "      <td>83.65</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.287735</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.2535</td>\n",
       "      <td>-0.030825</td>\n",
       "      <td>0.016695</td>\n",
       "      <td>0.6142</td>\n",
       "      <td>-0.2851</td>\n",
       "      <td>0.3291</td>\n",
       "      <td>72.6758</td>\n",
       "      <td>67.7966</td>\n",
       "      <td>-0.7531</td>\n",
       "      <td>-78.5714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>84.20</td>\n",
       "      <td>84.20</td>\n",
       "      <td>83.01</td>\n",
       "      <td>83.29</td>\n",
       "      <td>83.29</td>\n",
       "      <td>443.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.080760</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.2787</td>\n",
       "      <td>-0.035290</td>\n",
       "      <td>0.012142</td>\n",
       "      <td>0.6855</td>\n",
       "      <td>-0.3210</td>\n",
       "      <td>0.3645</td>\n",
       "      <td>44.1339</td>\n",
       "      <td>62.9174</td>\n",
       "      <td>-0.7096</td>\n",
       "      <td>-78.5714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>83.21</td>\n",
       "      <td>84.20</td>\n",
       "      <td>83.21</td>\n",
       "      <td>84.04</td>\n",
       "      <td>84.04</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997476</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.3714</td>\n",
       "      <td>-0.025983</td>\n",
       "      <td>0.019855</td>\n",
       "      <td>0.7657</td>\n",
       "      <td>-0.3247</td>\n",
       "      <td>0.4410</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>81.7008</td>\n",
       "      <td>-0.6703</td>\n",
       "      <td>-92.8571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>82.17</td>\n",
       "      <td>83.75</td>\n",
       "      <td>82.17</td>\n",
       "      <td>83.75</td>\n",
       "      <td>83.75</td>\n",
       "      <td>742.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.922843</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.3569</td>\n",
       "      <td>-0.029506</td>\n",
       "      <td>0.016634</td>\n",
       "      <td>0.8469</td>\n",
       "      <td>-0.3910</td>\n",
       "      <td>0.4559</td>\n",
       "      <td>88.6782</td>\n",
       "      <td>63.4016</td>\n",
       "      <td>-0.7425</td>\n",
       "      <td>-92.8571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>82.66</td>\n",
       "      <td>83.86</td>\n",
       "      <td>82.66</td>\n",
       "      <td>83.70</td>\n",
       "      <td>83.70</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.258166</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>82.3835</td>\n",
       "      <td>-0.030149</td>\n",
       "      <td>0.015729</td>\n",
       "      <td>0.9447</td>\n",
       "      <td>-0.4468</td>\n",
       "      <td>0.4979</td>\n",
       "      <td>67.6404</td>\n",
       "      <td>38.1249</td>\n",
       "      <td>-0.7287</td>\n",
       "      <td>-78.5714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>83.50</td>\n",
       "      <td>83.50</td>\n",
       "      <td>82.33</td>\n",
       "      <td>82.65</td>\n",
       "      <td>82.65</td>\n",
       "      <td>657.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.017964</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.3590</td>\n",
       "      <td>-0.043291</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>1.0563</td>\n",
       "      <td>-0.5071</td>\n",
       "      <td>0.5492</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.6094</td>\n",
       "      <td>-0.7640</td>\n",
       "      <td>-78.5714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>83.86</td>\n",
       "      <td>83.86</td>\n",
       "      <td>82.80</td>\n",
       "      <td>82.80</td>\n",
       "      <td>82.80</td>\n",
       "      <td>695.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.264011</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.5745</td>\n",
       "      <td>-0.040465</td>\n",
       "      <td>0.002723</td>\n",
       "      <td>1.1831</td>\n",
       "      <td>-0.4694</td>\n",
       "      <td>0.7137</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>17.2188</td>\n",
       "      <td>-0.7512</td>\n",
       "      <td>-71.4286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>83.92</td>\n",
       "      <td>84.31</td>\n",
       "      <td>83.53</td>\n",
       "      <td>83.58</td>\n",
       "      <td>83.58</td>\n",
       "      <td>907.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.405148</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.4435</td>\n",
       "      <td>-0.031688</td>\n",
       "      <td>0.013598</td>\n",
       "      <td>1.3005</td>\n",
       "      <td>-0.4024</td>\n",
       "      <td>0.8980</td>\n",
       "      <td>28.5771</td>\n",
       "      <td>34.4376</td>\n",
       "      <td>-0.8857</td>\n",
       "      <td>-35.7143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>84.96</td>\n",
       "      <td>85.00</td>\n",
       "      <td>83.98</td>\n",
       "      <td>84.18</td>\n",
       "      <td>84.18</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.918079</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.2933</td>\n",
       "      <td>-0.025074</td>\n",
       "      <td>0.022413</td>\n",
       "      <td>1.4011</td>\n",
       "      <td>-0.3603</td>\n",
       "      <td>1.0408</td>\n",
       "      <td>46.3193</td>\n",
       "      <td>40.2982</td>\n",
       "      <td>-1.0026</td>\n",
       "      <td>-35.7143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>83.95</td>\n",
       "      <td>84.54</td>\n",
       "      <td>83.95</td>\n",
       "      <td>84.54</td>\n",
       "      <td>84.54</td>\n",
       "      <td>733.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.702799</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.3071</td>\n",
       "      <td>-0.020888</td>\n",
       "      <td>0.026412</td>\n",
       "      <td>1.4911</td>\n",
       "      <td>-0.3444</td>\n",
       "      <td>1.1468</td>\n",
       "      <td>43.0797</td>\n",
       "      <td>34.2772</td>\n",
       "      <td>-1.1046</td>\n",
       "      <td>-35.7143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>82.95</td>\n",
       "      <td>84.62</td>\n",
       "      <td>82.95</td>\n",
       "      <td>84.51</td>\n",
       "      <td>84.51</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.880651</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.3101</td>\n",
       "      <td>-0.021405</td>\n",
       "      <td>0.026031</td>\n",
       "      <td>1.5772</td>\n",
       "      <td>-0.3485</td>\n",
       "      <td>1.2287</td>\n",
       "      <td>42.3920</td>\n",
       "      <td>25.4746</td>\n",
       "      <td>-1.0652</td>\n",
       "      <td>-35.7142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>84.75</td>\n",
       "      <td>84.75</td>\n",
       "      <td>82.84</td>\n",
       "      <td>82.84</td>\n",
       "      <td>82.84</td>\n",
       "      <td>616.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.253687</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>82.3098</td>\n",
       "      <td>-0.041987</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>1.6644</td>\n",
       "      <td>-0.3459</td>\n",
       "      <td>1.3185</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.5572</td>\n",
       "      <td>-1.0609</td>\n",
       "      <td>-35.7143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>84.72</td>\n",
       "      <td>85.23</td>\n",
       "      <td>84.72</td>\n",
       "      <td>84.85</td>\n",
       "      <td>84.85</td>\n",
       "      <td>776.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.153447</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.2730</td>\n",
       "      <td>-0.017525</td>\n",
       "      <td>0.030371</td>\n",
       "      <td>1.7508</td>\n",
       "      <td>-0.1669</td>\n",
       "      <td>1.5839</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>17.1145</td>\n",
       "      <td>-0.9706</td>\n",
       "      <td>71.4286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>85.90</td>\n",
       "      <td>85.90</td>\n",
       "      <td>85.00</td>\n",
       "      <td>85.24</td>\n",
       "      <td>85.24</td>\n",
       "      <td>1162.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.768335</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>81.2816</td>\n",
       "      <td>-0.018693</td>\n",
       "      <td>0.046438</td>\n",
       "      <td>1.7926</td>\n",
       "      <td>-0.0976</td>\n",
       "      <td>1.6950</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>34.2290</td>\n",
       "      <td>-0.7504</td>\n",
       "      <td>78.5714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>85.10</td>\n",
       "      <td>86.00</td>\n",
       "      <td>85.10</td>\n",
       "      <td>86.00</td>\n",
       "      <td>86.00</td>\n",
       "      <td>637.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.057579</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>80.7751</td>\n",
       "      <td>-0.010406</td>\n",
       "      <td>0.060755</td>\n",
       "      <td>1.8170</td>\n",
       "      <td>-0.0446</td>\n",
       "      <td>1.7724</td>\n",
       "      <td>78.1896</td>\n",
       "      <td>68.4580</td>\n",
       "      <td>-0.4977</td>\n",
       "      <td>78.5714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>85.39</td>\n",
       "      <td>85.44</td>\n",
       "      <td>84.86</td>\n",
       "      <td>85.44</td>\n",
       "      <td>85.44</td>\n",
       "      <td>371.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.058555</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>80.3857</td>\n",
       "      <td>-0.015359</td>\n",
       "      <td>0.059156</td>\n",
       "      <td>1.8281</td>\n",
       "      <td>-0.0600</td>\n",
       "      <td>1.7681</td>\n",
       "      <td>52.3383</td>\n",
       "      <td>58.7263</td>\n",
       "      <td>-0.3326</td>\n",
       "      <td>78.5714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>86.70</td>\n",
       "      <td>87.32</td>\n",
       "      <td>84.51</td>\n",
       "      <td>85.40</td>\n",
       "      <td>85.40</td>\n",
       "      <td>2485.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.499423</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>79.7518</td>\n",
       "      <td>-0.016302</td>\n",
       "      <td>0.066138</td>\n",
       "      <td>1.8431</td>\n",
       "      <td>-0.0493</td>\n",
       "      <td>1.7938</td>\n",
       "      <td>50.5261</td>\n",
       "      <td>65.1142</td>\n",
       "      <td>-0.2032</td>\n",
       "      <td>78.5714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>84.99</td>\n",
       "      <td>86.10</td>\n",
       "      <td>84.99</td>\n",
       "      <td>86.00</td>\n",
       "      <td>86.00</td>\n",
       "      <td>1629.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.188375</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.4031</td>\n",
       "      <td>-0.014662</td>\n",
       "      <td>0.088336</td>\n",
       "      <td>1.8554</td>\n",
       "      <td>-0.0508</td>\n",
       "      <td>1.8047</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>79.7023</td>\n",
       "      <td>-0.0140</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>83.45</td>\n",
       "      <td>84.91</td>\n",
       "      <td>83.45</td>\n",
       "      <td>84.63</td>\n",
       "      <td>84.63</td>\n",
       "      <td>970.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414020</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.1508</td>\n",
       "      <td>-0.026707</td>\n",
       "      <td>0.076559</td>\n",
       "      <td>1.8681</td>\n",
       "      <td>-0.1369</td>\n",
       "      <td>1.7312</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>59.4045</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>28.5714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>83.89</td>\n",
       "      <td>83.89</td>\n",
       "      <td>82.95</td>\n",
       "      <td>83.73</td>\n",
       "      <td>83.73</td>\n",
       "      <td>918.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.190726</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>77.9815</td>\n",
       "      <td>-0.034916</td>\n",
       "      <td>0.068655</td>\n",
       "      <td>1.9024</td>\n",
       "      <td>-0.1507</td>\n",
       "      <td>1.7517</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>18.8091</td>\n",
       "      <td>0.4094</td>\n",
       "      <td>28.5714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>83.72</td>\n",
       "      <td>83.91</td>\n",
       "      <td>83.61</td>\n",
       "      <td>83.91</td>\n",
       "      <td>83.91</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.226947</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>77.6601</td>\n",
       "      <td>-0.031521</td>\n",
       "      <td>0.074483</td>\n",
       "      <td>1.9400</td>\n",
       "      <td>-0.0960</td>\n",
       "      <td>1.8440</td>\n",
       "      <td>7.4191</td>\n",
       "      <td>37.6181</td>\n",
       "      <td>0.8754</td>\n",
       "      <td>42.8571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>84.59</td>\n",
       "      <td>84.59</td>\n",
       "      <td>83.89</td>\n",
       "      <td>84.16</td>\n",
       "      <td>84.16</td>\n",
       "      <td>670.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.508334</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>77.4536</td>\n",
       "      <td>-0.026252</td>\n",
       "      <td>0.079686</td>\n",
       "      <td>1.9640</td>\n",
       "      <td>-0.0473</td>\n",
       "      <td>1.9168</td>\n",
       "      <td>85.2159</td>\n",
       "      <td>67.8172</td>\n",
       "      <td>1.1910</td>\n",
       "      <td>50.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>84.69</td>\n",
       "      <td>84.69</td>\n",
       "      <td>82.88</td>\n",
       "      <td>83.87</td>\n",
       "      <td>83.87</td>\n",
       "      <td>836.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.968237</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>77.2705</td>\n",
       "      <td>-0.026786</td>\n",
       "      <td>0.078687</td>\n",
       "      <td>1.9758</td>\n",
       "      <td>-0.0196</td>\n",
       "      <td>1.9562</td>\n",
       "      <td>65.7970</td>\n",
       "      <td>50.4185</td>\n",
       "      <td>1.3960</td>\n",
       "      <td>57.1429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>82.98</td>\n",
       "      <td>84.25</td>\n",
       "      <td>82.98</td>\n",
       "      <td>84.04</td>\n",
       "      <td>84.04</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.277416</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.9970</td>\n",
       "      <td>-0.022168</td>\n",
       "      <td>0.083805</td>\n",
       "      <td>1.9807</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>2.0077</td>\n",
       "      <td>40.9577</td>\n",
       "      <td>35.0399</td>\n",
       "      <td>1.4416</td>\n",
       "      <td>57.1428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>84.09</td>\n",
       "      <td>84.09</td>\n",
       "      <td>83.50</td>\n",
       "      <td>83.50</td>\n",
       "      <td>83.50</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.701629</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.4892</td>\n",
       "      <td>-0.026848</td>\n",
       "      <td>0.083962</td>\n",
       "      <td>1.9740</td>\n",
       "      <td>0.0529</td>\n",
       "      <td>2.0269</td>\n",
       "      <td>22.8221</td>\n",
       "      <td>29.1220</td>\n",
       "      <td>1.3827</td>\n",
       "      <td>57.1429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>83.16</td>\n",
       "      <td>84.03</td>\n",
       "      <td>83.16</td>\n",
       "      <td>84.03</td>\n",
       "      <td>84.03</td>\n",
       "      <td>293.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.046176</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.1603</td>\n",
       "      <td>-0.017740</td>\n",
       "      <td>0.093653</td>\n",
       "      <td>1.9608</td>\n",
       "      <td>0.1160</td>\n",
       "      <td>2.0768</td>\n",
       "      <td>44.0919</td>\n",
       "      <td>35.4219</td>\n",
       "      <td>1.4245</td>\n",
       "      <td>57.1428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>83.40</td>\n",
       "      <td>83.40</td>\n",
       "      <td>81.85</td>\n",
       "      <td>82.27</td>\n",
       "      <td>82.27</td>\n",
       "      <td>595.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.354916</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>75.8762</td>\n",
       "      <td>-0.035150</td>\n",
       "      <td>0.077717</td>\n",
       "      <td>1.9318</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>2.0564</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>26.7519</td>\n",
       "      <td>1.5793</td>\n",
       "      <td>57.1429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>85.11</td>\n",
       "      <td>85.11</td>\n",
       "      <td>81.56</td>\n",
       "      <td>82.70</td>\n",
       "      <td>82.70</td>\n",
       "      <td>2046.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.831630</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>75.6015</td>\n",
       "      <td>-0.027842</td>\n",
       "      <td>0.085834</td>\n",
       "      <td>1.9006</td>\n",
       "      <td>0.2791</td>\n",
       "      <td>2.1797</td>\n",
       "      <td>14.9057</td>\n",
       "      <td>53.5039</td>\n",
       "      <td>1.8413</td>\n",
       "      <td>57.1428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>85.57</td>\n",
       "      <td>85.57</td>\n",
       "      <td>83.38</td>\n",
       "      <td>84.47</td>\n",
       "      <td>84.47</td>\n",
       "      <td>28716.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.285497</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>75.2629</td>\n",
       "      <td>-0.003707</td>\n",
       "      <td>0.108998</td>\n",
       "      <td>1.8308</td>\n",
       "      <td>0.4307</td>\n",
       "      <td>2.2615</td>\n",
       "      <td>89.5151</td>\n",
       "      <td>92.1021</td>\n",
       "      <td>2.0658</td>\n",
       "      <td>57.1429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>84.54</td>\n",
       "      <td>85.34</td>\n",
       "      <td>84.54</td>\n",
       "      <td>84.70</td>\n",
       "      <td>84.70</td>\n",
       "      <td>28981.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.189260</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>75.3064</td>\n",
       "      <td>0.007372</td>\n",
       "      <td>0.110904</td>\n",
       "      <td>1.7232</td>\n",
       "      <td>0.4296</td>\n",
       "      <td>2.1528</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>94.6891</td>\n",
       "      <td>2.1899</td>\n",
       "      <td>50.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>84.00</td>\n",
       "      <td>84.50</td>\n",
       "      <td>83.46</td>\n",
       "      <td>84.50</td>\n",
       "      <td>84.50</td>\n",
       "      <td>66920.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>75.3138</td>\n",
       "      <td>0.014944</td>\n",
       "      <td>0.108712</td>\n",
       "      <td>1.6158</td>\n",
       "      <td>0.3436</td>\n",
       "      <td>1.9594</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>89.3782</td>\n",
       "      <td>2.2059</td>\n",
       "      <td>42.8571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>80.47</td>\n",
       "      <td>82.77</td>\n",
       "      <td>80.47</td>\n",
       "      <td>82.66</td>\n",
       "      <td>82.66</td>\n",
       "      <td>39255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.721511</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>75.1461</td>\n",
       "      <td>0.002711</td>\n",
       "      <td>0.090901</td>\n",
       "      <td>1.5298</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>1.7043</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>78.7564</td>\n",
       "      <td>2.2029</td>\n",
       "      <td>35.7143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>80.58</td>\n",
       "      <td>80.58</td>\n",
       "      <td>79.57</td>\n",
       "      <td>79.90</td>\n",
       "      <td>79.90</td>\n",
       "      <td>20517.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.843882</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>74.6951</td>\n",
       "      <td>-0.026982</td>\n",
       "      <td>0.065143</td>\n",
       "      <td>1.4862</td>\n",
       "      <td>0.0551</td>\n",
       "      <td>1.5413</td>\n",
       "      <td>59.7187</td>\n",
       "      <td>57.5127</td>\n",
       "      <td>2.0583</td>\n",
       "      <td>14.2857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>80.78</td>\n",
       "      <td>80.92</td>\n",
       "      <td>80.27</td>\n",
       "      <td>80.79</td>\n",
       "      <td>80.79</td>\n",
       "      <td>24057.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.012379</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.7571</td>\n",
       "      <td>-0.018801</td>\n",
       "      <td>0.087052</td>\n",
       "      <td>1.4725</td>\n",
       "      <td>0.1195</td>\n",
       "      <td>1.5919</td>\n",
       "      <td>62.9194</td>\n",
       "      <td>55.3067</td>\n",
       "      <td>1.9549</td>\n",
       "      <td>14.2857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>80.09</td>\n",
       "      <td>81.00</td>\n",
       "      <td>79.38</td>\n",
       "      <td>80.68</td>\n",
       "      <td>80.68</td>\n",
       "      <td>54845.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.736671</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>72.9176</td>\n",
       "      <td>-0.020369</td>\n",
       "      <td>0.096212</td>\n",
       "      <td>1.4426</td>\n",
       "      <td>0.1001</td>\n",
       "      <td>1.5427</td>\n",
       "      <td>61.5570</td>\n",
       "      <td>47.6940</td>\n",
       "      <td>1.8067</td>\n",
       "      <td>14.2857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>77.15</td>\n",
       "      <td>79.76</td>\n",
       "      <td>77.15</td>\n",
       "      <td>79.50</td>\n",
       "      <td>79.50</td>\n",
       "      <td>35986.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.046014</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>72.2767</td>\n",
       "      <td>-0.033538</td>\n",
       "      <td>0.090859</td>\n",
       "      <td>1.4175</td>\n",
       "      <td>0.0511</td>\n",
       "      <td>1.4687</td>\n",
       "      <td>46.3335</td>\n",
       "      <td>33.8310</td>\n",
       "      <td>1.7504</td>\n",
       "      <td>78.5714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>79.29</td>\n",
       "      <td>79.71</td>\n",
       "      <td>75.39</td>\n",
       "      <td>76.60</td>\n",
       "      <td>76.60</td>\n",
       "      <td>55498.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.392609</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>71.4068</td>\n",
       "      <td>-0.073580</td>\n",
       "      <td>0.067796</td>\n",
       "      <td>1.4048</td>\n",
       "      <td>0.0682</td>\n",
       "      <td>1.4730</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>21.3284</td>\n",
       "      <td>1.6467</td>\n",
       "      <td>85.7143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>80.62</td>\n",
       "      <td>80.62</td>\n",
       "      <td>79.77</td>\n",
       "      <td>79.77</td>\n",
       "      <td>79.77</td>\n",
       "      <td>17510.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.054329</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.8070</td>\n",
       "      <td>-0.032819</td>\n",
       "      <td>0.112361</td>\n",
       "      <td>1.3877</td>\n",
       "      <td>0.3646</td>\n",
       "      <td>1.7523</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>42.6568</td>\n",
       "      <td>1.5613</td>\n",
       "      <td>92.8571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>79.83</td>\n",
       "      <td>81.00</td>\n",
       "      <td>79.83</td>\n",
       "      <td>80.57</td>\n",
       "      <td>80.57</td>\n",
       "      <td>22698.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.926970</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.2401</td>\n",
       "      <td>-0.019696</td>\n",
       "      <td>0.128210</td>\n",
       "      <td>1.2966</td>\n",
       "      <td>0.4640</td>\n",
       "      <td>1.7605</td>\n",
       "      <td>96.8177</td>\n",
       "      <td>85.3137</td>\n",
       "      <td>1.3673</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>80.09</td>\n",
       "      <td>80.09</td>\n",
       "      <td>79.11</td>\n",
       "      <td>79.53</td>\n",
       "      <td>79.53</td>\n",
       "      <td>15564.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.699213</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0532</td>\n",
       "      <td>-0.025786</td>\n",
       "      <td>0.119160</td>\n",
       "      <td>1.1806</td>\n",
       "      <td>0.4834</td>\n",
       "      <td>1.6640</td>\n",
       "      <td>56.9304</td>\n",
       "      <td>73.8096</td>\n",
       "      <td>1.2267</td>\n",
       "      <td>100.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>79.37</td>\n",
       "      <td>79.99</td>\n",
       "      <td>78.18</td>\n",
       "      <td>79.99</td>\n",
       "      <td>79.99</td>\n",
       "      <td>26589.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.781152</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.4764</td>\n",
       "      <td>-0.016122</td>\n",
       "      <td>0.131436</td>\n",
       "      <td>1.0597</td>\n",
       "      <td>0.5627</td>\n",
       "      <td>1.6225</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>90.6887</td>\n",
       "      <td>1.0480</td>\n",
       "      <td>92.8571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>78.97</td>\n",
       "      <td>79.80</td>\n",
       "      <td>78.92</td>\n",
       "      <td>79.80</td>\n",
       "      <td>79.80</td>\n",
       "      <td>29404.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.051032</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.8688</td>\n",
       "      <td>-0.013273</td>\n",
       "      <td>0.136982</td>\n",
       "      <td>0.9190</td>\n",
       "      <td>0.5800</td>\n",
       "      <td>1.4990</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>81.3775</td>\n",
       "      <td>0.8923</td>\n",
       "      <td>85.7143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>78.32</td>\n",
       "      <td>79.20</td>\n",
       "      <td>78.29</td>\n",
       "      <td>79.00</td>\n",
       "      <td>79.00</td>\n",
       "      <td>14776.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.868233</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.2593</td>\n",
       "      <td>-0.017578</td>\n",
       "      <td>0.135958</td>\n",
       "      <td>0.7741</td>\n",
       "      <td>0.5649</td>\n",
       "      <td>1.3390</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>62.7550</td>\n",
       "      <td>0.7593</td>\n",
       "      <td>78.5714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>78.07</td>\n",
       "      <td>78.07</td>\n",
       "      <td>77.35</td>\n",
       "      <td>77.35</td>\n",
       "      <td>77.35</td>\n",
       "      <td>13666.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.922249</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.2572</td>\n",
       "      <td>-0.030573</td>\n",
       "      <td>0.117554</td>\n",
       "      <td>0.6328</td>\n",
       "      <td>0.5639</td>\n",
       "      <td>1.1967</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>25.5100</td>\n",
       "      <td>0.3780</td>\n",
       "      <td>35.7143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>78.22</td>\n",
       "      <td>78.53</td>\n",
       "      <td>75.99</td>\n",
       "      <td>78.00</td>\n",
       "      <td>78.00</td>\n",
       "      <td>9297.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.281258</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0578</td>\n",
       "      <td>-0.016772</td>\n",
       "      <td>0.127464</td>\n",
       "      <td>0.4918</td>\n",
       "      <td>0.6739</td>\n",
       "      <td>1.1658</td>\n",
       "      <td>33.3744</td>\n",
       "      <td>51.0200</td>\n",
       "      <td>-0.1044</td>\n",
       "      <td>35.7143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>77.19</td>\n",
       "      <td>77.60</td>\n",
       "      <td>76.67</td>\n",
       "      <td>77.60</td>\n",
       "      <td>77.60</td>\n",
       "      <td>8452.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.531157</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0717</td>\n",
       "      <td>-0.013999</td>\n",
       "      <td>0.122787</td>\n",
       "      <td>0.3234</td>\n",
       "      <td>0.7197</td>\n",
       "      <td>1.0431</td>\n",
       "      <td>53.7374</td>\n",
       "      <td>68.6655</td>\n",
       "      <td>-0.4234</td>\n",
       "      <td>78.5714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>77.76</td>\n",
       "      <td>78.05</td>\n",
       "      <td>77.16</td>\n",
       "      <td>77.93</td>\n",
       "      <td>77.93</td>\n",
       "      <td>14063.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.218621</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0869</td>\n",
       "      <td>-0.001759</td>\n",
       "      <td>0.126307</td>\n",
       "      <td>0.1434</td>\n",
       "      <td>0.7686</td>\n",
       "      <td>0.9120</td>\n",
       "      <td>80.9558</td>\n",
       "      <td>83.5937</td>\n",
       "      <td>-0.7079</td>\n",
       "      <td>78.5714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>78.00</td>\n",
       "      <td>78.00</td>\n",
       "      <td>77.12</td>\n",
       "      <td>77.12</td>\n",
       "      <td>77.12</td>\n",
       "      <td>21251.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.128205</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.3723</td>\n",
       "      <td>-0.004522</td>\n",
       "      <td>0.113430</td>\n",
       "      <td>-0.0487</td>\n",
       "      <td>0.7466</td>\n",
       "      <td>0.6979</td>\n",
       "      <td>72.9086</td>\n",
       "      <td>86.2316</td>\n",
       "      <td>-0.9216</td>\n",
       "      <td>92.8571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>77.33</td>\n",
       "      <td>78.63</td>\n",
       "      <td>77.33</td>\n",
       "      <td>77.83</td>\n",
       "      <td>77.83</td>\n",
       "      <td>42023.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.646580</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.5955</td>\n",
       "      <td>0.010876</td>\n",
       "      <td>0.118650</td>\n",
       "      <td>-0.2354</td>\n",
       "      <td>0.7323</td>\n",
       "      <td>0.4970</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>99.5545</td>\n",
       "      <td>-1.0976</td>\n",
       "      <td>92.8571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>75.28</td>\n",
       "      <td>76.78</td>\n",
       "      <td>74.85</td>\n",
       "      <td>76.39</td>\n",
       "      <td>76.39</td>\n",
       "      <td>21553.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.474495</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.9859</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>0.096925</td>\n",
       "      <td>-0.4185</td>\n",
       "      <td>0.5794</td>\n",
       "      <td>0.1609</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>99.1091</td>\n",
       "      <td>-1.1820</td>\n",
       "      <td>85.7143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>75.10</td>\n",
       "      <td>76.00</td>\n",
       "      <td>74.53</td>\n",
       "      <td>74.81</td>\n",
       "      <td>74.81</td>\n",
       "      <td>19772.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.386152</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.1714</td>\n",
       "      <td>-0.015527</td>\n",
       "      <td>0.075372</td>\n",
       "      <td>-0.5633</td>\n",
       "      <td>0.4397</td>\n",
       "      <td>-0.1237</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>98.2181</td>\n",
       "      <td>-1.3139</td>\n",
       "      <td>78.5714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>72.57</td>\n",
       "      <td>74.35</td>\n",
       "      <td>72.30</td>\n",
       "      <td>74.35</td>\n",
       "      <td>74.35</td>\n",
       "      <td>26303.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.452804</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.2144</td>\n",
       "      <td>-0.020331</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>-0.6732</td>\n",
       "      <td>0.3490</td>\n",
       "      <td>-0.3242</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>96.4362</td>\n",
       "      <td>-1.4934</td>\n",
       "      <td>71.4286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>72.38</td>\n",
       "      <td>73.05</td>\n",
       "      <td>71.50</td>\n",
       "      <td>73.05</td>\n",
       "      <td>73.05</td>\n",
       "      <td>17181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.925670</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>69.1951</td>\n",
       "      <td>-0.039150</td>\n",
       "      <td>0.052771</td>\n",
       "      <td>-0.7605</td>\n",
       "      <td>0.2318</td>\n",
       "      <td>-0.5287</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>92.8725</td>\n",
       "      <td>-1.7237</td>\n",
       "      <td>-35.7143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>71.06</td>\n",
       "      <td>72.61</td>\n",
       "      <td>70.43</td>\n",
       "      <td>72.54</td>\n",
       "      <td>72.54</td>\n",
       "      <td>22322.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.082747</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.1475</td>\n",
       "      <td>-0.049511</td>\n",
       "      <td>0.046767</td>\n",
       "      <td>-0.8184</td>\n",
       "      <td>0.1688</td>\n",
       "      <td>-0.6496</td>\n",
       "      <td>85.4438</td>\n",
       "      <td>85.7449</td>\n",
       "      <td>-1.7408</td>\n",
       "      <td>-42.8571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>70.99</td>\n",
       "      <td>73.00</td>\n",
       "      <td>70.62</td>\n",
       "      <td>72.70</td>\n",
       "      <td>72.70</td>\n",
       "      <td>12109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.408790</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>69.1534</td>\n",
       "      <td>-0.049816</td>\n",
       "      <td>0.048784</td>\n",
       "      <td>-0.8606</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>-0.7426</td>\n",
       "      <td>99.4282</td>\n",
       "      <td>86.0460</td>\n",
       "      <td>-1.6241</td>\n",
       "      <td>-50.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>71.50</td>\n",
       "      <td>71.50</td>\n",
       "      <td>71.50</td>\n",
       "      <td>71.50</td>\n",
       "      <td>71.50</td>\n",
       "      <td>9316.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>69.0589</td>\n",
       "      <td>-0.073218</td>\n",
       "      <td>0.034141</td>\n",
       "      <td>-0.8901</td>\n",
       "      <td>0.0233</td>\n",
       "      <td>-0.8668</td>\n",
       "      <td>63.9631</td>\n",
       "      <td>72.6638</td>\n",
       "      <td>-1.4977</td>\n",
       "      <td>-50.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>72.53</td>\n",
       "      <td>72.53</td>\n",
       "      <td>71.86</td>\n",
       "      <td>72.12</td>\n",
       "      <td>72.12</td>\n",
       "      <td>11953.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.565283</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.2090</td>\n",
       "      <td>-0.064920</td>\n",
       "      <td>0.040363</td>\n",
       "      <td>-0.8959</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>-0.8904</td>\n",
       "      <td>84.5120</td>\n",
       "      <td>81.3646</td>\n",
       "      <td>-1.2910</td>\n",
       "      <td>-50.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    1. open  2. high  3. low  4. close  5. adjusted close  6. volume  \\\n",
       "1     83.48    84.06   83.12     84.05              84.05     1684.0   \n",
       "2     83.50    83.50   83.21     83.28              83.28     1158.0   \n",
       "3     84.26    84.37   83.86     83.86              83.86      754.0   \n",
       "4     83.41    83.72   83.24     83.65              83.65      431.0   \n",
       "5     84.20    84.20   83.01     83.29              83.29      443.0   \n",
       "6     83.21    84.20   83.21     84.04              84.04       60.0   \n",
       "7     82.17    83.75   82.17     83.75              83.75      742.0   \n",
       "8     82.66    83.86   82.66     83.70              83.70      281.0   \n",
       "9     83.50    83.50   82.33     82.65              82.65      657.0   \n",
       "10    83.86    83.86   82.80     82.80              82.80      695.0   \n",
       "11    83.92    84.31   83.53     83.58              83.58      907.0   \n",
       "12    84.96    85.00   83.98     84.18              84.18     1165.0   \n",
       "13    83.95    84.54   83.95     84.54              84.54      733.0   \n",
       "14    82.95    84.62   82.95     84.51              84.51      219.0   \n",
       "15    84.75    84.75   82.84     82.84              82.84      616.0   \n",
       "16    84.72    85.23   84.72     84.85              84.85      776.0   \n",
       "17    85.90    85.90   85.00     85.24              85.24     1162.0   \n",
       "18    85.10    86.00   85.10     86.00              86.00      637.0   \n",
       "19    85.39    85.44   84.86     85.44              85.44      371.0   \n",
       "20    86.70    87.32   84.51     85.40              85.40     2485.0   \n",
       "21    84.99    86.10   84.99     86.00              86.00     1629.0   \n",
       "22    83.45    84.91   83.45     84.63              84.63      970.0   \n",
       "23    83.89    83.89   82.95     83.73              83.73      918.0   \n",
       "24    83.72    83.91   83.61     83.91              83.91      171.0   \n",
       "25    84.59    84.59   83.89     84.16              84.16      670.0   \n",
       "26    84.69    84.69   82.88     83.87              83.87      836.0   \n",
       "27    82.98    84.25   82.98     84.04              84.04      183.0   \n",
       "28    84.09    84.09   83.50     83.50              83.50     1102.0   \n",
       "29    83.16    84.03   83.16     84.03              84.03      293.0   \n",
       "30    83.40    83.40   81.85     82.27              82.27      595.0   \n",
       "31    85.11    85.11   81.56     82.70              82.70     2046.0   \n",
       "32    85.57    85.57   83.38     84.47              84.47    28716.0   \n",
       "33    84.54    85.34   84.54     84.70              84.70    28981.0   \n",
       "34    84.00    84.50   83.46     84.50              84.50    66920.0   \n",
       "35    80.47    82.77   80.47     82.66              82.66    39255.0   \n",
       "36    80.58    80.58   79.57     79.90              79.90    20517.0   \n",
       "37    80.78    80.92   80.27     80.79              80.79    24057.0   \n",
       "38    80.09    81.00   79.38     80.68              80.68    54845.0   \n",
       "39    77.15    79.76   77.15     79.50              79.50    35986.0   \n",
       "40    79.29    79.71   75.39     76.60              76.60    55498.0   \n",
       "41    80.62    80.62   79.77     79.77              79.77    17510.0   \n",
       "42    79.83    81.00   79.83     80.57              80.57    22698.0   \n",
       "43    80.09    80.09   79.11     79.53              79.53    15564.0   \n",
       "44    79.37    79.99   78.18     79.99              79.99    26589.0   \n",
       "45    78.97    79.80   78.92     79.80              79.80    29404.0   \n",
       "46    78.32    79.20   78.29     79.00              79.00    14776.0   \n",
       "47    78.07    78.07   77.35     77.35              77.35    13666.0   \n",
       "48    78.22    78.53   75.99     78.00              78.00     9297.0   \n",
       "49    77.19    77.60   76.67     77.60              77.60     8452.0   \n",
       "50    77.76    78.05   77.16     77.93              77.93    14063.0   \n",
       "51    78.00    78.00   77.12     77.12              77.12    21251.0   \n",
       "52    77.33    78.63   77.33     77.83              77.83    42023.0   \n",
       "53    75.28    76.78   74.85     76.39              76.39    21553.0   \n",
       "54    75.10    76.00   74.53     74.81              74.81    19772.0   \n",
       "55    72.57    74.35   72.30     74.35              74.35    26303.0   \n",
       "56    72.38    73.05   71.50     73.05              73.05    17181.0   \n",
       "57    71.06    72.61   70.43     72.54              72.54    22322.0   \n",
       "58    70.99    73.00   70.62     72.70              72.70    12109.0   \n",
       "59    71.50    71.50   71.50     71.50              71.50     9316.0   \n",
       "60    72.53    72.53   71.86     72.12              72.12    11953.0   \n",
       "\n",
       "    7. dividend amount  8. split coefficient  day_pcent_change  buy_tomorrow  \\\n",
       "1                  0.0                   1.0          0.682798             0   \n",
       "2                  0.0                   1.0         -0.263473             0   \n",
       "3                  0.0                   1.0         -0.474721             0   \n",
       "4                  0.0                   1.0          0.287735             0   \n",
       "5                  0.0                   1.0         -1.080760             0   \n",
       "6                  0.0                   1.0          0.997476             0   \n",
       "7                  0.0                   1.0          1.922843             0   \n",
       "8                  0.0                   1.0          1.258166             1   \n",
       "9                  0.0                   1.0         -1.017964             0   \n",
       "10                 0.0                   1.0         -1.264011             0   \n",
       "11                 0.0                   1.0         -0.405148             0   \n",
       "12                 0.0                   1.0         -0.918079             0   \n",
       "13                 0.0                   1.0          0.702799             0   \n",
       "14                 0.0                   1.0          1.880651             0   \n",
       "15                 0.0                   1.0         -2.253687             1   \n",
       "16                 0.0                   1.0          0.153447             0   \n",
       "17                 0.0                   1.0         -0.768335             0   \n",
       "18                 0.0                   1.0          1.057579             0   \n",
       "19                 0.0                   1.0          0.058555             0   \n",
       "20                 0.0                   1.0         -1.499423             0   \n",
       "21                 0.0                   1.0          1.188375             0   \n",
       "22                 0.0                   1.0          1.414020             0   \n",
       "23                 0.0                   1.0         -0.190726             0   \n",
       "24                 0.0                   1.0          0.226947             0   \n",
       "25                 0.0                   1.0         -0.508334             0   \n",
       "26                 0.0                   1.0         -0.968237             0   \n",
       "27                 0.0                   1.0          1.277416             0   \n",
       "28                 0.0                   1.0         -0.701629             0   \n",
       "29                 0.0                   1.0          1.046176             0   \n",
       "30                 0.0                   1.0         -1.354916             0   \n",
       "31                 0.0                   1.0         -2.831630             0   \n",
       "32                 0.0                   1.0         -1.285497             0   \n",
       "33                 0.0                   1.0          0.189260             0   \n",
       "34                 0.0                   1.0          0.595238             0   \n",
       "35                 0.0                   1.0          2.721511             0   \n",
       "36                 0.0                   1.0         -0.843882             1   \n",
       "37                 0.0                   1.0          0.012379             0   \n",
       "38                 0.0                   1.0          0.736671             0   \n",
       "39                 0.0                   1.0          3.046014             0   \n",
       "40                 0.0                   1.0         -3.392609             1   \n",
       "41                 0.0                   1.0         -1.054329             0   \n",
       "42                 0.0                   1.0          0.926970             0   \n",
       "43                 0.0                   1.0         -0.699213             0   \n",
       "44                 0.0                   1.0          0.781152             0   \n",
       "45                 0.0                   1.0          1.051032             0   \n",
       "46                 0.0                   1.0          0.868233             0   \n",
       "47                 0.0                   1.0         -0.922249             0   \n",
       "48                 0.0                   1.0         -0.281258             0   \n",
       "49                 0.0                   1.0          0.531157             0   \n",
       "50                 0.0                   1.0          0.218621             0   \n",
       "51                 0.0                   1.0         -1.128205             0   \n",
       "52                 0.0                   1.0          0.646580             0   \n",
       "53                 0.0                   1.0          1.474495             0   \n",
       "54                 0.0                   1.0         -0.386152             0   \n",
       "55                 0.0                   1.0          2.452804             0   \n",
       "56                 0.0                   1.0          0.925670             1   \n",
       "57                 0.0                   1.0          2.082747             0   \n",
       "58                 0.0                   1.0          2.408790             1   \n",
       "59                 0.0                   1.0          0.000000             1   \n",
       "60                 0.0                   1.0         -0.565283             0   \n",
       "\n",
       "    ...  bb_lower  pcent_diff_to_bb_upper  pcent_diff_to_bb_lower  \\\n",
       "1   ...   82.2469               -0.022226                0.021453   \n",
       "2   ...   82.1634               -0.035022                0.013408   \n",
       "3   ...   82.2659               -0.028251                0.019009   \n",
       "4   ...   82.2535               -0.030825                0.016695   \n",
       "5   ...   82.2787               -0.035290                0.012142   \n",
       "6   ...   82.3714               -0.025983                0.019855   \n",
       "7   ...   82.3569               -0.029506                0.016634   \n",
       "8   ...   82.3835               -0.030149                0.015729   \n",
       "9   ...   82.3590               -0.043291                0.003521   \n",
       "10  ...   82.5745               -0.040465                0.002723   \n",
       "11  ...   82.4435               -0.031688                0.013598   \n",
       "12  ...   82.2933               -0.025074                0.022413   \n",
       "13  ...   82.3071               -0.020888                0.026412   \n",
       "14  ...   82.3101               -0.021405                0.026031   \n",
       "15  ...   82.3098               -0.041987                0.006400   \n",
       "16  ...   82.2730               -0.017525                0.030371   \n",
       "17  ...   81.2816               -0.018693                0.046438   \n",
       "18  ...   80.7751               -0.010406                0.060755   \n",
       "19  ...   80.3857               -0.015359                0.059156   \n",
       "20  ...   79.7518               -0.016302                0.066138   \n",
       "21  ...   78.4031               -0.014662                0.088336   \n",
       "22  ...   78.1508               -0.026707                0.076559   \n",
       "23  ...   77.9815               -0.034916                0.068655   \n",
       "24  ...   77.6601               -0.031521                0.074483   \n",
       "25  ...   77.4536               -0.026252                0.079686   \n",
       "26  ...   77.2705               -0.026786                0.078687   \n",
       "27  ...   76.9970               -0.022168                0.083805   \n",
       "28  ...   76.4892               -0.026848                0.083962   \n",
       "29  ...   76.1603               -0.017740                0.093653   \n",
       "30  ...   75.8762               -0.035150                0.077717   \n",
       "31  ...   75.6015               -0.027842                0.085834   \n",
       "32  ...   75.2629               -0.003707                0.108998   \n",
       "33  ...   75.3064                0.007372                0.110904   \n",
       "34  ...   75.3138                0.014944                0.108712   \n",
       "35  ...   75.1461                0.002711                0.090901   \n",
       "36  ...   74.6951               -0.026982                0.065143   \n",
       "37  ...   73.7571               -0.018801                0.087052   \n",
       "38  ...   72.9176               -0.020369                0.096212   \n",
       "39  ...   72.2767               -0.033538                0.090859   \n",
       "40  ...   71.4068               -0.073580                0.067796   \n",
       "41  ...   70.8070               -0.032819                0.112361   \n",
       "42  ...   70.2401               -0.019696                0.128210   \n",
       "43  ...   70.0532               -0.025786                0.119160   \n",
       "44  ...   69.4764               -0.016122                0.131436   \n",
       "45  ...   68.8688               -0.013273                0.136982   \n",
       "46  ...   68.2593               -0.017578                0.135958   \n",
       "47  ...   68.2572               -0.030573                0.117554   \n",
       "48  ...   68.0578               -0.016772                0.127464   \n",
       "49  ...   68.0717               -0.013999                0.122787   \n",
       "50  ...   68.0869               -0.001759                0.126307   \n",
       "51  ...   68.3723               -0.004522                0.113430   \n",
       "52  ...   68.5955                0.010876                0.118650   \n",
       "53  ...   68.9859                0.001033                0.096925   \n",
       "54  ...   69.1714               -0.015527                0.075372   \n",
       "55  ...   69.2144               -0.020331                0.069073   \n",
       "56  ...   69.1951               -0.039150                0.052771   \n",
       "57  ...   69.1475               -0.049511                0.046767   \n",
       "58  ...   69.1534               -0.049816                0.048784   \n",
       "59  ...   69.0589               -0.073218                0.034141   \n",
       "60  ...   69.2090               -0.064920                0.040363   \n",
       "\n",
       "    macd_signal  macd_hist    macd  stochrsi_fast_k  stochrsi_fast_d     ppo  \\\n",
       "1        0.4478    -0.1845  0.2634         100.0000          68.6130 -1.2474   \n",
       "2        0.4940    -0.2410  0.2529           0.0000          37.2260 -1.1117   \n",
       "3        0.5542    -0.2399  0.3143          81.1073          74.4519 -0.8960   \n",
       "4        0.6142    -0.2851  0.3291          72.6758          67.7966 -0.7531   \n",
       "5        0.6855    -0.3210  0.3645          44.1339          62.9174 -0.7096   \n",
       "6        0.7657    -0.3247  0.4410         100.0000          81.7008 -0.6703   \n",
       "7        0.8469    -0.3910  0.4559          88.6782          63.4016 -0.7425   \n",
       "8        0.9447    -0.4468  0.4979          67.6404          38.1249 -0.7287   \n",
       "9        1.0563    -0.5071  0.5492           0.0000           8.6094 -0.7640   \n",
       "10       1.1831    -0.4694  0.7137           0.0000          17.2188 -0.7512   \n",
       "11       1.3005    -0.4024  0.8980          28.5771          34.4376 -0.8857   \n",
       "12       1.4011    -0.3603  1.0408          46.3193          40.2982 -1.0026   \n",
       "13       1.4911    -0.3444  1.1468          43.0797          34.2772 -1.1046   \n",
       "14       1.5772    -0.3485  1.2287          42.3920          25.4746 -1.0652   \n",
       "15       1.6644    -0.3459  1.3185           0.0000           8.5572 -1.0609   \n",
       "16       1.7508    -0.1669  1.5839           0.0000          17.1145 -0.9706   \n",
       "17       1.7926    -0.0976  1.6950           0.0000          34.2290 -0.7504   \n",
       "18       1.8170    -0.0446  1.7724          78.1896          68.4580 -0.4977   \n",
       "19       1.8281    -0.0600  1.7681          52.3383          58.7263 -0.3326   \n",
       "20       1.8431    -0.0493  1.7938          50.5261          65.1142 -0.2032   \n",
       "21       1.8554    -0.0508  1.8047         100.0000          79.7023 -0.0140   \n",
       "22       1.8681    -0.1369  1.7312         100.0000          59.4045 -0.0017   \n",
       "23       1.9024    -0.1507  1.7517           0.0000          18.8091  0.4094   \n",
       "24       1.9400    -0.0960  1.8440           7.4191          37.6181  0.8754   \n",
       "25       1.9640    -0.0473  1.9168          85.2159          67.8172  1.1910   \n",
       "26       1.9758    -0.0196  1.9562          65.7970          50.4185  1.3960   \n",
       "27       1.9807     0.0270  2.0077          40.9577          35.0399  1.4416   \n",
       "28       1.9740     0.0529  2.0269          22.8221          29.1220  1.3827   \n",
       "29       1.9608     0.1160  2.0768          44.0919          35.4219  1.4245   \n",
       "30       1.9318     0.1247  2.0564           0.0000          26.7519  1.5793   \n",
       "31       1.9006     0.2791  2.1797          14.9057          53.5039  1.8413   \n",
       "32       1.8308     0.4307  2.2615          89.5151          92.1021  2.0658   \n",
       "33       1.7232     0.4296  2.1528         100.0000          94.6891  2.1899   \n",
       "34       1.6158     0.3436  1.9594         100.0000          89.3782  2.2059   \n",
       "35       1.5298     0.1745  1.7043         100.0000          78.7564  2.2029   \n",
       "36       1.4862     0.0551  1.5413          59.7187          57.5127  2.0583   \n",
       "37       1.4725     0.1195  1.5919          62.9194          55.3067  1.9549   \n",
       "38       1.4426     0.1001  1.5427          61.5570          47.6940  1.8067   \n",
       "39       1.4175     0.0511  1.4687          46.3335          33.8310  1.7504   \n",
       "40       1.4048     0.0682  1.4730           0.0000          21.3284  1.6467   \n",
       "41       1.3877     0.3646  1.7523           0.0000          42.6568  1.5613   \n",
       "42       1.2966     0.4640  1.7605          96.8177          85.3137  1.3673   \n",
       "43       1.1806     0.4834  1.6640          56.9304          73.8096  1.2267   \n",
       "44       1.0597     0.5627  1.6225         100.0000          90.6887  1.0480   \n",
       "45       0.9190     0.5800  1.4990         100.0000          81.3775  0.8923   \n",
       "46       0.7741     0.5649  1.3390         100.0000          62.7550  0.7593   \n",
       "47       0.6328     0.5639  1.1967           0.0000          25.5100  0.3780   \n",
       "48       0.4918     0.6739  1.1658          33.3744          51.0200 -0.1044   \n",
       "49       0.3234     0.7197  1.0431          53.7374          68.6655 -0.4234   \n",
       "50       0.1434     0.7686  0.9120          80.9558          83.5937 -0.7079   \n",
       "51      -0.0487     0.7466  0.6979          72.9086          86.2316 -0.9216   \n",
       "52      -0.2354     0.7323  0.4970         100.0000          99.5545 -1.0976   \n",
       "53      -0.4185     0.5794  0.1609         100.0000          99.1091 -1.1820   \n",
       "54      -0.5633     0.4397 -0.1237         100.0000          98.2181 -1.3139   \n",
       "55      -0.6732     0.3490 -0.3242         100.0000          96.4362 -1.4934   \n",
       "56      -0.7605     0.2318 -0.5287         100.0000          92.8725 -1.7237   \n",
       "57      -0.8184     0.1688 -0.6496          85.4438          85.7449 -1.7408   \n",
       "58      -0.8606     0.1180 -0.7426          99.4282          86.0460 -1.6241   \n",
       "59      -0.8901     0.0233 -0.8668          63.9631          72.6638 -1.4977   \n",
       "60      -0.8959     0.0055 -0.8904          84.5120          81.3646 -1.2910   \n",
       "\n",
       "       aroon  \n",
       "1   -35.7143  \n",
       "2   -64.2857  \n",
       "3   -71.4286  \n",
       "4   -78.5714  \n",
       "5   -78.5714  \n",
       "6   -92.8571  \n",
       "7   -92.8571  \n",
       "8   -78.5714  \n",
       "9   -78.5714  \n",
       "10  -71.4286  \n",
       "11  -35.7143  \n",
       "12  -35.7143  \n",
       "13  -35.7143  \n",
       "14  -35.7142  \n",
       "15  -35.7143  \n",
       "16   71.4286  \n",
       "17   78.5714  \n",
       "18   78.5714  \n",
       "19   78.5714  \n",
       "20   78.5714  \n",
       "21  100.0000  \n",
       "22   28.5714  \n",
       "23   28.5714  \n",
       "24   42.8571  \n",
       "25   50.0000  \n",
       "26   57.1429  \n",
       "27   57.1428  \n",
       "28   57.1429  \n",
       "29   57.1428  \n",
       "30   57.1429  \n",
       "31   57.1428  \n",
       "32   57.1429  \n",
       "33   50.0000  \n",
       "34   42.8571  \n",
       "35   35.7143  \n",
       "36   14.2857  \n",
       "37   14.2857  \n",
       "38   14.2857  \n",
       "39   78.5714  \n",
       "40   85.7143  \n",
       "41   92.8571  \n",
       "42  100.0000  \n",
       "43  100.0000  \n",
       "44   92.8571  \n",
       "45   85.7143  \n",
       "46   78.5714  \n",
       "47   35.7143  \n",
       "48   35.7143  \n",
       "49   78.5714  \n",
       "50   78.5714  \n",
       "51   92.8571  \n",
       "52   92.8571  \n",
       "53   85.7143  \n",
       "54   78.5714  \n",
       "55   71.4286  \n",
       "56  -35.7143  \n",
       "57  -42.8571  \n",
       "58  -50.0000  \n",
       "59  -50.0000  \n",
       "60  -50.0000  \n",
       "\n",
       "[60 rows x 32 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = final_data.iloc[1: , :]\n",
    "final_data.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "598d7355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. adjusted close</th>\n",
       "      <th>6. volume</th>\n",
       "      <th>7. dividend amount</th>\n",
       "      <th>8. split coefficient</th>\n",
       "      <th>day_pcent_change</th>\n",
       "      <th>buy_tomorrow</th>\n",
       "      <th>...</th>\n",
       "      <th>bb_lower</th>\n",
       "      <th>pcent_diff_to_bb_upper</th>\n",
       "      <th>pcent_diff_to_bb_lower</th>\n",
       "      <th>macd_signal</th>\n",
       "      <th>macd_hist</th>\n",
       "      <th>macd</th>\n",
       "      <th>stochrsi_fast_k</th>\n",
       "      <th>stochrsi_fast_d</th>\n",
       "      <th>ppo</th>\n",
       "      <th>aroon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4491.000000</td>\n",
       "      <td>4491.000000</td>\n",
       "      <td>4491.000000</td>\n",
       "      <td>4491.000000</td>\n",
       "      <td>4491.000000</td>\n",
       "      <td>4.491000e+03</td>\n",
       "      <td>4491.000000</td>\n",
       "      <td>4491.0</td>\n",
       "      <td>4491.000000</td>\n",
       "      <td>4491.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4491.000000</td>\n",
       "      <td>4491.000000</td>\n",
       "      <td>4491.000000</td>\n",
       "      <td>4491.000000</td>\n",
       "      <td>4491.000000</td>\n",
       "      <td>4491.000000</td>\n",
       "      <td>4491.000000</td>\n",
       "      <td>4491.000000</td>\n",
       "      <td>4491.000000</td>\n",
       "      <td>4491.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>64.003856</td>\n",
       "      <td>64.672381</td>\n",
       "      <td>63.269501</td>\n",
       "      <td>64.005611</td>\n",
       "      <td>51.955327</td>\n",
       "      <td>1.066142e+05</td>\n",
       "      <td>0.007108</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.025091</td>\n",
       "      <td>0.154309</td>\n",
       "      <td>...</td>\n",
       "      <td>48.911475</td>\n",
       "      <td>0.169053</td>\n",
       "      <td>0.262175</td>\n",
       "      <td>0.096210</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.096640</td>\n",
       "      <td>51.108658</td>\n",
       "      <td>51.106294</td>\n",
       "      <td>0.188003</td>\n",
       "      <td>5.724146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21.952144</td>\n",
       "      <td>22.090183</td>\n",
       "      <td>21.765651</td>\n",
       "      <td>21.938207</td>\n",
       "      <td>22.406856</td>\n",
       "      <td>2.337421e+05</td>\n",
       "      <td>0.139798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.726053</td>\n",
       "      <td>0.361285</td>\n",
       "      <td>...</td>\n",
       "      <td>21.406853</td>\n",
       "      <td>0.143309</td>\n",
       "      <td>0.127314</td>\n",
       "      <td>0.996443</td>\n",
       "      <td>0.329746</td>\n",
       "      <td>1.062502</td>\n",
       "      <td>40.765792</td>\n",
       "      <td>31.346277</td>\n",
       "      <td>2.387513</td>\n",
       "      <td>63.800152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.500000</td>\n",
       "      <td>17.905000</td>\n",
       "      <td>16.115000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>11.657600</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-12.293578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.639000</td>\n",
       "      <td>-0.734486</td>\n",
       "      <td>-0.054526</td>\n",
       "      <td>-5.475400</td>\n",
       "      <td>-2.165500</td>\n",
       "      <td>-6.347100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110700</td>\n",
       "      <td>-15.330200</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>43.415000</td>\n",
       "      <td>43.825000</td>\n",
       "      <td>42.862500</td>\n",
       "      <td>43.420000</td>\n",
       "      <td>28.253000</td>\n",
       "      <td>2.056950e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.881415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>26.789400</td>\n",
       "      <td>0.062040</td>\n",
       "      <td>0.156633</td>\n",
       "      <td>-0.392400</td>\n",
       "      <td>-0.175950</td>\n",
       "      <td>-0.421700</td>\n",
       "      <td>2.335900</td>\n",
       "      <td>21.741800</td>\n",
       "      <td>-1.113500</td>\n",
       "      <td>-57.142800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>68.611000</td>\n",
       "      <td>69.350000</td>\n",
       "      <td>67.850000</td>\n",
       "      <td>68.860000</td>\n",
       "      <td>57.080000</td>\n",
       "      <td>3.910600e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>53.003700</td>\n",
       "      <td>0.204050</td>\n",
       "      <td>0.292095</td>\n",
       "      <td>0.113100</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.096300</td>\n",
       "      <td>52.198400</td>\n",
       "      <td>51.214800</td>\n",
       "      <td>0.244500</td>\n",
       "      <td>21.428600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.300000</td>\n",
       "      <td>83.140000</td>\n",
       "      <td>81.432500</td>\n",
       "      <td>82.270000</td>\n",
       "      <td>70.851150</td>\n",
       "      <td>9.635400e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>67.686600</td>\n",
       "      <td>0.286234</td>\n",
       "      <td>0.370362</td>\n",
       "      <td>0.615900</td>\n",
       "      <td>0.169950</td>\n",
       "      <td>0.646600</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>80.588900</td>\n",
       "      <td>1.696750</td>\n",
       "      <td>64.285700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>122.890000</td>\n",
       "      <td>123.699000</td>\n",
       "      <td>120.225000</td>\n",
       "      <td>122.998000</td>\n",
       "      <td>99.650000</td>\n",
       "      <td>5.277522e+06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.092245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>91.049500</td>\n",
       "      <td>0.382821</td>\n",
       "      <td>0.547382</td>\n",
       "      <td>3.382800</td>\n",
       "      <td>1.468500</td>\n",
       "      <td>3.612900</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.996200</td>\n",
       "      <td>6.647600</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1. open      2. high       3. low     4. close  5. adjusted close  \\\n",
       "count  4491.000000  4491.000000  4491.000000  4491.000000        4491.000000   \n",
       "mean     64.003856    64.672381    63.269501    64.005611          51.955327   \n",
       "std      21.952144    22.090183    21.765651    21.938207          22.406856   \n",
       "min      17.500000    17.905000    16.115000    17.400000          11.657600   \n",
       "25%      43.415000    43.825000    42.862500    43.420000          28.253000   \n",
       "50%      68.611000    69.350000    67.850000    68.860000          57.080000   \n",
       "75%      82.300000    83.140000    81.432500    82.270000          70.851150   \n",
       "max     122.890000   123.699000   120.225000   122.998000          99.650000   \n",
       "\n",
       "          6. volume  7. dividend amount  8. split coefficient  \\\n",
       "count  4.491000e+03         4491.000000                4491.0   \n",
       "mean   1.066142e+05            0.007108                   1.0   \n",
       "std    2.337421e+05            0.139798                   0.0   \n",
       "min    0.000000e+00            0.000000                   1.0   \n",
       "25%    2.056950e+04            0.000000                   1.0   \n",
       "50%    3.910600e+04            0.000000                   1.0   \n",
       "75%    9.635400e+04            0.000000                   1.0   \n",
       "max    5.277522e+06            4.000000                   1.0   \n",
       "\n",
       "       day_pcent_change  buy_tomorrow  ...     bb_lower  \\\n",
       "count       4491.000000   4491.000000  ...  4491.000000   \n",
       "mean           0.025091      0.154309  ...    48.911475   \n",
       "std            1.726053      0.361285  ...    21.406853   \n",
       "min          -12.293578      0.000000  ...    10.639000   \n",
       "25%           -0.881415      0.000000  ...    26.789400   \n",
       "50%            0.040239      0.000000  ...    53.003700   \n",
       "75%            0.928003      0.000000  ...    67.686600   \n",
       "max           16.092245      1.000000  ...    91.049500   \n",
       "\n",
       "       pcent_diff_to_bb_upper  pcent_diff_to_bb_lower  macd_signal  \\\n",
       "count             4491.000000             4491.000000  4491.000000   \n",
       "mean                 0.169053                0.262175     0.096210   \n",
       "std                  0.143309                0.127314     0.996443   \n",
       "min                 -0.734486               -0.054526    -5.475400   \n",
       "25%                  0.062040                0.156633    -0.392400   \n",
       "50%                  0.204050                0.292095     0.113100   \n",
       "75%                  0.286234                0.370362     0.615900   \n",
       "max                  0.382821                0.547382     3.382800   \n",
       "\n",
       "         macd_hist         macd  stochrsi_fast_k  stochrsi_fast_d  \\\n",
       "count  4491.000000  4491.000000      4491.000000      4491.000000   \n",
       "mean      0.000430     0.096640        51.108658        51.106294   \n",
       "std       0.329746     1.062502        40.765792        31.346277   \n",
       "min      -2.165500    -6.347100         0.000000         0.110700   \n",
       "25%      -0.175950    -0.421700         2.335900        21.741800   \n",
       "50%       0.005600     0.096300        52.198400        51.214800   \n",
       "75%       0.169950     0.646600       100.000000        80.588900   \n",
       "max       1.468500     3.612900       100.000000        99.996200   \n",
       "\n",
       "               ppo        aroon  \n",
       "count  4491.000000  4491.000000  \n",
       "mean      0.188003     5.724146  \n",
       "std       2.387513    63.800152  \n",
       "min     -15.330200  -100.000000  \n",
       "25%      -1.113500   -57.142800  \n",
       "50%       0.244500    21.428600  \n",
       "75%       1.696750    64.285700  \n",
       "max       6.647600   100.000000  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4d9bc0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = final_data\n",
    "label = 'buy_tomorrow'\n",
    "save_path = './autogluon_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "0390bb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogluon_models\"\n",
      "Presets specified: ['best_quality']\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{'auto_stack': True, 'num_bag_folds': 20, 'num_stack_levels': 3}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': True,\n",
      " 'calibrate': 'auto',\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'keep_only_best': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': 20,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': 3,\n",
      " 'pseudo_data': None,\n",
      " 'refit_full': False,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Stack configuration (auto_stack=True): num_stack_levels=3, num_bag_folds=20, num_bag_sets=20\n",
      "Saving ./autogluon_models/learner.pkl\n",
      "Saving ./autogluon_models/predictor.pkl\n",
      "Beginning AutoGluon training ... Time limit = 15000s\n",
      "AutoGluon will save models to \"./autogluon_models/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Mar 2 19:14:12 UTC 2022\n",
      "Train Data Rows:    4487\n",
      "Train Data Columns: 28\n",
      "Label Column: buy_tomorrow\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29404.9 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t27 features in original data used to generate 27 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t27 features in original data used to generate 27 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t27 features in original data used to generate 27 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t27 features in original data used to generate 27 features in processed data.\n",
      "\tUseless Original Features (Count: 1): ['8. split coefficient']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t27 features in original data used to generate 27 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'precision'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving ./autogluon_models/learner.pkl\n",
      "Saving ./autogluon_models/utils/data/X.pkl\n",
      "Saving ./autogluon_models/utils/data/y.pkl\n",
      "AutoGluon will fit 4 stack levels (L1 to L4) ...\n",
      "Model configs that will be trained (in order):\n",
      "\tKNeighborsUnif_BAG_L1: \t{'weights': 'uniform', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Unif', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tKNeighborsDist_BAG_L1: \t{'weights': 'distance', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Dist', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tRandomForestEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tExtraTreesEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 4998.72s of the 14999.91s of remaining time.\n",
      "\tFitting KNeighborsUnif_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/KNeighborsUnif_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsUnif_BAG_L1/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/KNeighborsUnif_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "\t0.152\t = Validation score   (precision)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.71s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 4997.96s of the 14999.15s of remaining time.\n",
      "\tFitting KNeighborsDist_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/KNeighborsDist_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsDist_BAG_L1/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/KNeighborsDist_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "\t0.1228\t = Validation score   (precision)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 4997.31s of the 14998.5s of remaining time.\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.4651\t = Validation score   (precision)\n",
      "\t15.61s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 4978.71s of the 14979.9s of remaining time.\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.5577\t = Validation score   (precision)\n",
      "\t17.65s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 4957.84s of the 14959.03s of remaining time.\n",
      "\tFitting RandomForestGini_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/RandomForestGini_BAG_L1/model.pkl\n",
      "\t0.2245\t = Validation score   (precision)\n",
      "\t1.3s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 4955.09s of the 14956.28s of remaining time.\n",
      "\tFitting RandomForestEntr_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/RandomForestEntr_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L1/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "\t0.2088\t = Validation score   (precision)\n",
      "\t2.1s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 4951.76s of the 14952.94s of remaining time.\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/CatBoost_BAG_L1/model.pkl\n",
      "\t1.0\t = Validation score   (precision)\n",
      "\t19.76s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 4929.06s of the 14930.25s of remaining time.\n",
      "\tFitting ExtraTreesGini_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/ExtraTreesGini_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L1/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "\t0.1809\t = Validation score   (precision)\n",
      "\t0.91s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 4925.94s of the 14927.13s of remaining time.\n",
      "\tFitting ExtraTreesEntr_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/ExtraTreesEntr_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L1/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "\t0.2024\t = Validation score   (precision)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 4922.99s of the 14924.18s of remaining time.\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t0.3681\t = Validation score   (precision)\n",
      "\t30.3s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 4889.7s of the 14890.89s of remaining time.\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.4769\t = Validation score   (precision)\n",
      "\t31.95s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 4854.45s of the 14855.64s of remaining time.\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving ./autogluon_models/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t0.0\t = Validation score   (precision)\n",
      "\t23.86s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 4827.57s of the 14828.76s of remaining time.\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.4912\t = Validation score   (precision)\n",
      "\t36.72s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Repeating k-fold bagging: 2/20\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 4787.34s of the 14788.53s of remaining time.\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L1/model.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 4787.33s of the 14788.52s of remaining time.\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L1/model.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 4787.32s of the 14788.51s of remaining time.\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 4787.31s of the 14788.5s of remaining time.\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L1/model.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 4787.31s of the 14788.5s of remaining time.\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 4787.3s of the 14788.49s of remaining time.\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 4787.29s of the 14788.48s of remaining time.\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Repeating k-fold bagging: 3/20\n",
      "Repeating k-fold bagging: 4/20\n",
      "Repeating k-fold bagging: 5/20\n",
      "Repeating k-fold bagging: 6/20\n",
      "Repeating k-fold bagging: 7/20\n",
      "Repeating k-fold bagging: 8/20\n",
      "Repeating k-fold bagging: 9/20\n",
      "Repeating k-fold bagging: 10/20\n",
      "Repeating k-fold bagging: 11/20\n",
      "Repeating k-fold bagging: 12/20\n",
      "Repeating k-fold bagging: 13/20\n",
      "Repeating k-fold bagging: 14/20\n",
      "Repeating k-fold bagging: 15/20\n",
      "Repeating k-fold bagging: 16/20\n",
      "Repeating k-fold bagging: 17/20\n",
      "Repeating k-fold bagging: 18/20\n",
      "Repeating k-fold bagging: 19/20\n",
      "Repeating k-fold bagging: 20/20\n",
      "Completed 20/20 k-fold bagging repeats ...\n",
      "Loading: ./autogluon_models/models/KNeighborsUnif_BAG_L1/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsDist_BAG_L1/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 499.87s of the 14788.45s of remaining time.\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 16\n",
      "Ensemble weights: \n",
      "[0.25   0.125  0.3125 0.25   0.     0.0625]\n",
      "Saving ./autogluon_models/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/WeightedEnsemble_L2/model.pkl\n",
      "\t0.2667\t = Validation score   (precision)\n",
      "\t1.9s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestGini_BAG_L2: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tRandomForestEntr_BAG_L2: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesGini_BAG_L2: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tExtraTreesEntr_BAG_L2: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 11 L2 models ...\n",
      "Loading: ./autogluon_models/models/KNeighborsUnif_BAG_L1/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsDist_BAG_L1/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 6570.14s of the 14786.5s of remaining time.\n",
      "\tFitting LightGBMXT_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/LightGBMXT_BAG_L2/model.pkl\n",
      "\t0.6552\t = Validation score   (precision)\n",
      "\t17.06s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 6549.98s of the 14766.34s of remaining time.\n",
      "\tFitting LightGBM_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/LightGBM_BAG_L2/model.pkl\n",
      "\t0.7586\t = Validation score   (precision)\n",
      "\t19.51s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 6527.29s of the 14743.64s of remaining time.\n",
      "\tFitting RandomForestGini_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/RandomForestGini_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L2/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/RandomForestGini_BAG_L2/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/RandomForestGini_BAG_L2/model.pkl\n",
      "\t0.3438\t = Validation score   (precision)\n",
      "\t1.42s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 6525.53s of the 14741.89s of remaining time.\n",
      "\tFitting RandomForestEntr_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/RandomForestEntr_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L2/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/RandomForestEntr_BAG_L2/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/RandomForestEntr_BAG_L2/model.pkl\n",
      "\t0.5556\t = Validation score   (precision)\n",
      "\t2.0s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 6523.19s of the 14739.55s of remaining time.\n",
      "\tFitting CatBoost_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving ./autogluon_models/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/CatBoost_BAG_L2/model.pkl\n",
      "\t0.0\t = Validation score   (precision)\n",
      "\t21.64s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 6498.55s of the 14714.91s of remaining time.\n",
      "\tFitting ExtraTreesGini_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/ExtraTreesGini_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L2/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/ExtraTreesGini_BAG_L2/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/ExtraTreesGini_BAG_L2/model.pkl\n",
      "\t0.4545\t = Validation score   (precision)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 6497.5s of the 14713.86s of remaining time.\n",
      "\tFitting ExtraTreesEntr_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/ExtraTreesEntr_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L2/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/ExtraTreesEntr_BAG_L2/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/ExtraTreesEntr_BAG_L2/model.pkl\n",
      "\t0.5455\t = Validation score   (precision)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 6496.34s of the 14712.7s of remaining time.\n",
      "\tFitting NeuralNetFastAI_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "\t0.5921\t = Validation score   (precision)\n",
      "\t32.61s\t = Training   runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 6460.68s of the 14677.04s of remaining time.\n",
      "\tFitting XGBoost_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/XGBoost_BAG_L2/model.pkl\n",
      "\t0.6471\t = Validation score   (precision)\n",
      "\t30.7s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 6426.74s of the 14643.1s of remaining time.\n",
      "\tFitting NeuralNetTorch_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "\t0.0\t = Validation score   (precision)\n",
      "\t23.98s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 6399.68s of the 14616.04s of remaining time.\n",
      "\tFitting LightGBMLarge_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "\t0.6875\t = Validation score   (precision)\n",
      "\t44.38s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Repeating k-fold bagging: 2/20\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 6351.84s of the 14568.2s of remaining time.\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L2/model.pkl\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 6351.83s of the 14568.18s of remaining time.\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L2/model.pkl\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 6351.81s of the 14568.17s of remaining time.\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "\tWarning: Exception caused CatBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 6351.8s of the 14568.16s of remaining time.\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L2/model.pkl\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 6351.79s of the 14568.15s of remaining time.\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 6351.78s of the 14568.13s of remaining time.\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 6351.77s of the 14568.12s of remaining time.\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Repeating k-fold bagging: 3/20\n",
      "Repeating k-fold bagging: 4/20\n",
      "Repeating k-fold bagging: 5/20\n",
      "Repeating k-fold bagging: 6/20\n",
      "Repeating k-fold bagging: 7/20\n",
      "Repeating k-fold bagging: 8/20\n",
      "Repeating k-fold bagging: 9/20\n",
      "Repeating k-fold bagging: 10/20\n",
      "Repeating k-fold bagging: 11/20\n",
      "Repeating k-fold bagging: 12/20\n",
      "Repeating k-fold bagging: 13/20\n",
      "Repeating k-fold bagging: 14/20\n",
      "Repeating k-fold bagging: 15/20\n",
      "Repeating k-fold bagging: 16/20\n",
      "Repeating k-fold bagging: 17/20\n",
      "Repeating k-fold bagging: 18/20\n",
      "Repeating k-fold bagging: 19/20\n",
      "Repeating k-fold bagging: 20/20\n",
      "Completed 20/20 k-fold bagging repeats ...\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L2/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L2/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L2/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L2/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L3: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 657.01s of the 14568.1s of remaining time.\n",
      "\tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "Ensemble size: 14\n",
      "Ensemble weights: \n",
      "[0.07142857 0.92857143 0.         0.        ]\n",
      "Saving ./autogluon_models/models/WeightedEnsemble_L3/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/WeightedEnsemble_L3/model.pkl\n",
      "\t0.5769\t = Validation score   (precision)\n",
      "\t1.29s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L3: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestGini_BAG_L3: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tRandomForestEntr_BAG_L3: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesGini_BAG_L3: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tExtraTreesEntr_BAG_L3: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L3: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 11 L3 models ...\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L2/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L2/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L2/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L2/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 9708.76s of the 14566.77s of remaining time.\n",
      "\tFitting LightGBMXT_BAG_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/LightGBMXT_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L3/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/LightGBMXT_BAG_L3/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/LightGBMXT_BAG_L3/model.pkl\n",
      "\t0.5\t = Validation score   (precision)\n",
      "\t16.83s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L3 ... Training model for up to 9688.82s of the 14546.83s of remaining time.\n",
      "\tFitting LightGBM_BAG_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/LightGBM_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L3/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/LightGBM_BAG_L3/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/LightGBM_BAG_L3/model.pkl\n",
      "\t0.5738\t = Validation score   (precision)\n",
      "\t17.29s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: RandomForestGini_BAG_L3 ... Training model for up to 9668.38s of the 14526.39s of remaining time.\n",
      "\tFitting RandomForestGini_BAG_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/RandomForestGini_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L3/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/RandomForestGini_BAG_L3/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/RandomForestGini_BAG_L3/model.pkl\n",
      "\t0.3412\t = Validation score   (precision)\n",
      "\t1.61s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: RandomForestEntr_BAG_L3 ... Training model for up to 9666.43s of the 14524.44s of remaining time.\n",
      "\tFitting RandomForestEntr_BAG_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/RandomForestEntr_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L3/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/RandomForestEntr_BAG_L3/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/RandomForestEntr_BAG_L3/model.pkl\n",
      "\t0.3425\t = Validation score   (precision)\n",
      "\t2.11s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L3 ... Training model for up to 9663.99s of the 14521.99s of remaining time.\n",
      "\tFitting CatBoost_BAG_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/CatBoost_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L3/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/CatBoost_BAG_L3/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/CatBoost_BAG_L3/model.pkl\n",
      "\t0.3333\t = Validation score   (precision)\n",
      "\t22.64s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: ExtraTreesGini_BAG_L3 ... Training model for up to 9638.34s of the 14496.34s of remaining time.\n",
      "\tFitting ExtraTreesGini_BAG_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/ExtraTreesGini_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L3/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/ExtraTreesGini_BAG_L3/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/ExtraTreesGini_BAG_L3/model.pkl\n",
      "\t0.3291\t = Validation score   (precision)\n",
      "\t0.9s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: ExtraTreesEntr_BAG_L3 ... Training model for up to 9637.07s of the 14495.08s of remaining time.\n",
      "\tFitting ExtraTreesEntr_BAG_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/ExtraTreesEntr_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L3/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/ExtraTreesEntr_BAG_L3/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/ExtraTreesEntr_BAG_L3/model.pkl\n",
      "\t0.3429\t = Validation score   (precision)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L3 ... Training model for up to 9636.02s of the 14494.03s of remaining time.\n",
      "\tFitting NeuralNetFastAI_BAG_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/NeuralNetFastAI_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L3/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/NeuralNetFastAI_BAG_L3/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "\t0.5269\t = Validation score   (precision)\n",
      "\t31.64s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L3 ... Training model for up to 9601.33s of the 14459.33s of remaining time.\n",
      "\tFitting XGBoost_BAG_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/XGBoost_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L3/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/XGBoost_BAG_L3/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/XGBoost_BAG_L3/model.pkl\n",
      "\t0.5222\t = Validation score   (precision)\n",
      "\t28.81s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L3 ... Training model for up to 9569.27s of the 14427.27s of remaining time.\n",
      "\tFitting NeuralNetTorch_BAG_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/NeuralNetTorch_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L3/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/NeuralNetTorch_BAG_L3/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "\t0.0526\t = Validation score   (precision)\n",
      "\t24.44s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L3 ... Training model for up to 9541.75s of the 14399.76s of remaining time.\n",
      "\tFitting LightGBMLarge_BAG_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/LightGBMLarge_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L3/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/LightGBMLarge_BAG_L3/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "\t0.5455\t = Validation score   (precision)\n",
      "\t35.69s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Repeating k-fold bagging: 2/20\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 9502.82s of the 14360.83s of remaining time.\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L3/utils/model_template.pkl\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L3 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L3/model.pkl\n",
      "Fitting model: LightGBM_BAG_L3 ... Training model for up to 9502.81s of the 14360.82s of remaining time.\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L3/utils/model_template.pkl\n",
      "\tWarning: Exception caused LightGBM_BAG_L3 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L3/model.pkl\n",
      "Fitting model: CatBoost_BAG_L3 ... Training model for up to 9502.8s of the 14360.81s of remaining time.\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L3/utils/model_template.pkl\n",
      "\tWarning: Exception caused CatBoost_BAG_L3 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L3 ... Training model for up to 9502.79s of the 14360.8s of remaining time.\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L3/utils/model_template.pkl\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L3 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L3/model.pkl\n",
      "Fitting model: XGBoost_BAG_L3 ... Training model for up to 9502.78s of the 14360.79s of remaining time.\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L3/utils/model_template.pkl\n",
      "\tWarning: Exception caused XGBoost_BAG_L3 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L3 ... Training model for up to 9502.77s of the 14360.77s of remaining time.\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L3/utils/model_template.pkl\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L3 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L3 ... Training model for up to 9502.76s of the 14360.76s of remaining time.\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L3/utils/model_template.pkl\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L3 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Repeating k-fold bagging: 3/20\n",
      "Repeating k-fold bagging: 4/20\n",
      "Repeating k-fold bagging: 5/20\n",
      "Repeating k-fold bagging: 6/20\n",
      "Repeating k-fold bagging: 7/20\n",
      "Repeating k-fold bagging: 8/20\n",
      "Repeating k-fold bagging: 9/20\n",
      "Repeating k-fold bagging: 10/20\n",
      "Repeating k-fold bagging: 11/20\n",
      "Repeating k-fold bagging: 12/20\n",
      "Repeating k-fold bagging: 13/20\n",
      "Repeating k-fold bagging: 14/20\n",
      "Repeating k-fold bagging: 15/20\n",
      "Repeating k-fold bagging: 16/20\n",
      "Repeating k-fold bagging: 17/20\n",
      "Repeating k-fold bagging: 18/20\n",
      "Repeating k-fold bagging: 19/20\n",
      "Repeating k-fold bagging: 20/20\n",
      "Completed 20/20 k-fold bagging repeats ...\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L3/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L3/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L3/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L3/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L4: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L4 ... Training model for up to 970.88s of the 14360.74s of remaining time.\n",
      "\tFitting WeightedEnsemble_L4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/WeightedEnsemble_L4/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L4/utils/model_template.pkl\n",
      "Ensemble size: 12\n",
      "Ensemble weights: \n",
      "[0.08333333 0.16666667 0.         0.75      ]\n",
      "Saving ./autogluon_models/models/WeightedEnsemble_L4/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/WeightedEnsemble_L4/model.pkl\n",
      "\t0.3443\t = Validation score   (precision)\n",
      "\t1.27s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L4: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestGini_BAG_L4: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tRandomForestEntr_BAG_L4: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesGini_BAG_L4: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tExtraTreesEntr_BAG_L4: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L4: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 11 L4 models ...\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L3/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L3/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L3/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L3/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L4 ... Training model for up to 14359.34s of the 14359.33s of remaining time.\n",
      "\tFitting LightGBMXT_BAG_L4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/LightGBMXT_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L4/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/LightGBMXT_BAG_L4/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/LightGBMXT_BAG_L4/model.pkl\n",
      "\t0.6552\t = Validation score   (precision)\n",
      "\t16.7s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L4 ... Training model for up to 14339.58s of the 14339.57s of remaining time.\n",
      "\tFitting LightGBM_BAG_L4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/LightGBM_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L4/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/LightGBM_BAG_L4/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/LightGBM_BAG_L4/model.pkl\n",
      "\t0.6\t = Validation score   (precision)\n",
      "\t20.94s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: RandomForestGini_BAG_L4 ... Training model for up to 14315.54s of the 14315.52s of remaining time.\n",
      "\tFitting RandomForestGini_BAG_L4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/RandomForestGini_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L4/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/RandomForestGini_BAG_L4/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/RandomForestGini_BAG_L4/model.pkl\n",
      "\t0.3571\t = Validation score   (precision)\n",
      "\t1.4s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: RandomForestEntr_BAG_L4 ... Training model for up to 14313.79s of the 14313.78s of remaining time.\n",
      "\tFitting RandomForestEntr_BAG_L4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/RandomForestEntr_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L4/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/RandomForestEntr_BAG_L4/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/RandomForestEntr_BAG_L4/model.pkl\n",
      "\t0.38\t = Validation score   (precision)\n",
      "\t2.11s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L4 ... Training model for up to 14311.36s of the 14311.34s of remaining time.\n",
      "\tFitting CatBoost_BAG_L4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/CatBoost_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L4/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/CatBoost_BAG_L4/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/CatBoost_BAG_L4/model.pkl\n",
      "\t0.2857\t = Validation score   (precision)\n",
      "\t21.33s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: ExtraTreesGini_BAG_L4 ... Training model for up to 14287.04s of the 14287.03s of remaining time.\n",
      "\tFitting ExtraTreesGini_BAG_L4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/ExtraTreesGini_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L4/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/ExtraTreesGini_BAG_L4/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/ExtraTreesGini_BAG_L4/model.pkl\n",
      "\t0.3721\t = Validation score   (precision)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: ExtraTreesEntr_BAG_L4 ... Training model for up to 14285.8s of the 14285.79s of remaining time.\n",
      "\tFitting ExtraTreesEntr_BAG_L4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/ExtraTreesEntr_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L4/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/ExtraTreesEntr_BAG_L4/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/ExtraTreesEntr_BAG_L4/model.pkl\n",
      "\t0.3714\t = Validation score   (precision)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L4 ... Training model for up to 14284.75s of the 14284.73s of remaining time.\n",
      "\tFitting NeuralNetFastAI_BAG_L4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/NeuralNetFastAI_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L4/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/NeuralNetFastAI_BAG_L4/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "\t0.625\t = Validation score   (precision)\n",
      "\t31.66s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L4 ... Training model for up to 14250.03s of the 14250.02s of remaining time.\n",
      "\tFitting XGBoost_BAG_L4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/XGBoost_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L4/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/XGBoost_BAG_L4/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/XGBoost_BAG_L4/model.pkl\n",
      "\t0.6818\t = Validation score   (precision)\n",
      "\t28.89s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L4 ... Training model for up to 14217.84s of the 14217.83s of remaining time.\n",
      "\tFitting NeuralNetTorch_BAG_L4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/NeuralNetTorch_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L4/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/NeuralNetTorch_BAG_L4/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "\t0.0\t = Validation score   (precision)\n",
      "\t24.19s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L4 ... Training model for up to 14190.47s of the 14190.46s of remaining time.\n",
      "\tFitting LightGBMLarge_BAG_L4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/LightGBMLarge_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L4/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/LightGBMLarge_BAG_L4/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "\t0.619\t = Validation score   (precision)\n",
      "\t40.94s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Repeating k-fold bagging: 2/20\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L4/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L4 ... Training model for up to 14146.08s of the 14146.07s of remaining time.\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L4/utils/model_template.pkl\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L4 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L4/model.pkl\n",
      "Fitting model: LightGBM_BAG_L4 ... Training model for up to 14146.07s of the 14146.06s of remaining time.\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L4/utils/model_template.pkl\n",
      "\tWarning: Exception caused LightGBM_BAG_L4 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L4/model.pkl\n",
      "Fitting model: CatBoost_BAG_L4 ... Training model for up to 14146.06s of the 14146.05s of remaining time.\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L4/utils/model_template.pkl\n",
      "\tWarning: Exception caused CatBoost_BAG_L4 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L4 ... Training model for up to 14146.05s of the 14146.03s of remaining time.\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L4/utils/model_template.pkl\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L4 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L4/model.pkl\n",
      "Fitting model: XGBoost_BAG_L4 ... Training model for up to 14146.04s of the 14146.02s of remaining time.\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L4/utils/model_template.pkl\n",
      "\tWarning: Exception caused XGBoost_BAG_L4 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L4 ... Training model for up to 14146.03s of the 14146.01s of remaining time.\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L4/utils/model_template.pkl\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L4 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L4 ... Training model for up to 14146.01s of the 14146.0s of remaining time.\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L4/utils/model_template.pkl\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L4 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Repeating k-fold bagging: 3/20\n",
      "Repeating k-fold bagging: 4/20\n",
      "Repeating k-fold bagging: 5/20\n",
      "Repeating k-fold bagging: 6/20\n",
      "Repeating k-fold bagging: 7/20\n",
      "Repeating k-fold bagging: 8/20\n",
      "Repeating k-fold bagging: 9/20\n",
      "Repeating k-fold bagging: 10/20\n",
      "Repeating k-fold bagging: 11/20\n",
      "Repeating k-fold bagging: 12/20\n",
      "Repeating k-fold bagging: 13/20\n",
      "Repeating k-fold bagging: 14/20\n",
      "Repeating k-fold bagging: 15/20\n",
      "Repeating k-fold bagging: 16/20\n",
      "Repeating k-fold bagging: 17/20\n",
      "Repeating k-fold bagging: 18/20\n",
      "Repeating k-fold bagging: 19/20\n",
      "Repeating k-fold bagging: 20/20\n",
      "Completed 20/20 k-fold bagging repeats ...\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L4/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L4/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L4/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L4/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L5: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L5 ... Training model for up to 1435.93s of the 14145.97s of remaining time.\n",
      "\tFitting WeightedEnsemble_L5 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/WeightedEnsemble_L5/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L5/utils/model_template.pkl\n",
      "Ensemble size: 3\n",
      "Ensemble weights: \n",
      "[0.         0.33333333 0.         0.66666667]\n",
      "Saving ./autogluon_models/models/WeightedEnsemble_L5/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/WeightedEnsemble_L5/model.pkl\n",
      "\t0.4074\t = Validation score   (precision)\n",
      "\t1.31s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 855.37s ... Best model: \"WeightedEnsemble_L3\"\n",
      "Loading: ./autogluon_models/models/trainer.pkl\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Saving ./autogluon_models/learner.pkl\n",
      "Saving ./autogluon_models/predictor.pkl\n",
      "Saving ./autogluon_models/__version__ with contents \"0.6.1\"\n",
      "Saving ./autogluon_models/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./autogluon_models/\")\n"
     ]
    }
   ],
   "source": [
    "# there is currently a bug where num_bag_sets >1 produces an error with various algos - waiting on fix\n",
    "# https://github.com/autogluon/autogluon/issues/2581\n",
    "\n",
    "predictor = TabularPredictor(label=label, path=save_path, verbosity=3, eval_metric='precision').fit(\n",
    "    train_data, presets='best_quality', time_limit=15000, num_bag_folds=20, num_stack_levels=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c5645b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./autogluon_models/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L5/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                      model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           CatBoost_BAG_L1   1.000000       0.028020  19.758722                0.028020          19.758722            1       True          7\n",
      "1           LightGBM_BAG_L2   0.758621       2.482328  24.534868                0.106126          19.512355            2       True         16\n",
      "2      LightGBMLarge_BAG_L2   0.687500       2.515875  49.400836                0.139673          44.378322            2       True         25\n",
      "3            XGBoost_BAG_L4   0.681818       4.935526  44.152152                0.387177          28.890719            4       True         47\n",
      "4         LightGBMXT_BAG_L2   0.655172       2.496622  22.081645                0.120420          17.059132            2       True         15\n",
      "5         LightGBMXT_BAG_L4   0.655172       4.682258  31.960919                0.133908          16.699486            4       True         39\n",
      "6            XGBoost_BAG_L2   0.647059       2.747867  35.724406                0.371665          30.701892            2       True         23\n",
      "7    NeuralNetFastAI_BAG_L4   0.625000       5.177690  46.918955                0.629340          31.657522            4       True         46\n",
      "8      LightGBMLarge_BAG_L4   0.619048       4.729132  56.203698                0.180783          40.942265            4       True         49\n",
      "9           LightGBM_BAG_L4   0.600000       4.703117  36.204757                0.154767          20.943324            4       True         40\n",
      "10   NeuralNetFastAI_BAG_L2   0.592105       3.065826  37.636348                0.689624          32.613834            2       True         22\n",
      "11      WeightedEnsemble_L3   0.576923       2.919105   9.734679                0.008428           1.293525            3       True         26\n",
      "12          LightGBM_BAG_L3   0.573770       3.551551  27.237962                0.094569          17.293293            3       True         28\n",
      "13          LightGBM_BAG_L1   0.557692       0.092479  17.649890                0.092479          17.649890            1       True          4\n",
      "14  RandomForestEntr_BAG_L2   0.555556       2.641812   7.025552                0.265610           2.003038            2       True         18\n",
      "15    ExtraTreesEntr_BAG_L2   0.545455       2.647543   5.824564                0.271341           0.802051            2       True         21\n",
      "16     LightGBMLarge_BAG_L3   0.545455       3.592900  45.637333                0.135918          35.692664            3       True         37\n",
      "17   NeuralNetFastAI_BAG_L3   0.526882       3.980477  41.588726                0.523495          31.644057            3       True         34\n",
      "18           XGBoost_BAG_L3   0.522222       3.827672  38.755360                0.370691          28.810691            3       True         35\n",
      "19        LightGBMXT_BAG_L3   0.500000       3.585666  26.770352                0.128684          16.825683            3       True         27\n",
      "20     LightGBMLarge_BAG_L1   0.491228       0.161006  36.715800                0.161006          36.715800            1       True         13\n",
      "21           XGBoost_BAG_L1   0.476923       0.389956  31.946066                0.389956          31.946066            1       True         11\n",
      "22        LightGBMXT_BAG_L1   0.465116       0.110265  15.611301                0.110265          15.611301            1       True          3\n",
      "23    ExtraTreesGini_BAG_L2   0.454545       2.651165   5.723978                0.274963           0.701465            2       True         20\n",
      "24      WeightedEnsemble_L5   0.407407       5.097492  19.379652                0.008218           1.312049            5       True         50\n",
      "25  RandomForestEntr_BAG_L4   0.380000       4.814547  17.367158                0.266197           2.105725            4       True         42\n",
      "26    ExtraTreesGini_BAG_L4   0.372093       4.824049  16.064256                0.275699           0.802823            4       True         44\n",
      "27    ExtraTreesEntr_BAG_L4   0.371429       4.823078  15.961878                0.274728           0.700445            4       True         45\n",
      "28   NeuralNetFastAI_BAG_L1   0.368098       0.483325  30.296918                0.483325          30.296918            1       True         10\n",
      "29  RandomForestGini_BAG_L4   0.357143       4.820721  16.665362                0.272372           1.403929            4       True         41\n",
      "30      WeightedEnsemble_L4   0.344262       4.281361  15.628512                0.008453           1.269353            4       True         38\n",
      "31  RandomForestGini_BAG_L2   0.343750       2.645067   6.438115                0.268865           1.415602            2       True         17\n",
      "32    ExtraTreesEntr_BAG_L3   0.342857       3.732960  10.644395                0.275978           0.699726            3       True         33\n",
      "33  RandomForestEntr_BAG_L3   0.342466       3.723411  12.050984                0.266429           2.106315            3       True         30\n",
      "34  RandomForestGini_BAG_L3   0.341176       3.730501  11.553118                0.273519           1.608449            3       True         29\n",
      "35          CatBoost_BAG_L3   0.333333       3.490634  32.584258                0.033652          22.639589            3       True         31\n",
      "36    ExtraTreesGini_BAG_L3   0.329114       3.732424  10.846943                0.275442           0.902274            3       True         32\n",
      "37          CatBoost_BAG_L4   0.285714       4.578872  36.590702                0.030522          21.329268            4       True         43\n",
      "38      WeightedEnsemble_L2   0.266667       2.120806   6.019157                0.010700           1.902386            2       True         14\n",
      "39  RandomForestGini_BAG_L1   0.224490       0.266957   1.301742                0.266957           1.301742            1       True          5\n",
      "40  RandomForestEntr_BAG_L1   0.208791       0.256319   2.100045                0.256319           2.100045            1       True          6\n",
      "41    ExtraTreesEntr_BAG_L1   0.202381       0.269624   0.697529                0.269624           0.697529            1       True          9\n",
      "42    ExtraTreesGini_BAG_L1   0.180851       0.266096   0.905742                0.266096           0.905742            1       True          8\n",
      "43    KNeighborsUnif_BAG_L1   0.152000       0.709356   0.008894                0.709356           0.008894            1       True          1\n",
      "44    KNeighborsDist_BAG_L1   0.122807       0.607851   0.008561                0.607851           0.008561            1       True          2\n",
      "45    NeuralNetTorch_BAG_L3   0.052632       3.776145  34.386559                0.319163          24.441890            3       True         36\n",
      "46    NeuralNetTorch_BAG_L1   0.000000       0.248370  23.858209                0.248370          23.858209            1       True         12\n",
      "47          CatBoost_BAG_L2   0.000000       2.412805  26.661134                0.036603          21.638621            2       True         19\n",
      "48    NeuralNetTorch_BAG_L2   0.000000       2.735929  29.006363                0.359727          23.983850            2       True         24\n",
      "49    NeuralNetTorch_BAG_L4   0.000000       4.873152  39.454084                0.324802          24.192651            4       True         48\n",
      "Number of models trained: 50\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_XT', 'WeightedEnsembleModel', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_TabularNeuralNetTorch', 'StackerEnsembleModel_KNN', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_XGBoost'}\n",
      "Bagging used: True  (with 20 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 5 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', []) : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "Plot summary of models saved to file: ./autogluon_models/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9bd868b4-db7c-4f97-b674-8fe059ac7e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./autogluon_models/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L5/model.pkl\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038095</td>\n",
       "      <td>0.028020</td>\n",
       "      <td>19.758722</td>\n",
       "      <td>0.038095</td>\n",
       "      <td>0.028020</td>\n",
       "      <td>19.758722</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.214824</td>\n",
       "      <td>0.092479</td>\n",
       "      <td>17.649890</td>\n",
       "      <td>0.214824</td>\n",
       "      <td>0.092479</td>\n",
       "      <td>17.649890</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.208791</td>\n",
       "      <td>0.224058</td>\n",
       "      <td>0.256319</td>\n",
       "      <td>2.100045</td>\n",
       "      <td>0.224058</td>\n",
       "      <td>0.256319</td>\n",
       "      <td>2.100045</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0.225853</td>\n",
       "      <td>0.266957</td>\n",
       "      <td>1.301742</td>\n",
       "      <td>0.225853</td>\n",
       "      <td>0.266957</td>\n",
       "      <td>1.301742</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesGini_BAG_L1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.180851</td>\n",
       "      <td>0.235512</td>\n",
       "      <td>0.266096</td>\n",
       "      <td>0.905742</td>\n",
       "      <td>0.235512</td>\n",
       "      <td>0.266096</td>\n",
       "      <td>0.905742</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202381</td>\n",
       "      <td>0.236475</td>\n",
       "      <td>0.269624</td>\n",
       "      <td>0.697529</td>\n",
       "      <td>0.236475</td>\n",
       "      <td>0.269624</td>\n",
       "      <td>0.697529</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.304072</td>\n",
       "      <td>0.110265</td>\n",
       "      <td>15.611301</td>\n",
       "      <td>0.304072</td>\n",
       "      <td>0.110265</td>\n",
       "      <td>15.611301</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.350253</td>\n",
       "      <td>0.389956</td>\n",
       "      <td>31.946066</td>\n",
       "      <td>0.350253</td>\n",
       "      <td>0.389956</td>\n",
       "      <td>31.946066</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.517237</td>\n",
       "      <td>0.161006</td>\n",
       "      <td>36.715800</td>\n",
       "      <td>0.517237</td>\n",
       "      <td>0.161006</td>\n",
       "      <td>36.715800</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.605458</td>\n",
       "      <td>0.607851</td>\n",
       "      <td>0.008561</td>\n",
       "      <td>0.605458</td>\n",
       "      <td>0.607851</td>\n",
       "      <td>0.008561</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1.907706</td>\n",
       "      <td>2.120806</td>\n",
       "      <td>6.019157</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>1.902386</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBMLarge_BAG_L4</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>4.463961</td>\n",
       "      <td>4.729132</td>\n",
       "      <td>56.203698</td>\n",
       "      <td>0.471781</td>\n",
       "      <td>0.180783</td>\n",
       "      <td>40.942265</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LightGBM_BAG_L4</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>4.237496</td>\n",
       "      <td>4.703117</td>\n",
       "      <td>36.204757</td>\n",
       "      <td>0.245316</td>\n",
       "      <td>0.154767</td>\n",
       "      <td>20.943324</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost_BAG_L4</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>4.359276</td>\n",
       "      <td>4.935526</td>\n",
       "      <td>44.152152</td>\n",
       "      <td>0.367097</td>\n",
       "      <td>0.387177</td>\n",
       "      <td>28.890719</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestEntr_BAG_L4</td>\n",
       "      <td>0.918699</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>4.216813</td>\n",
       "      <td>4.814547</td>\n",
       "      <td>17.367158</td>\n",
       "      <td>0.224633</td>\n",
       "      <td>0.266197</td>\n",
       "      <td>2.105725</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>WeightedEnsemble_L5</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>4.456093</td>\n",
       "      <td>5.097492</td>\n",
       "      <td>19.379652</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>0.008218</td>\n",
       "      <td>1.312049</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ExtraTreesEntr_BAG_L4</td>\n",
       "      <td>0.909910</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>4.227871</td>\n",
       "      <td>4.823078</td>\n",
       "      <td>15.961878</td>\n",
       "      <td>0.235692</td>\n",
       "      <td>0.274728</td>\n",
       "      <td>0.700445</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomForestGini_BAG_L4</td>\n",
       "      <td>0.860294</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>4.218492</td>\n",
       "      <td>4.820721</td>\n",
       "      <td>16.665362</td>\n",
       "      <td>0.226312</td>\n",
       "      <td>0.272372</td>\n",
       "      <td>1.403929</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ExtraTreesGini_BAG_L4</td>\n",
       "      <td>0.844828</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>4.227990</td>\n",
       "      <td>4.824049</td>\n",
       "      <td>16.064256</td>\n",
       "      <td>0.235810</td>\n",
       "      <td>0.275699</td>\n",
       "      <td>0.802823</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ExtraTreesEntr_BAG_L3</td>\n",
       "      <td>0.773196</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>3.299826</td>\n",
       "      <td>3.732960</td>\n",
       "      <td>10.644395</td>\n",
       "      <td>0.235620</td>\n",
       "      <td>0.275978</td>\n",
       "      <td>0.699726</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ExtraTreesEntr_BAG_L2</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>2.375258</td>\n",
       "      <td>2.647543</td>\n",
       "      <td>5.824564</td>\n",
       "      <td>0.236929</td>\n",
       "      <td>0.271341</td>\n",
       "      <td>0.802051</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>WeightedEnsemble_L4</td>\n",
       "      <td>0.756477</td>\n",
       "      <td>0.344262</td>\n",
       "      <td>3.759978</td>\n",
       "      <td>4.281361</td>\n",
       "      <td>15.628512</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>0.008453</td>\n",
       "      <td>1.269353</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomForestEntr_BAG_L3</td>\n",
       "      <td>0.752381</td>\n",
       "      <td>0.342466</td>\n",
       "      <td>3.291384</td>\n",
       "      <td>3.723411</td>\n",
       "      <td>12.050984</td>\n",
       "      <td>0.227178</td>\n",
       "      <td>0.266429</td>\n",
       "      <td>2.106315</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ExtraTreesGini_BAG_L3</td>\n",
       "      <td>0.751269</td>\n",
       "      <td>0.329114</td>\n",
       "      <td>3.300402</td>\n",
       "      <td>3.732424</td>\n",
       "      <td>10.846943</td>\n",
       "      <td>0.236196</td>\n",
       "      <td>0.275442</td>\n",
       "      <td>0.902274</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ExtraTreesGini_BAG_L2</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>2.375422</td>\n",
       "      <td>2.651165</td>\n",
       "      <td>5.723978</td>\n",
       "      <td>0.237093</td>\n",
       "      <td>0.274963</td>\n",
       "      <td>0.701465</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RandomForestGini_BAG_L3</td>\n",
       "      <td>0.695853</td>\n",
       "      <td>0.341176</td>\n",
       "      <td>3.293186</td>\n",
       "      <td>3.730501</td>\n",
       "      <td>11.553118</td>\n",
       "      <td>0.228980</td>\n",
       "      <td>0.273519</td>\n",
       "      <td>1.608449</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.368098</td>\n",
       "      <td>1.462972</td>\n",
       "      <td>0.483325</td>\n",
       "      <td>30.296918</td>\n",
       "      <td>1.462972</td>\n",
       "      <td>0.483325</td>\n",
       "      <td>30.296918</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LightGBMLarge_BAG_L3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>3.414721</td>\n",
       "      <td>3.592900</td>\n",
       "      <td>45.637333</td>\n",
       "      <td>0.350515</td>\n",
       "      <td>0.135918</td>\n",
       "      <td>35.692664</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.610973</td>\n",
       "      <td>0.709356</td>\n",
       "      <td>0.008894</td>\n",
       "      <td>0.610973</td>\n",
       "      <td>0.709356</td>\n",
       "      <td>0.008894</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LightGBMXT_BAG_L3</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.344395</td>\n",
       "      <td>3.585666</td>\n",
       "      <td>26.770352</td>\n",
       "      <td>0.280189</td>\n",
       "      <td>0.128684</td>\n",
       "      <td>16.825683</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LightGBM_BAG_L3</td>\n",
       "      <td>0.530303</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>3.262111</td>\n",
       "      <td>3.551551</td>\n",
       "      <td>27.237962</td>\n",
       "      <td>0.197905</td>\n",
       "      <td>0.094569</td>\n",
       "      <td>17.293293</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>XGBoost_BAG_L3</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>3.432372</td>\n",
       "      <td>3.827672</td>\n",
       "      <td>38.755360</td>\n",
       "      <td>0.368166</td>\n",
       "      <td>0.370691</td>\n",
       "      <td>28.810691</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RandomForestGini_BAG_L2</td>\n",
       "      <td>0.482014</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>2.364306</td>\n",
       "      <td>2.645067</td>\n",
       "      <td>6.438115</td>\n",
       "      <td>0.225977</td>\n",
       "      <td>0.268865</td>\n",
       "      <td>1.415602</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>2.596576</td>\n",
       "      <td>2.919105</td>\n",
       "      <td>9.734679</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>0.008428</td>\n",
       "      <td>1.293525</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RandomForestEntr_BAG_L2</td>\n",
       "      <td>0.465753</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>2.364207</td>\n",
       "      <td>2.641812</td>\n",
       "      <td>7.025552</td>\n",
       "      <td>0.225878</td>\n",
       "      <td>0.265610</td>\n",
       "      <td>2.003038</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NeuralNetTorch_BAG_L3</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>3.672942</td>\n",
       "      <td>3.776145</td>\n",
       "      <td>34.386559</td>\n",
       "      <td>0.608737</td>\n",
       "      <td>0.319163</td>\n",
       "      <td>24.441890</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NeuralNetFastAI_BAG_L3</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.526882</td>\n",
       "      <td>4.599478</td>\n",
       "      <td>3.980477</td>\n",
       "      <td>41.588726</td>\n",
       "      <td>1.535272</td>\n",
       "      <td>0.523495</td>\n",
       "      <td>31.644057</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NeuralNetFastAI_BAG_L4</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>5.529272</td>\n",
       "      <td>5.177690</td>\n",
       "      <td>46.918955</td>\n",
       "      <td>1.537092</td>\n",
       "      <td>0.629340</td>\n",
       "      <td>31.657522</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466661</td>\n",
       "      <td>0.248370</td>\n",
       "      <td>23.858209</td>\n",
       "      <td>0.466661</td>\n",
       "      <td>0.248370</td>\n",
       "      <td>23.858209</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.179135</td>\n",
       "      <td>2.412805</td>\n",
       "      <td>26.661134</td>\n",
       "      <td>0.040806</td>\n",
       "      <td>0.036603</td>\n",
       "      <td>21.638621</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>2.382574</td>\n",
       "      <td>2.482328</td>\n",
       "      <td>24.534868</td>\n",
       "      <td>0.244245</td>\n",
       "      <td>0.106126</td>\n",
       "      <td>19.512355</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>2.406039</td>\n",
       "      <td>2.496622</td>\n",
       "      <td>22.081645</td>\n",
       "      <td>0.267709</td>\n",
       "      <td>0.120420</td>\n",
       "      <td>17.059132</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>XGBoost_BAG_L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>2.519325</td>\n",
       "      <td>2.747867</td>\n",
       "      <td>35.724406</td>\n",
       "      <td>0.380996</td>\n",
       "      <td>0.371665</td>\n",
       "      <td>30.701892</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>LightGBMLarge_BAG_L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>2.538507</td>\n",
       "      <td>2.515875</td>\n",
       "      <td>49.400836</td>\n",
       "      <td>0.400177</td>\n",
       "      <td>0.139673</td>\n",
       "      <td>44.378322</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NeuralNetTorch_BAG_L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.786907</td>\n",
       "      <td>2.735929</td>\n",
       "      <td>29.006363</td>\n",
       "      <td>0.648578</td>\n",
       "      <td>0.359727</td>\n",
       "      <td>23.983850</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>CatBoost_BAG_L3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.105183</td>\n",
       "      <td>3.490634</td>\n",
       "      <td>32.584258</td>\n",
       "      <td>0.040977</td>\n",
       "      <td>0.033652</td>\n",
       "      <td>22.639589</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>3.672685</td>\n",
       "      <td>3.065826</td>\n",
       "      <td>37.636348</td>\n",
       "      <td>1.534356</td>\n",
       "      <td>0.689624</td>\n",
       "      <td>32.613834</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>CatBoost_BAG_L4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>4.032390</td>\n",
       "      <td>4.578872</td>\n",
       "      <td>36.590702</td>\n",
       "      <td>0.040210</td>\n",
       "      <td>0.030522</td>\n",
       "      <td>21.329268</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>LightGBMXT_BAG_L4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>4.270675</td>\n",
       "      <td>4.682258</td>\n",
       "      <td>31.960919</td>\n",
       "      <td>0.278495</td>\n",
       "      <td>0.133908</td>\n",
       "      <td>16.699486</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NeuralNetTorch_BAG_L4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.787262</td>\n",
       "      <td>4.873152</td>\n",
       "      <td>39.454084</td>\n",
       "      <td>0.795082</td>\n",
       "      <td>0.324802</td>\n",
       "      <td>24.192651</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  score_test  score_val  pred_time_test  \\\n",
       "0           CatBoost_BAG_L1    1.000000   1.000000        0.038095   \n",
       "1           LightGBM_BAG_L1    1.000000   0.557692        0.214824   \n",
       "2   RandomForestEntr_BAG_L1    1.000000   0.208791        0.224058   \n",
       "3   RandomForestGini_BAG_L1    1.000000   0.224490        0.225853   \n",
       "4     ExtraTreesGini_BAG_L1    1.000000   0.180851        0.235512   \n",
       "5     ExtraTreesEntr_BAG_L1    1.000000   0.202381        0.236475   \n",
       "6         LightGBMXT_BAG_L1    1.000000   0.465116        0.304072   \n",
       "7            XGBoost_BAG_L1    1.000000   0.476923        0.350253   \n",
       "8      LightGBMLarge_BAG_L1    1.000000   0.491228        0.517237   \n",
       "9     KNeighborsDist_BAG_L1    1.000000   0.122807        0.605458   \n",
       "10      WeightedEnsemble_L2    1.000000   0.266667        1.907706   \n",
       "11     LightGBMLarge_BAG_L4    0.983607   0.619048        4.463961   \n",
       "12          LightGBM_BAG_L4    0.947368   0.600000        4.237496   \n",
       "13           XGBoost_BAG_L4    0.931818   0.681818        4.359276   \n",
       "14  RandomForestEntr_BAG_L4    0.918699   0.380000        4.216813   \n",
       "15      WeightedEnsemble_L5    0.913793   0.407407        4.456093   \n",
       "16    ExtraTreesEntr_BAG_L4    0.909910   0.371429        4.227871   \n",
       "17  RandomForestGini_BAG_L4    0.860294   0.357143        4.218492   \n",
       "18    ExtraTreesGini_BAG_L4    0.844828   0.372093        4.227990   \n",
       "19    ExtraTreesEntr_BAG_L3    0.773196   0.342857        3.299826   \n",
       "20    ExtraTreesEntr_BAG_L2    0.772727   0.545455        2.375258   \n",
       "21      WeightedEnsemble_L4    0.756477   0.344262        3.759978   \n",
       "22  RandomForestEntr_BAG_L3    0.752381   0.342466        3.291384   \n",
       "23    ExtraTreesGini_BAG_L3    0.751269   0.329114        3.300402   \n",
       "24    ExtraTreesGini_BAG_L2    0.702703   0.454545        2.375422   \n",
       "25  RandomForestGini_BAG_L3    0.695853   0.341176        3.293186   \n",
       "26   NeuralNetFastAI_BAG_L1    0.687500   0.368098        1.462972   \n",
       "27     LightGBMLarge_BAG_L3    0.666667   0.545455        3.414721   \n",
       "28    KNeighborsUnif_BAG_L1    0.620690   0.152000        0.610973   \n",
       "29        LightGBMXT_BAG_L3    0.580645   0.500000        3.344395   \n",
       "30          LightGBM_BAG_L3    0.530303   0.573770        3.262111   \n",
       "31           XGBoost_BAG_L3    0.523810   0.522222        3.432372   \n",
       "32  RandomForestGini_BAG_L2    0.482014   0.343750        2.364306   \n",
       "33      WeightedEnsemble_L3    0.466667   0.576923        2.596576   \n",
       "34  RandomForestEntr_BAG_L2    0.465753   0.555556        2.364207   \n",
       "35    NeuralNetTorch_BAG_L3    0.360000   0.052632        3.672942   \n",
       "36   NeuralNetFastAI_BAG_L3    0.310345   0.526882        4.599478   \n",
       "37   NeuralNetFastAI_BAG_L4    0.181818   0.625000        5.529272   \n",
       "38    NeuralNetTorch_BAG_L1    0.000000   0.000000        0.466661   \n",
       "39          CatBoost_BAG_L2    0.000000   0.000000        2.179135   \n",
       "40          LightGBM_BAG_L2    0.000000   0.758621        2.382574   \n",
       "41        LightGBMXT_BAG_L2    0.000000   0.655172        2.406039   \n",
       "42           XGBoost_BAG_L2    0.000000   0.647059        2.519325   \n",
       "43     LightGBMLarge_BAG_L2    0.000000   0.687500        2.538507   \n",
       "44    NeuralNetTorch_BAG_L2    0.000000   0.000000        2.786907   \n",
       "45          CatBoost_BAG_L3    0.000000   0.333333        3.105183   \n",
       "46   NeuralNetFastAI_BAG_L2    0.000000   0.592105        3.672685   \n",
       "47          CatBoost_BAG_L4    0.000000   0.285714        4.032390   \n",
       "48        LightGBMXT_BAG_L4    0.000000   0.655172        4.270675   \n",
       "49    NeuralNetTorch_BAG_L4    0.000000   0.000000        4.787262   \n",
       "\n",
       "    pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0        0.028020  19.758722                 0.038095                0.028020   \n",
       "1        0.092479  17.649890                 0.214824                0.092479   \n",
       "2        0.256319   2.100045                 0.224058                0.256319   \n",
       "3        0.266957   1.301742                 0.225853                0.266957   \n",
       "4        0.266096   0.905742                 0.235512                0.266096   \n",
       "5        0.269624   0.697529                 0.236475                0.269624   \n",
       "6        0.110265  15.611301                 0.304072                0.110265   \n",
       "7        0.389956  31.946066                 0.350253                0.389956   \n",
       "8        0.161006  36.715800                 0.517237                0.161006   \n",
       "9        0.607851   0.008561                 0.605458                0.607851   \n",
       "10       2.120806   6.019157                 0.004889                0.010700   \n",
       "11       4.729132  56.203698                 0.471781                0.180783   \n",
       "12       4.703117  36.204757                 0.245316                0.154767   \n",
       "13       4.935526  44.152152                 0.367097                0.387177   \n",
       "14       4.814547  17.367158                 0.224633                0.266197   \n",
       "15       5.097492  19.379652                 0.003588                0.008218   \n",
       "16       4.823078  15.961878                 0.235692                0.274728   \n",
       "17       4.820721  16.665362                 0.226312                0.272372   \n",
       "18       4.824049  16.064256                 0.235810                0.275699   \n",
       "19       3.732960  10.644395                 0.235620                0.275978   \n",
       "20       2.647543   5.824564                 0.236929                0.271341   \n",
       "21       4.281361  15.628512                 0.003994                0.008453   \n",
       "22       3.723411  12.050984                 0.227178                0.266429   \n",
       "23       3.732424  10.846943                 0.236196                0.275442   \n",
       "24       2.651165   5.723978                 0.237093                0.274963   \n",
       "25       3.730501  11.553118                 0.228980                0.273519   \n",
       "26       0.483325  30.296918                 1.462972                0.483325   \n",
       "27       3.592900  45.637333                 0.350515                0.135918   \n",
       "28       0.709356   0.008894                 0.610973                0.709356   \n",
       "29       3.585666  26.770352                 0.280189                0.128684   \n",
       "30       3.551551  27.237962                 0.197905                0.094569   \n",
       "31       3.827672  38.755360                 0.368166                0.370691   \n",
       "32       2.645067   6.438115                 0.225977                0.268865   \n",
       "33       2.919105   9.734679                 0.006393                0.008428   \n",
       "34       2.641812   7.025552                 0.225878                0.265610   \n",
       "35       3.776145  34.386559                 0.608737                0.319163   \n",
       "36       3.980477  41.588726                 1.535272                0.523495   \n",
       "37       5.177690  46.918955                 1.537092                0.629340   \n",
       "38       0.248370  23.858209                 0.466661                0.248370   \n",
       "39       2.412805  26.661134                 0.040806                0.036603   \n",
       "40       2.482328  24.534868                 0.244245                0.106126   \n",
       "41       2.496622  22.081645                 0.267709                0.120420   \n",
       "42       2.747867  35.724406                 0.380996                0.371665   \n",
       "43       2.515875  49.400836                 0.400177                0.139673   \n",
       "44       2.735929  29.006363                 0.648578                0.359727   \n",
       "45       3.490634  32.584258                 0.040977                0.033652   \n",
       "46       3.065826  37.636348                 1.534356                0.689624   \n",
       "47       4.578872  36.590702                 0.040210                0.030522   \n",
       "48       4.682258  31.960919                 0.278495                0.133908   \n",
       "49       4.873152  39.454084                 0.795082                0.324802   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           19.758722            1       True          7  \n",
       "1           17.649890            1       True          4  \n",
       "2            2.100045            1       True          6  \n",
       "3            1.301742            1       True          5  \n",
       "4            0.905742            1       True          8  \n",
       "5            0.697529            1       True          9  \n",
       "6           15.611301            1       True          3  \n",
       "7           31.946066            1       True         11  \n",
       "8           36.715800            1       True         13  \n",
       "9            0.008561            1       True          2  \n",
       "10           1.902386            2       True         14  \n",
       "11          40.942265            4       True         49  \n",
       "12          20.943324            4       True         40  \n",
       "13          28.890719            4       True         47  \n",
       "14           2.105725            4       True         42  \n",
       "15           1.312049            5       True         50  \n",
       "16           0.700445            4       True         45  \n",
       "17           1.403929            4       True         41  \n",
       "18           0.802823            4       True         44  \n",
       "19           0.699726            3       True         33  \n",
       "20           0.802051            2       True         21  \n",
       "21           1.269353            4       True         38  \n",
       "22           2.106315            3       True         30  \n",
       "23           0.902274            3       True         32  \n",
       "24           0.701465            2       True         20  \n",
       "25           1.608449            3       True         29  \n",
       "26          30.296918            1       True         10  \n",
       "27          35.692664            3       True         37  \n",
       "28           0.008894            1       True          1  \n",
       "29          16.825683            3       True         27  \n",
       "30          17.293293            3       True         28  \n",
       "31          28.810691            3       True         35  \n",
       "32           1.415602            2       True         17  \n",
       "33           1.293525            3       True         26  \n",
       "34           2.003038            2       True         18  \n",
       "35          24.441890            3       True         36  \n",
       "36          31.644057            3       True         34  \n",
       "37          31.657522            4       True         46  \n",
       "38          23.858209            1       True         12  \n",
       "39          21.638621            2       True         19  \n",
       "40          19.512355            2       True         16  \n",
       "41          17.059132            2       True         15  \n",
       "42          30.701892            2       True         23  \n",
       "43          44.378322            2       True         25  \n",
       "44          23.983850            2       True         24  \n",
       "45          22.639589            3       True         31  \n",
       "46          32.613834            2       True         22  \n",
       "47          21.329268            4       True         43  \n",
       "48          16.699486            4       True         39  \n",
       "49          24.192651            4       True         48  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(train_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "30f1411d-b62e-4f84-b7d2-566c670df9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['8. split coefficient']\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L3/model.pkl\n",
      "Computing feature importance via permutation shuffling for 27 features using 4487 rows with 5 shuffle sets...\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L3/model.pkl\n",
      "\t367.04s\t= Expected runtime (73.41s per shuffle set)\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L3/model.pkl\n",
      "\t161.8s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7. dividend amount</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_pcent_change</th>\n",
       "      <td>-0.003655</td>\n",
       "      <td>0.039270</td>\n",
       "      <td>0.577358</td>\n",
       "      <td>5</td>\n",
       "      <td>0.077203</td>\n",
       "      <td>-0.084514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppo</th>\n",
       "      <td>-0.021273</td>\n",
       "      <td>0.043738</td>\n",
       "      <td>0.831031</td>\n",
       "      <td>5</td>\n",
       "      <td>0.068784</td>\n",
       "      <td>-0.111329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bb_width</th>\n",
       "      <td>-0.071032</td>\n",
       "      <td>0.078455</td>\n",
       "      <td>0.943542</td>\n",
       "      <td>5</td>\n",
       "      <td>0.090507</td>\n",
       "      <td>-0.232571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMA_20_pcent_diff_to_close</th>\n",
       "      <td>-0.094851</td>\n",
       "      <td>0.030117</td>\n",
       "      <td>0.998928</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.032839</td>\n",
       "      <td>-0.156863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMA_5_pcent_diff_to_close</th>\n",
       "      <td>-0.103003</td>\n",
       "      <td>0.028470</td>\n",
       "      <td>0.999366</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.044384</td>\n",
       "      <td>-0.161623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stochrsi_fast_k</th>\n",
       "      <td>-0.106143</td>\n",
       "      <td>0.015855</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.073498</td>\n",
       "      <td>-0.138789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stochrsi_fast_d</th>\n",
       "      <td>-0.119357</td>\n",
       "      <td>0.058997</td>\n",
       "      <td>0.994686</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>-0.240833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMA_20_pcent_diff_to_open</th>\n",
       "      <td>-0.120010</td>\n",
       "      <td>0.039272</td>\n",
       "      <td>0.998800</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.039148</td>\n",
       "      <td>-0.200871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMA_10_pcent_diff_to_open</th>\n",
       "      <td>-0.125198</td>\n",
       "      <td>0.022575</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.078717</td>\n",
       "      <td>-0.171679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMA_40_pcent_diff_to_open</th>\n",
       "      <td>-0.133004</td>\n",
       "      <td>0.044597</td>\n",
       "      <td>0.998686</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.041178</td>\n",
       "      <td>-0.224830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMA_5_pcent_diff_to_open</th>\n",
       "      <td>-0.151980</td>\n",
       "      <td>0.032895</td>\n",
       "      <td>0.999752</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.084249</td>\n",
       "      <td>-0.219711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMA_10_pcent_diff_to_close</th>\n",
       "      <td>-0.152803</td>\n",
       "      <td>0.027813</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.095535</td>\n",
       "      <td>-0.210071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4. close</th>\n",
       "      <td>-0.158597</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.998068</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.037065</td>\n",
       "      <td>-0.280129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMA_40_pcent_diff_to_close</th>\n",
       "      <td>-0.161622</td>\n",
       "      <td>0.035110</td>\n",
       "      <td>0.999749</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.089329</td>\n",
       "      <td>-0.233914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bb_lower</th>\n",
       "      <td>-0.166882</td>\n",
       "      <td>0.050118</td>\n",
       "      <td>0.999131</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.063687</td>\n",
       "      <td>-0.270076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1. open</th>\n",
       "      <td>-0.170281</td>\n",
       "      <td>0.051054</td>\n",
       "      <td>0.999136</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.065160</td>\n",
       "      <td>-0.275401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macd_signal</th>\n",
       "      <td>-0.171061</td>\n",
       "      <td>0.025323</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.118921</td>\n",
       "      <td>-0.223200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bb_upper</th>\n",
       "      <td>-0.176250</td>\n",
       "      <td>0.029448</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.115616</td>\n",
       "      <td>-0.236884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMA_80_pcent_diff_to_open</th>\n",
       "      <td>-0.184043</td>\n",
       "      <td>0.026644</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.129182</td>\n",
       "      <td>-0.238904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. low</th>\n",
       "      <td>-0.184812</td>\n",
       "      <td>0.061701</td>\n",
       "      <td>0.998707</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.057769</td>\n",
       "      <td>-0.311856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6. volume</th>\n",
       "      <td>-0.190259</td>\n",
       "      <td>0.008961</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.171808</td>\n",
       "      <td>-0.208710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcent_diff_to_bb_upper</th>\n",
       "      <td>-0.197353</td>\n",
       "      <td>0.038306</td>\n",
       "      <td>0.999838</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.118481</td>\n",
       "      <td>-0.276225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcent_diff_to_bb_lower</th>\n",
       "      <td>-0.199883</td>\n",
       "      <td>0.036637</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.124446</td>\n",
       "      <td>-0.275320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMA_80_pcent_diff_to_close</th>\n",
       "      <td>-0.200297</td>\n",
       "      <td>0.021005</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.157048</td>\n",
       "      <td>-0.243547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. high</th>\n",
       "      <td>-0.202716</td>\n",
       "      <td>0.046872</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.106206</td>\n",
       "      <td>-0.299225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5. adjusted close</th>\n",
       "      <td>-0.237494</td>\n",
       "      <td>0.055932</td>\n",
       "      <td>0.999657</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.122330</td>\n",
       "      <td>-0.352658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            importance    stddev   p_value  n  p99_high  \\\n",
       "7. dividend amount            0.000000  0.000000  0.500000  5  0.000000   \n",
       "day_pcent_change             -0.003655  0.039270  0.577358  5  0.077203   \n",
       "ppo                          -0.021273  0.043738  0.831031  5  0.068784   \n",
       "bb_width                     -0.071032  0.078455  0.943542  5  0.090507   \n",
       "WMA_20_pcent_diff_to_close   -0.094851  0.030117  0.998928  5 -0.032839   \n",
       "WMA_5_pcent_diff_to_close    -0.103003  0.028470  0.999366  5 -0.044384   \n",
       "stochrsi_fast_k              -0.106143  0.015855  0.999942  5 -0.073498   \n",
       "stochrsi_fast_d              -0.119357  0.058997  0.994686  5  0.002118   \n",
       "WMA_20_pcent_diff_to_open    -0.120010  0.039272  0.998800  5 -0.039148   \n",
       "WMA_10_pcent_diff_to_open    -0.125198  0.022575  0.999878  5 -0.078717   \n",
       "WMA_40_pcent_diff_to_open    -0.133004  0.044597  0.998686  5 -0.041178   \n",
       "WMA_5_pcent_diff_to_open     -0.151980  0.032895  0.999752  5 -0.084249   \n",
       "WMA_10_pcent_diff_to_close   -0.152803  0.027813  0.999874  5 -0.095535   \n",
       "4. close                     -0.158597  0.059024  0.998068  5 -0.037065   \n",
       "WMA_40_pcent_diff_to_close   -0.161622  0.035110  0.999749  5 -0.089329   \n",
       "bb_lower                     -0.166882  0.050118  0.999131  5 -0.063687   \n",
       "1. open                      -0.170281  0.051054  0.999136  5 -0.065160   \n",
       "macd_signal                  -0.171061  0.025323  0.999944  5 -0.118921   \n",
       "bb_upper                     -0.176250  0.029448  0.999910  5 -0.115616   \n",
       "WMA_80_pcent_diff_to_open    -0.184043  0.026644  0.999949  5 -0.129182   \n",
       "3. low                       -0.184812  0.061701  0.998707  5 -0.057769   \n",
       "6. volume                    -0.190259  0.008961  0.999999  5 -0.171808   \n",
       "pcent_diff_to_bb_upper       -0.197353  0.038306  0.999838  5 -0.118481   \n",
       "pcent_diff_to_bb_lower       -0.199883  0.036637  0.999870  5 -0.124446   \n",
       "WMA_80_pcent_diff_to_close   -0.200297  0.021005  0.999986  5 -0.157048   \n",
       "2. high                      -0.202716  0.046872  0.999680  5 -0.106206   \n",
       "5. adjusted close            -0.237494  0.055932  0.999657  5 -0.122330   \n",
       "\n",
       "                             p99_low  \n",
       "7. dividend amount          0.000000  \n",
       "day_pcent_change           -0.084514  \n",
       "ppo                        -0.111329  \n",
       "bb_width                   -0.232571  \n",
       "WMA_20_pcent_diff_to_close -0.156863  \n",
       "WMA_5_pcent_diff_to_close  -0.161623  \n",
       "stochrsi_fast_k            -0.138789  \n",
       "stochrsi_fast_d            -0.240833  \n",
       "WMA_20_pcent_diff_to_open  -0.200871  \n",
       "WMA_10_pcent_diff_to_open  -0.171679  \n",
       "WMA_40_pcent_diff_to_open  -0.224830  \n",
       "WMA_5_pcent_diff_to_open   -0.219711  \n",
       "WMA_10_pcent_diff_to_close -0.210071  \n",
       "4. close                   -0.280129  \n",
       "WMA_40_pcent_diff_to_close -0.233914  \n",
       "bb_lower                   -0.270076  \n",
       "1. open                    -0.275401  \n",
       "macd_signal                -0.223200  \n",
       "bb_upper                   -0.236884  \n",
       "WMA_80_pcent_diff_to_open  -0.238904  \n",
       "3. low                     -0.311856  \n",
       "6. volume                  -0.208710  \n",
       "pcent_diff_to_bb_upper     -0.276225  \n",
       "pcent_diff_to_bb_lower     -0.275320  \n",
       "WMA_80_pcent_diff_to_close -0.243547  \n",
       "2. high                    -0.299225  \n",
       "5. adjusted close          -0.352658  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(train_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
