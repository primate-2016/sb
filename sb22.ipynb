{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe5d5a9-d03b-407c-94f8-cb4c68414614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "!pip install alpha_vantage autogluon\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from alpha_vantage.techindicators import TechIndicators\n",
    "from alpha_vantage.sectorperformance import SectorPerformances\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import os\n",
    "from time import sleep\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ca8eeca7-2e2d-4232-bf8c-61b0da4def55",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.getenv('API_KEY')\n",
    "symbol = 'BMW.FRK'\n",
    "pcent_change_to_buy_on = 1.5\n",
    "sleep_time = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5f3bf505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get sector overview for stock\n",
    "# url = f'https://www.alphavantage.co/query?function=OVERVIEW&symbol={symbol}&apikey={API_KEY}'\n",
    "# r = requests.get(url)\n",
    "# sector = r.json()['Sector']\n",
    "# data = r.json()\n",
    "# print(sector)\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "fda2fc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ***************Sentiment would be a good source but can't seem to get more than 50 items from the API so won't go back\n",
    "# # far enough???????\n",
    "# # replace the \"demo\" apikey below with your own key from https://www.alphavantage.co/support/#api-key\n",
    "# # url = f'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers={symbol}&apikey={API_KEY}\n",
    "# url = f'https://www.alphavantage.co/query?function=NEWS_SENTIMENT&tickers={symbol}&time_from=20040825T0130&apikey={API_KEY}'\n",
    "# print(url)\n",
    "# r = requests.get(url)\n",
    "\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b6e3a27a-725a-4ff0-8093-48f7a3c22a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get json object with the intraday data and another with  the call's metadata\n",
    "# For the default date string index behavior\n",
    "# ts = TimeSeries(key=API_KEY, output_format='pandas', indexing_type='integer')\n",
    "# ts_data, ts_meta_data = ts.get_intraday(symbol, interval='1min', outputsize='full')\n",
    "\n",
    "\n",
    "# ts_data['4. close'].plot()\n",
    "# plt.title(f'Intraday Times Series for the {symbol} stock (1 min)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "50321556-61d2-4424-8bcf-c5a256dbcce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted daily data\n",
    "ts = TimeSeries(key=API_KEY, output_format='pandas', indexing_type='integer')\n",
    "ts_data, ts_meta_data = ts.get_daily_adjusted(symbol, outputsize='full')\n",
    "\n",
    "\n",
    "# ts_data['4. close'].plot()\n",
    "# plt.title('Intraday Times Series for the GOOGL stock (1 min)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d180864-2979-4d73-b2b7-fc36c7578314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "93c7ac35-6711-4dad-b71b-e6211827b528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. adjusted close</th>\n",
       "      <th>6. volume</th>\n",
       "      <th>7. dividend amount</th>\n",
       "      <th>8. split coefficient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4562</th>\n",
       "      <td>2005-01-07</td>\n",
       "      <td>34.60</td>\n",
       "      <td>34.72</td>\n",
       "      <td>34.30</td>\n",
       "      <td>34.57</td>\n",
       "      <td>21.4574</td>\n",
       "      <td>280363.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4563</th>\n",
       "      <td>2005-01-06</td>\n",
       "      <td>34.55</td>\n",
       "      <td>34.90</td>\n",
       "      <td>34.53</td>\n",
       "      <td>34.70</td>\n",
       "      <td>21.5381</td>\n",
       "      <td>250466.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4564</th>\n",
       "      <td>2005-01-05</td>\n",
       "      <td>34.20</td>\n",
       "      <td>34.70</td>\n",
       "      <td>34.15</td>\n",
       "      <td>34.65</td>\n",
       "      <td>21.5071</td>\n",
       "      <td>734946.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4565</th>\n",
       "      <td>2005-01-04</td>\n",
       "      <td>33.70</td>\n",
       "      <td>34.48</td>\n",
       "      <td>33.67</td>\n",
       "      <td>34.39</td>\n",
       "      <td>21.3457</td>\n",
       "      <td>567720.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4566</th>\n",
       "      <td>2005-01-03</td>\n",
       "      <td>33.30</td>\n",
       "      <td>33.80</td>\n",
       "      <td>33.30</td>\n",
       "      <td>33.75</td>\n",
       "      <td>20.9485</td>\n",
       "      <td>246820.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  1. open  2. high  3. low  4. close  5. adjusted close  \\\n",
       "index                                                                      \n",
       "4562   2005-01-07    34.60    34.72   34.30     34.57            21.4574   \n",
       "4563   2005-01-06    34.55    34.90   34.53     34.70            21.5381   \n",
       "4564   2005-01-05    34.20    34.70   34.15     34.65            21.5071   \n",
       "4565   2005-01-04    33.70    34.48   33.67     34.39            21.3457   \n",
       "4566   2005-01-03    33.30    33.80   33.30     33.75            20.9485   \n",
       "\n",
       "       6. volume  7. dividend amount  8. split coefficient  \n",
       "index                                                       \n",
       "4562    280363.0                 0.0                   1.0  \n",
       "4563    250466.0                 0.0                   1.0  \n",
       "4564    734946.0                 0.0                   1.0  \n",
       "4565    567720.0                 0.0                   1.0  \n",
       "4566    246820.0                 0.0                   1.0  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_data = ts_data\n",
    "adjusted_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e469caf1-30e1-4ba1-944a-75d992d73ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the percent change for each day\n",
    "adjusted_data['day_pcent_change'] = 100 * ((ts_data['4. close'] - ts_data['1. open']) / ts_data['1. open'])\n",
    "\n",
    "\n",
    "# ******need to predict whether price for tomorrow will go up by 2% or greater - so need label - buy - 0 or 1\n",
    "# today's close data will be used to predict whether to buy tomorrow\n",
    "# so model cannot have the most recent row in it, since that would be today's data\n",
    "# from which tomorrow's prediction will be made\n",
    "\n",
    "# shift all the next days data by one which will be used to determine whether it should have been bought or not\n",
    "adjusted_data['next_days_pcent_change'] = adjusted_data['day_pcent_change'].shift(+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2b985068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the label - binary classification of whether to buy or not based on whether the stock went up 2% or more\n",
    "# that day\n",
    "\n",
    "def buy_or_not(row):\n",
    "    if row.next_days_pcent_change >= pcent_change_to_buy_on:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "adjusted_data['buy_tomorrow'] = adjusted_data.apply(buy_or_not, axis='columns')\n",
    "\n",
    "# next_days_pcent_change will pollute the data set so drop it\n",
    "\n",
    "adjusted_data.drop(columns='next_days_pcent_change',\n",
    "                  inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c7642421-0603-4f5c-ac8c-55225938ca85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WMA_5</th>\n",
       "      <th>WMA_10</th>\n",
       "      <th>WMA_20</th>\n",
       "      <th>WMA_40</th>\n",
       "      <th>WMA_80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4563.000000</td>\n",
       "      <td>4558.000000</td>\n",
       "      <td>4548.000000</td>\n",
       "      <td>4528.000000</td>\n",
       "      <td>4488.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>51.404965</td>\n",
       "      <td>51.415227</td>\n",
       "      <td>51.436436</td>\n",
       "      <td>51.479705</td>\n",
       "      <td>51.573188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.548574</td>\n",
       "      <td>22.523558</td>\n",
       "      <td>22.473208</td>\n",
       "      <td>22.370837</td>\n",
       "      <td>22.182938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.127500</td>\n",
       "      <td>12.280200</td>\n",
       "      <td>12.566200</td>\n",
       "      <td>13.270200</td>\n",
       "      <td>13.574300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.754950</td>\n",
       "      <td>27.830800</td>\n",
       "      <td>27.801750</td>\n",
       "      <td>27.826525</td>\n",
       "      <td>27.970875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.784000</td>\n",
       "      <td>56.123450</td>\n",
       "      <td>56.754950</td>\n",
       "      <td>56.965300</td>\n",
       "      <td>56.475250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.571500</td>\n",
       "      <td>70.595975</td>\n",
       "      <td>70.558800</td>\n",
       "      <td>70.575300</td>\n",
       "      <td>70.554200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>98.884000</td>\n",
       "      <td>98.297600</td>\n",
       "      <td>96.555600</td>\n",
       "      <td>94.075400</td>\n",
       "      <td>92.770000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             WMA_5       WMA_10       WMA_20       WMA_40       WMA_80\n",
       "count  4563.000000  4558.000000  4548.000000  4528.000000  4488.000000\n",
       "mean     51.404965    51.415227    51.436436    51.479705    51.573188\n",
       "std      22.548574    22.523558    22.473208    22.370837    22.182938\n",
       "min      12.127500    12.280200    12.566200    13.270200    13.574300\n",
       "25%      27.754950    27.830800    27.801750    27.826525    27.970875\n",
       "50%      55.784000    56.123450    56.754950    56.965300    56.475250\n",
       "75%      70.571500    70.595975    70.558800    70.575300    70.554200\n",
       "max      98.884000    98.297600    96.555600    94.075400    92.770000"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# technical indicators - some of these are premium\n",
    "\n",
    "wma = [5, 10, 20, 40, 80]\n",
    "\n",
    "# def concat_wma_df(df, period):\n",
    "#     '''\n",
    "#     concatenate the pandas dataframes being passed into the function\n",
    "#     '''\n",
    "    \n",
    "wma_data = pd.DataFrame()\n",
    "\n",
    "for period in wma:\n",
    "    \n",
    "    sleep(sleep_time) # avoid breaching the API request rate limit\n",
    "    ti = TechIndicators(key=API_KEY, output_format='pandas')\n",
    "    ti_data, ti_meta_data = ti.get_wma(symbol, interval='daily', time_period=period)\n",
    "    wma_data[f'WMA_{period}'] = ti_data['WMA']\n",
    "\n",
    "    \n",
    "wma_data.describe() \n",
    "\n",
    "# *********get the resistance figures for the MAs?\n",
    "# need to understand the relevance of the MAs better and what predictive power they are supposed to be happened so it can be represented properly\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ti_data.plot()\n",
    "# plt.title('WMA indicator for  GOOGL stock (60 min)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b45c8c06-af57-4d07-adfe-1c75dcbe1430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>WMA_5</th>\n",
       "      <th>WMA_10</th>\n",
       "      <th>WMA_20</th>\n",
       "      <th>WMA_40</th>\n",
       "      <th>WMA_80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>83.6487</td>\n",
       "      <td>83.5449</td>\n",
       "      <td>83.8986</td>\n",
       "      <td>83.8549</td>\n",
       "      <td>81.3006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-22</td>\n",
       "      <td>83.5940</td>\n",
       "      <td>83.5547</td>\n",
       "      <td>83.9561</td>\n",
       "      <td>83.8272</td>\n",
       "      <td>81.1762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-21</td>\n",
       "      <td>83.6267</td>\n",
       "      <td>83.6218</td>\n",
       "      <td>84.0520</td>\n",
       "      <td>83.8128</td>\n",
       "      <td>81.0576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-20</td>\n",
       "      <td>83.3787</td>\n",
       "      <td>83.5673</td>\n",
       "      <td>84.0758</td>\n",
       "      <td>83.7557</td>\n",
       "      <td>80.9173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>83.2560</td>\n",
       "      <td>83.5925</td>\n",
       "      <td>84.1285</td>\n",
       "      <td>83.7050</td>\n",
       "      <td>80.7809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    WMA_5   WMA_10   WMA_20   WMA_40   WMA_80\n",
       "0 2022-12-23  83.6487  83.5449  83.8986  83.8549  81.3006\n",
       "1 2022-12-22  83.5940  83.5547  83.9561  83.8272  81.1762\n",
       "2 2022-12-21  83.6267  83.6218  84.0520  83.8128  81.0576\n",
       "3 2022-12-20  83.3787  83.5673  84.0758  83.7557  80.9173\n",
       "4 2022-12-19  83.2560  83.5925  84.1285  83.7050  80.7809"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tech indicator data is received in the reverse order to price data so reverse it\n",
    "rev_wma_data = wma_data[::-1]\n",
    "rev_wma_data.reset_index(inplace=True)\n",
    "\n",
    "# rev_ti_data.drop(index=rev_ti_data.index[0], \n",
    "#         axis=0, \n",
    "#         inplace=True)\n",
    "rev_wma_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2307cc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for period in wma:\n",
    "    adjusted_data[f'WMA_{period}'] = rev_wma_data[f'WMA_{period}']\n",
    "#     these should be percentage diff to close as well?\n",
    "    adjusted_data[f'WMA_{period}_pcent_diff_to_close'] = (adjusted_data['4. close'] - adjusted_data[f'WMA_{period}']) / adjusted_data['4. close']\n",
    "    adjusted_data[f'WMA_{period}_pcent_diff_to_open'] = (adjusted_data['1. open'] - adjusted_data[f'WMA_{period}']) / adjusted_data['4. close']\n",
    "    adjusted_data.drop(columns=f'WMA_{period}', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b97ae181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. adjusted close</th>\n",
       "      <th>6. volume</th>\n",
       "      <th>7. dividend amount</th>\n",
       "      <th>8. split coefficient</th>\n",
       "      <th>day_pcent_change</th>\n",
       "      <th>...</th>\n",
       "      <th>WMA_5_pcent_diff_to_close</th>\n",
       "      <th>WMA_5_pcent_diff_to_open</th>\n",
       "      <th>WMA_10_pcent_diff_to_close</th>\n",
       "      <th>WMA_10_pcent_diff_to_open</th>\n",
       "      <th>WMA_20_pcent_diff_to_close</th>\n",
       "      <th>WMA_20_pcent_diff_to_open</th>\n",
       "      <th>WMA_40_pcent_diff_to_close</th>\n",
       "      <th>WMA_40_pcent_diff_to_open</th>\n",
       "      <th>WMA_80_pcent_diff_to_close</th>\n",
       "      <th>WMA_80_pcent_diff_to_open</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>83.41</td>\n",
       "      <td>83.72</td>\n",
       "      <td>83.24</td>\n",
       "      <td>83.65</td>\n",
       "      <td>83.65</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.287735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.002854</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>-0.001613</td>\n",
       "      <td>-0.002972</td>\n",
       "      <td>-0.005841</td>\n",
       "      <td>-0.002449</td>\n",
       "      <td>-0.005319</td>\n",
       "      <td>0.028086</td>\n",
       "      <td>0.025217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-22</td>\n",
       "      <td>84.20</td>\n",
       "      <td>84.20</td>\n",
       "      <td>83.01</td>\n",
       "      <td>83.29</td>\n",
       "      <td>83.29</td>\n",
       "      <td>443.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.080760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003650</td>\n",
       "      <td>0.007276</td>\n",
       "      <td>-0.003178</td>\n",
       "      <td>0.007748</td>\n",
       "      <td>-0.007997</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>-0.006450</td>\n",
       "      <td>0.004476</td>\n",
       "      <td>0.025379</td>\n",
       "      <td>0.036304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-21</td>\n",
       "      <td>83.21</td>\n",
       "      <td>84.20</td>\n",
       "      <td>83.21</td>\n",
       "      <td>84.04</td>\n",
       "      <td>84.04</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004918</td>\n",
       "      <td>-0.004958</td>\n",
       "      <td>0.004976</td>\n",
       "      <td>-0.004900</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>-0.010019</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>-0.007173</td>\n",
       "      <td>0.035488</td>\n",
       "      <td>0.025612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-20</td>\n",
       "      <td>82.17</td>\n",
       "      <td>83.75</td>\n",
       "      <td>82.17</td>\n",
       "      <td>83.75</td>\n",
       "      <td>83.75</td>\n",
       "      <td>742.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.922843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004433</td>\n",
       "      <td>-0.014432</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>-0.016684</td>\n",
       "      <td>-0.003890</td>\n",
       "      <td>-0.022756</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.018934</td>\n",
       "      <td>0.033823</td>\n",
       "      <td>0.014958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>82.66</td>\n",
       "      <td>83.86</td>\n",
       "      <td>82.66</td>\n",
       "      <td>83.70</td>\n",
       "      <td>83.70</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.258166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005305</td>\n",
       "      <td>-0.007121</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>-0.011141</td>\n",
       "      <td>-0.005119</td>\n",
       "      <td>-0.017545</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>-0.012485</td>\n",
       "      <td>0.034876</td>\n",
       "      <td>0.022450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  1. open  2. high  3. low  4. close  5. adjusted close  \\\n",
       "index                                                                      \n",
       "0      2022-12-23    83.41    83.72   83.24     83.65              83.65   \n",
       "1      2022-12-22    84.20    84.20   83.01     83.29              83.29   \n",
       "2      2022-12-21    83.21    84.20   83.21     84.04              84.04   \n",
       "3      2022-12-20    82.17    83.75   82.17     83.75              83.75   \n",
       "4      2022-12-19    82.66    83.86   82.66     83.70              83.70   \n",
       "\n",
       "       6. volume  7. dividend amount  8. split coefficient  day_pcent_change  \\\n",
       "index                                                                          \n",
       "0          431.0                 0.0                   1.0          0.287735   \n",
       "1          443.0                 0.0                   1.0         -1.080760   \n",
       "2           60.0                 0.0                   1.0          0.997476   \n",
       "3          742.0                 0.0                   1.0          1.922843   \n",
       "4          281.0                 0.0                   1.0          1.258166   \n",
       "\n",
       "       ...  WMA_5_pcent_diff_to_close  WMA_5_pcent_diff_to_open  \\\n",
       "index  ...                                                        \n",
       "0      ...                   0.000016                 -0.002854   \n",
       "1      ...                  -0.003650                  0.007276   \n",
       "2      ...                   0.004918                 -0.004958   \n",
       "3      ...                   0.004433                 -0.014432   \n",
       "4      ...                   0.005305                 -0.007121   \n",
       "\n",
       "       WMA_10_pcent_diff_to_close  WMA_10_pcent_diff_to_open  \\\n",
       "index                                                          \n",
       "0                        0.001256                  -0.001613   \n",
       "1                       -0.003178                   0.007748   \n",
       "2                        0.004976                  -0.004900   \n",
       "3                        0.002181                  -0.016684   \n",
       "4                        0.001284                  -0.011141   \n",
       "\n",
       "       WMA_20_pcent_diff_to_close  WMA_20_pcent_diff_to_open  \\\n",
       "index                                                          \n",
       "0                       -0.002972                  -0.005841   \n",
       "1                       -0.007997                   0.002928   \n",
       "2                       -0.000143                  -0.010019   \n",
       "3                       -0.003890                  -0.022756   \n",
       "4                       -0.005119                  -0.017545   \n",
       "\n",
       "       WMA_40_pcent_diff_to_close  WMA_40_pcent_diff_to_open  \\\n",
       "index                                                          \n",
       "0                       -0.002449                  -0.005319   \n",
       "1                       -0.006450                   0.004476   \n",
       "2                        0.002703                  -0.007173   \n",
       "3                       -0.000068                  -0.018934   \n",
       "4                       -0.000060                  -0.012485   \n",
       "\n",
       "       WMA_80_pcent_diff_to_close  WMA_80_pcent_diff_to_open  \n",
       "index                                                         \n",
       "0                        0.028086                   0.025217  \n",
       "1                        0.025379                   0.036304  \n",
       "2                        0.035488                   0.025612  \n",
       "3                        0.033823                   0.014958  \n",
       "4                        0.034876                   0.022450  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f447463f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************\n",
    "# Now get bollinger band details - need to study this more and figure out what it means\n",
    "# https://www.tradingview.com/support/solutions/43000501972-bollinger-bands-width-bbw/\n",
    "\n",
    "# calculate the bollinger band width then look at it the difference over the last 6 months\n",
    "# Bollinger Bands Width = (Upper Band - Lower Band) / Middle Band\n",
    "\n",
    "# look for: The low volatility period is followed by a surge in volatility and \n",
    "# price breaks through the Upper Band or falls through the Lower Band signifying a \n",
    "# change in the sideways movement and the beginning of a new directional trend.\n",
    "\n",
    "\n",
    "# In a Bullish BBW Squeeze\n",
    "\n",
    "# BBW drops. (In the example below, the threshold is 6% however this changes from security to security and \n",
    "#             timeframe to timeframe)\n",
    "# Price breaks through the Upper Band which starts a new upward trend. Volatility also increases.\n",
    "\n",
    "\n",
    "# In a Bearish BBW Squeeze\n",
    "\n",
    "# BBW drops. (In the example below, the threshold is 9% however this changes from security to \n",
    "#             security and timeframe to timeframe).\n",
    "# Price falls below the Lower Band which starts a new downward trend. Volatility also increases.\n",
    "        \n",
    "bb = TechIndicators(key=API_KEY, output_format='pandas')\n",
    "bb_data, bb_meta_data = bb.get_bbands(symbol, interval='daily', time_period=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f917e3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Real Upper Band</th>\n",
       "      <th>Real Middle Band</th>\n",
       "      <th>Real Lower Band</th>\n",
       "      <th>bb_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>86.2285</td>\n",
       "      <td>84.2410</td>\n",
       "      <td>82.2535</td>\n",
       "      <td>0.047186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-22</td>\n",
       "      <td>86.2293</td>\n",
       "      <td>84.2540</td>\n",
       "      <td>82.2787</td>\n",
       "      <td>0.046889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-21</td>\n",
       "      <td>86.2236</td>\n",
       "      <td>84.2975</td>\n",
       "      <td>82.3714</td>\n",
       "      <td>0.045698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-20</td>\n",
       "      <td>86.2211</td>\n",
       "      <td>84.2890</td>\n",
       "      <td>82.3569</td>\n",
       "      <td>0.045845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>86.2235</td>\n",
       "      <td>84.3035</td>\n",
       "      <td>82.3835</td>\n",
       "      <td>0.045550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  Real Upper Band  Real Middle Band  Real Lower Band  bb_width\n",
       "0 2022-12-23          86.2285           84.2410          82.2535  0.047186\n",
       "1 2022-12-22          86.2293           84.2540          82.2787  0.046889\n",
       "2 2022-12-21          86.2236           84.2975          82.3714  0.045698\n",
       "3 2022-12-20          86.2211           84.2890          82.3569  0.045845\n",
       "4 2022-12-19          86.2235           84.3035          82.3835  0.045550"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_data['bb_width'] = (bb_data['Real Upper Band'] - bb_data['Real Lower Band']) / bb_data['Real Middle Band']\n",
    "bb_data.reset_index(inplace=True)\n",
    "bb_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "545aa4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_data['bb_width'] = bb_data['bb_width']\n",
    "adjusted_data['bb_upper'] = bb_data['Real Upper Band']\n",
    "adjusted_data['bb_lower'] = bb_data['Real Lower Band']\n",
    "# add the below to percentages like day_pcent_change?\n",
    "adjusted_data['pcent_diff_to_bb_upper'] = (adjusted_data['4. close'] - adjusted_data['bb_upper']) / adjusted_data['4. close']\n",
    "adjusted_data['pcent_diff_to_bb_lower'] = (adjusted_data['4. close'] - adjusted_data['bb_lower']) / adjusted_data['4. close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "98bd65f6-3193-4b51-871f-5efbda9b8f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Don't seem to be able to get this with sufficient historical data\n",
    "# sp = SectorPerformances(key=API_KEY, output_format='pandas')\n",
    "# sp_data, sp_meta_data = sp.get_sector()\n",
    "# sp_data.head()\n",
    "# # sp_data['Rank A: Real-Time Performance'].plot(kind='bar')\n",
    "# # plt.title('Real Time Performance (%) per Sector')\n",
    "# # plt.tight_layout()\n",
    "# # plt.grid()\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "988ca236",
   "metadata": {},
   "outputs": [],
   "source": [
    "macd = TechIndicators(key=API_KEY, output_format='pandas')\n",
    "sleep(sleep_time)\n",
    "macd_data, macd_meta_data = bb.get_macd(symbol, series_type='close', interval='daily')\n",
    "macd_data.reset_index(inplace=True)\n",
    "adjusted_data['macd_signal'] = macd_data['MACD_Signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a42f16c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stochrsi = TechIndicators(key=API_KEY, output_format='pandas')\n",
    "sleep(sleep_time)\n",
    "stochrsi_data, stochrsi_meta_data = bb.get_stochrsi(symbol, series_type='close', interval='daily', time_period=10, fastkperiod=6, fastdmatype=1)\n",
    "stochrsi_data.reset_index(inplace=True)\n",
    "adjusted_data['stochrsi_fast_k'] = stochrsi_data['FastK']\n",
    "adjusted_data['stochrsi_fast_d'] = stochrsi_data['FastD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a1690899",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo = TechIndicators(key=API_KEY, output_format='pandas')\n",
    "sleep(sleep_time)\n",
    "ppo_data, ppo_meta_data = bb.get_ppo(symbol, series_type='close', interval='daily', fastperiod=10, matype=1)\n",
    "ppo_data.reset_index(inplace=True)\n",
    "adjusted_data['ppo'] = ppo_data['PPO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "8bcf94e7-7187-4063-8d58-c48651f52de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. adjusted close</th>\n",
       "      <th>6. volume</th>\n",
       "      <th>7. dividend amount</th>\n",
       "      <th>8. split coefficient</th>\n",
       "      <th>day_pcent_change</th>\n",
       "      <th>...</th>\n",
       "      <th>WMA_80_pcent_diff_to_open</th>\n",
       "      <th>bb_width</th>\n",
       "      <th>bb_upper</th>\n",
       "      <th>bb_lower</th>\n",
       "      <th>pcent_diff_to_bb_upper</th>\n",
       "      <th>pcent_diff_to_bb_lower</th>\n",
       "      <th>macd_signal</th>\n",
       "      <th>stochrsi_fast_k</th>\n",
       "      <th>stochrsi_fast_d</th>\n",
       "      <th>ppo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>83.41</td>\n",
       "      <td>83.72</td>\n",
       "      <td>83.24</td>\n",
       "      <td>83.65</td>\n",
       "      <td>83.65</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.287735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025217</td>\n",
       "      <td>0.047186</td>\n",
       "      <td>86.2285</td>\n",
       "      <td>82.2535</td>\n",
       "      <td>-0.030825</td>\n",
       "      <td>0.016695</td>\n",
       "      <td>0.6142</td>\n",
       "      <td>72.6758</td>\n",
       "      <td>67.7966</td>\n",
       "      <td>-1.4906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-22</td>\n",
       "      <td>84.20</td>\n",
       "      <td>84.20</td>\n",
       "      <td>83.01</td>\n",
       "      <td>83.29</td>\n",
       "      <td>83.29</td>\n",
       "      <td>443.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.080760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036304</td>\n",
       "      <td>0.046889</td>\n",
       "      <td>86.2293</td>\n",
       "      <td>82.2787</td>\n",
       "      <td>-0.035290</td>\n",
       "      <td>0.012142</td>\n",
       "      <td>0.6855</td>\n",
       "      <td>44.1339</td>\n",
       "      <td>62.9174</td>\n",
       "      <td>-1.2474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-21</td>\n",
       "      <td>83.21</td>\n",
       "      <td>84.20</td>\n",
       "      <td>83.21</td>\n",
       "      <td>84.04</td>\n",
       "      <td>84.04</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025612</td>\n",
       "      <td>0.045698</td>\n",
       "      <td>86.2236</td>\n",
       "      <td>82.3714</td>\n",
       "      <td>-0.025983</td>\n",
       "      <td>0.019855</td>\n",
       "      <td>0.7657</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>81.7008</td>\n",
       "      <td>-1.1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-20</td>\n",
       "      <td>82.17</td>\n",
       "      <td>83.75</td>\n",
       "      <td>82.17</td>\n",
       "      <td>83.75</td>\n",
       "      <td>83.75</td>\n",
       "      <td>742.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.922843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014958</td>\n",
       "      <td>0.045845</td>\n",
       "      <td>86.2211</td>\n",
       "      <td>82.3569</td>\n",
       "      <td>-0.029506</td>\n",
       "      <td>0.016634</td>\n",
       "      <td>0.8469</td>\n",
       "      <td>88.6782</td>\n",
       "      <td>63.4016</td>\n",
       "      <td>-0.8960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>82.66</td>\n",
       "      <td>83.86</td>\n",
       "      <td>82.66</td>\n",
       "      <td>83.70</td>\n",
       "      <td>83.70</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.258166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022450</td>\n",
       "      <td>0.045550</td>\n",
       "      <td>86.2235</td>\n",
       "      <td>82.3835</td>\n",
       "      <td>-0.030149</td>\n",
       "      <td>0.015729</td>\n",
       "      <td>0.9447</td>\n",
       "      <td>67.6404</td>\n",
       "      <td>38.1249</td>\n",
       "      <td>-0.7531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            index  1. open  2. high  3. low  4. close  5. adjusted close  \\\n",
       "index                                                                      \n",
       "0      2022-12-23    83.41    83.72   83.24     83.65              83.65   \n",
       "1      2022-12-22    84.20    84.20   83.01     83.29              83.29   \n",
       "2      2022-12-21    83.21    84.20   83.21     84.04              84.04   \n",
       "3      2022-12-20    82.17    83.75   82.17     83.75              83.75   \n",
       "4      2022-12-19    82.66    83.86   82.66     83.70              83.70   \n",
       "\n",
       "       6. volume  7. dividend amount  8. split coefficient  day_pcent_change  \\\n",
       "index                                                                          \n",
       "0          431.0                 0.0                   1.0          0.287735   \n",
       "1          443.0                 0.0                   1.0         -1.080760   \n",
       "2           60.0                 0.0                   1.0          0.997476   \n",
       "3          742.0                 0.0                   1.0          1.922843   \n",
       "4          281.0                 0.0                   1.0          1.258166   \n",
       "\n",
       "       ...  WMA_80_pcent_diff_to_open  bb_width  bb_upper  bb_lower  \\\n",
       "index  ...                                                            \n",
       "0      ...                   0.025217  0.047186   86.2285   82.2535   \n",
       "1      ...                   0.036304  0.046889   86.2293   82.2787   \n",
       "2      ...                   0.025612  0.045698   86.2236   82.3714   \n",
       "3      ...                   0.014958  0.045845   86.2211   82.3569   \n",
       "4      ...                   0.022450  0.045550   86.2235   82.3835   \n",
       "\n",
       "       pcent_diff_to_bb_upper  pcent_diff_to_bb_lower  macd_signal  \\\n",
       "index                                                                \n",
       "0                   -0.030825                0.016695       0.6142   \n",
       "1                   -0.035290                0.012142       0.6855   \n",
       "2                   -0.025983                0.019855       0.7657   \n",
       "3                   -0.029506                0.016634       0.8469   \n",
       "4                   -0.030149                0.015729       0.9447   \n",
       "\n",
       "       stochrsi_fast_k  stochrsi_fast_d     ppo  \n",
       "index                                            \n",
       "0              72.6758          67.7966 -1.4906  \n",
       "1              44.1339          62.9174 -1.2474  \n",
       "2             100.0000          81.7008 -1.1117  \n",
       "3              88.6782          63.4016 -0.8960  \n",
       "4              67.6404          38.1249 -0.7531  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "78b4929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up NaNs\n",
    "final_data = adjusted_data.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4e201bd6-94a6-4e0c-8571-c8b026872eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. adjusted close</th>\n",
       "      <th>6. volume</th>\n",
       "      <th>7. dividend amount</th>\n",
       "      <th>8. split coefficient</th>\n",
       "      <th>day_pcent_change</th>\n",
       "      <th>...</th>\n",
       "      <th>WMA_80_pcent_diff_to_open</th>\n",
       "      <th>bb_width</th>\n",
       "      <th>bb_upper</th>\n",
       "      <th>bb_lower</th>\n",
       "      <th>pcent_diff_to_bb_upper</th>\n",
       "      <th>pcent_diff_to_bb_lower</th>\n",
       "      <th>macd_signal</th>\n",
       "      <th>stochrsi_fast_k</th>\n",
       "      <th>stochrsi_fast_d</th>\n",
       "      <th>ppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-23</td>\n",
       "      <td>83.41</td>\n",
       "      <td>83.72</td>\n",
       "      <td>83.24</td>\n",
       "      <td>83.65</td>\n",
       "      <td>83.65</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.287735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025217</td>\n",
       "      <td>0.047186</td>\n",
       "      <td>86.2285</td>\n",
       "      <td>82.2535</td>\n",
       "      <td>-0.030825</td>\n",
       "      <td>0.016695</td>\n",
       "      <td>0.6142</td>\n",
       "      <td>72.6758</td>\n",
       "      <td>67.7966</td>\n",
       "      <td>-1.4906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-22</td>\n",
       "      <td>84.20</td>\n",
       "      <td>84.20</td>\n",
       "      <td>83.01</td>\n",
       "      <td>83.29</td>\n",
       "      <td>83.29</td>\n",
       "      <td>443.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.080760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036304</td>\n",
       "      <td>0.046889</td>\n",
       "      <td>86.2293</td>\n",
       "      <td>82.2787</td>\n",
       "      <td>-0.035290</td>\n",
       "      <td>0.012142</td>\n",
       "      <td>0.6855</td>\n",
       "      <td>44.1339</td>\n",
       "      <td>62.9174</td>\n",
       "      <td>-1.2474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-21</td>\n",
       "      <td>83.21</td>\n",
       "      <td>84.20</td>\n",
       "      <td>83.21</td>\n",
       "      <td>84.04</td>\n",
       "      <td>84.04</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025612</td>\n",
       "      <td>0.045698</td>\n",
       "      <td>86.2236</td>\n",
       "      <td>82.3714</td>\n",
       "      <td>-0.025983</td>\n",
       "      <td>0.019855</td>\n",
       "      <td>0.7657</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>81.7008</td>\n",
       "      <td>-1.1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-20</td>\n",
       "      <td>82.17</td>\n",
       "      <td>83.75</td>\n",
       "      <td>82.17</td>\n",
       "      <td>83.75</td>\n",
       "      <td>83.75</td>\n",
       "      <td>742.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.922843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014958</td>\n",
       "      <td>0.045845</td>\n",
       "      <td>86.2211</td>\n",
       "      <td>82.3569</td>\n",
       "      <td>-0.029506</td>\n",
       "      <td>0.016634</td>\n",
       "      <td>0.8469</td>\n",
       "      <td>88.6782</td>\n",
       "      <td>63.4016</td>\n",
       "      <td>-0.8960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>82.66</td>\n",
       "      <td>83.86</td>\n",
       "      <td>82.66</td>\n",
       "      <td>83.70</td>\n",
       "      <td>83.70</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.258166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022450</td>\n",
       "      <td>0.045550</td>\n",
       "      <td>86.2235</td>\n",
       "      <td>82.3835</td>\n",
       "      <td>-0.030149</td>\n",
       "      <td>0.015729</td>\n",
       "      <td>0.9447</td>\n",
       "      <td>67.6404</td>\n",
       "      <td>38.1249</td>\n",
       "      <td>-0.7531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  1. open  2. high  3. low  4. close  5. adjusted close  \\\n",
       "0  2022-12-23    83.41    83.72   83.24     83.65              83.65   \n",
       "1  2022-12-22    84.20    84.20   83.01     83.29              83.29   \n",
       "2  2022-12-21    83.21    84.20   83.21     84.04              84.04   \n",
       "3  2022-12-20    82.17    83.75   82.17     83.75              83.75   \n",
       "4  2022-12-19    82.66    83.86   82.66     83.70              83.70   \n",
       "\n",
       "   6. volume  7. dividend amount  8. split coefficient  day_pcent_change  ...  \\\n",
       "0      431.0                 0.0                   1.0          0.287735  ...   \n",
       "1      443.0                 0.0                   1.0         -1.080760  ...   \n",
       "2       60.0                 0.0                   1.0          0.997476  ...   \n",
       "3      742.0                 0.0                   1.0          1.922843  ...   \n",
       "4      281.0                 0.0                   1.0          1.258166  ...   \n",
       "\n",
       "   WMA_80_pcent_diff_to_open  bb_width  bb_upper  bb_lower  \\\n",
       "0                   0.025217  0.047186   86.2285   82.2535   \n",
       "1                   0.036304  0.046889   86.2293   82.2787   \n",
       "2                   0.025612  0.045698   86.2236   82.3714   \n",
       "3                   0.014958  0.045845   86.2211   82.3569   \n",
       "4                   0.022450  0.045550   86.2235   82.3835   \n",
       "\n",
       "   pcent_diff_to_bb_upper  pcent_diff_to_bb_lower  macd_signal  \\\n",
       "0               -0.030825                0.016695       0.6142   \n",
       "1               -0.035290                0.012142       0.6855   \n",
       "2               -0.025983                0.019855       0.7657   \n",
       "3               -0.029506                0.016634       0.8469   \n",
       "4               -0.030149                0.015729       0.9447   \n",
       "\n",
       "   stochrsi_fast_k  stochrsi_fast_d     ppo  \n",
       "0          72.6758          67.7966 -1.4906  \n",
       "1          44.1339          62.9174 -1.2474  \n",
       "2         100.0000          81.7008 -1.1117  \n",
       "3          88.6782          63.4016 -0.8960  \n",
       "4          67.6404          38.1249 -0.7531  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ce9f3c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't need the dates\n",
    "final_data.drop(columns='index', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f5139615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. adjusted close</th>\n",
       "      <th>6. volume</th>\n",
       "      <th>7. dividend amount</th>\n",
       "      <th>8. split coefficient</th>\n",
       "      <th>day_pcent_change</th>\n",
       "      <th>buy_tomorrow</th>\n",
       "      <th>...</th>\n",
       "      <th>WMA_80_pcent_diff_to_open</th>\n",
       "      <th>bb_width</th>\n",
       "      <th>bb_upper</th>\n",
       "      <th>bb_lower</th>\n",
       "      <th>pcent_diff_to_bb_upper</th>\n",
       "      <th>pcent_diff_to_bb_lower</th>\n",
       "      <th>macd_signal</th>\n",
       "      <th>stochrsi_fast_k</th>\n",
       "      <th>stochrsi_fast_d</th>\n",
       "      <th>ppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84.20</td>\n",
       "      <td>84.20</td>\n",
       "      <td>83.01</td>\n",
       "      <td>83.29</td>\n",
       "      <td>83.29</td>\n",
       "      <td>443.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.080760</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036304</td>\n",
       "      <td>0.046889</td>\n",
       "      <td>86.2293</td>\n",
       "      <td>82.2787</td>\n",
       "      <td>-0.035290</td>\n",
       "      <td>0.012142</td>\n",
       "      <td>0.6855</td>\n",
       "      <td>44.1339</td>\n",
       "      <td>62.9174</td>\n",
       "      <td>-1.2474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83.21</td>\n",
       "      <td>84.20</td>\n",
       "      <td>83.21</td>\n",
       "      <td>84.04</td>\n",
       "      <td>84.04</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997476</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025612</td>\n",
       "      <td>0.045698</td>\n",
       "      <td>86.2236</td>\n",
       "      <td>82.3714</td>\n",
       "      <td>-0.025983</td>\n",
       "      <td>0.019855</td>\n",
       "      <td>0.7657</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>81.7008</td>\n",
       "      <td>-1.1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82.17</td>\n",
       "      <td>83.75</td>\n",
       "      <td>82.17</td>\n",
       "      <td>83.75</td>\n",
       "      <td>83.75</td>\n",
       "      <td>742.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.922843</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014958</td>\n",
       "      <td>0.045845</td>\n",
       "      <td>86.2211</td>\n",
       "      <td>82.3569</td>\n",
       "      <td>-0.029506</td>\n",
       "      <td>0.016634</td>\n",
       "      <td>0.8469</td>\n",
       "      <td>88.6782</td>\n",
       "      <td>63.4016</td>\n",
       "      <td>-0.8960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82.66</td>\n",
       "      <td>83.86</td>\n",
       "      <td>82.66</td>\n",
       "      <td>83.70</td>\n",
       "      <td>83.70</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.258166</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022450</td>\n",
       "      <td>0.045550</td>\n",
       "      <td>86.2235</td>\n",
       "      <td>82.3835</td>\n",
       "      <td>-0.030149</td>\n",
       "      <td>0.015729</td>\n",
       "      <td>0.9447</td>\n",
       "      <td>67.6404</td>\n",
       "      <td>38.1249</td>\n",
       "      <td>-0.7531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>83.50</td>\n",
       "      <td>83.50</td>\n",
       "      <td>82.33</td>\n",
       "      <td>82.65</td>\n",
       "      <td>82.65</td>\n",
       "      <td>657.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.017964</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034571</td>\n",
       "      <td>0.045899</td>\n",
       "      <td>86.2280</td>\n",
       "      <td>82.3590</td>\n",
       "      <td>-0.043291</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>1.0563</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.6094</td>\n",
       "      <td>-0.7096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>83.86</td>\n",
       "      <td>83.86</td>\n",
       "      <td>82.80</td>\n",
       "      <td>82.80</td>\n",
       "      <td>82.80</td>\n",
       "      <td>695.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.264011</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040249</td>\n",
       "      <td>0.042389</td>\n",
       "      <td>86.1505</td>\n",
       "      <td>82.5745</td>\n",
       "      <td>-0.040465</td>\n",
       "      <td>0.002723</td>\n",
       "      <td>1.1831</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>17.2188</td>\n",
       "      <td>-0.6703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>83.92</td>\n",
       "      <td>84.31</td>\n",
       "      <td>83.53</td>\n",
       "      <td>83.58</td>\n",
       "      <td>83.58</td>\n",
       "      <td>907.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.405148</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042046</td>\n",
       "      <td>0.044880</td>\n",
       "      <td>86.2285</td>\n",
       "      <td>82.4435</td>\n",
       "      <td>-0.031688</td>\n",
       "      <td>0.013598</td>\n",
       "      <td>1.3005</td>\n",
       "      <td>28.5771</td>\n",
       "      <td>34.4376</td>\n",
       "      <td>-0.7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>84.96</td>\n",
       "      <td>85.00</td>\n",
       "      <td>83.98</td>\n",
       "      <td>84.18</td>\n",
       "      <td>84.18</td>\n",
       "      <td>1165.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.918079</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055808</td>\n",
       "      <td>0.047423</td>\n",
       "      <td>86.2907</td>\n",
       "      <td>82.2933</td>\n",
       "      <td>-0.025074</td>\n",
       "      <td>0.022413</td>\n",
       "      <td>1.4011</td>\n",
       "      <td>46.3193</td>\n",
       "      <td>40.2982</td>\n",
       "      <td>-0.7287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>83.95</td>\n",
       "      <td>84.54</td>\n",
       "      <td>83.95</td>\n",
       "      <td>84.54</td>\n",
       "      <td>84.54</td>\n",
       "      <td>733.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.702799</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045531</td>\n",
       "      <td>0.047432</td>\n",
       "      <td>86.3059</td>\n",
       "      <td>82.3071</td>\n",
       "      <td>-0.020888</td>\n",
       "      <td>0.026412</td>\n",
       "      <td>1.4911</td>\n",
       "      <td>43.0797</td>\n",
       "      <td>34.2772</td>\n",
       "      <td>-0.7640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>82.95</td>\n",
       "      <td>84.62</td>\n",
       "      <td>82.95</td>\n",
       "      <td>84.51</td>\n",
       "      <td>84.51</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.880651</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035771</td>\n",
       "      <td>0.047546</td>\n",
       "      <td>86.3189</td>\n",
       "      <td>82.3101</td>\n",
       "      <td>-0.021405</td>\n",
       "      <td>0.026031</td>\n",
       "      <td>1.5772</td>\n",
       "      <td>42.3920</td>\n",
       "      <td>25.4746</td>\n",
       "      <td>-0.7512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>84.75</td>\n",
       "      <td>84.75</td>\n",
       "      <td>82.84</td>\n",
       "      <td>82.84</td>\n",
       "      <td>82.84</td>\n",
       "      <td>616.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.253687</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060342</td>\n",
       "      <td>0.047541</td>\n",
       "      <td>86.3182</td>\n",
       "      <td>82.3098</td>\n",
       "      <td>-0.041987</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>1.6644</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.5572</td>\n",
       "      <td>-0.8857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>84.72</td>\n",
       "      <td>85.23</td>\n",
       "      <td>84.72</td>\n",
       "      <td>84.85</td>\n",
       "      <td>84.85</td>\n",
       "      <td>776.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.153447</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060161</td>\n",
       "      <td>0.048206</td>\n",
       "      <td>86.3370</td>\n",
       "      <td>82.2730</td>\n",
       "      <td>-0.017525</td>\n",
       "      <td>0.030371</td>\n",
       "      <td>1.7508</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>17.1145</td>\n",
       "      <td>-1.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>85.90</td>\n",
       "      <td>85.90</td>\n",
       "      <td>85.00</td>\n",
       "      <td>85.24</td>\n",
       "      <td>85.24</td>\n",
       "      <td>1162.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.768335</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075935</td>\n",
       "      <td>0.066048</td>\n",
       "      <td>86.8334</td>\n",
       "      <td>81.2816</td>\n",
       "      <td>-0.018693</td>\n",
       "      <td>0.046438</td>\n",
       "      <td>1.7926</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>34.2290</td>\n",
       "      <td>-1.1046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>85.10</td>\n",
       "      <td>86.00</td>\n",
       "      <td>85.10</td>\n",
       "      <td>86.00</td>\n",
       "      <td>86.00</td>\n",
       "      <td>637.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.057579</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068281</td>\n",
       "      <td>0.072998</td>\n",
       "      <td>86.8949</td>\n",
       "      <td>80.7751</td>\n",
       "      <td>-0.010406</td>\n",
       "      <td>0.060755</td>\n",
       "      <td>1.8170</td>\n",
       "      <td>78.1896</td>\n",
       "      <td>68.4580</td>\n",
       "      <td>-1.0652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>85.39</td>\n",
       "      <td>85.44</td>\n",
       "      <td>84.86</td>\n",
       "      <td>85.44</td>\n",
       "      <td>85.44</td>\n",
       "      <td>371.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.058555</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074706</td>\n",
       "      <td>0.076184</td>\n",
       "      <td>86.7523</td>\n",
       "      <td>80.3857</td>\n",
       "      <td>-0.015359</td>\n",
       "      <td>0.059156</td>\n",
       "      <td>1.8281</td>\n",
       "      <td>52.3383</td>\n",
       "      <td>58.7263</td>\n",
       "      <td>-1.0609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>86.70</td>\n",
       "      <td>87.32</td>\n",
       "      <td>84.51</td>\n",
       "      <td>85.40</td>\n",
       "      <td>85.40</td>\n",
       "      <td>2485.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.499423</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092529</td>\n",
       "      <td>0.084547</td>\n",
       "      <td>86.7922</td>\n",
       "      <td>79.7518</td>\n",
       "      <td>-0.016302</td>\n",
       "      <td>0.066138</td>\n",
       "      <td>1.8431</td>\n",
       "      <td>50.5261</td>\n",
       "      <td>65.1142</td>\n",
       "      <td>-0.9706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>84.99</td>\n",
       "      <td>86.10</td>\n",
       "      <td>84.99</td>\n",
       "      <td>86.00</td>\n",
       "      <td>86.00</td>\n",
       "      <td>1629.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.188375</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074447</td>\n",
       "      <td>0.106937</td>\n",
       "      <td>87.2609</td>\n",
       "      <td>78.4031</td>\n",
       "      <td>-0.014662</td>\n",
       "      <td>0.088336</td>\n",
       "      <td>1.8554</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>79.7023</td>\n",
       "      <td>-0.7504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>83.45</td>\n",
       "      <td>84.91</td>\n",
       "      <td>83.45</td>\n",
       "      <td>84.63</td>\n",
       "      <td>84.63</td>\n",
       "      <td>970.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.414020</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060145</td>\n",
       "      <td>0.105906</td>\n",
       "      <td>86.8902</td>\n",
       "      <td>78.1508</td>\n",
       "      <td>-0.026707</td>\n",
       "      <td>0.076559</td>\n",
       "      <td>1.8681</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>59.4045</td>\n",
       "      <td>-0.4977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>83.89</td>\n",
       "      <td>83.89</td>\n",
       "      <td>82.95</td>\n",
       "      <td>83.73</td>\n",
       "      <td>83.73</td>\n",
       "      <td>918.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.190726</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068391</td>\n",
       "      <td>0.105348</td>\n",
       "      <td>86.6535</td>\n",
       "      <td>77.9815</td>\n",
       "      <td>-0.034916</td>\n",
       "      <td>0.068655</td>\n",
       "      <td>1.9024</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>18.8091</td>\n",
       "      <td>-0.3326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>83.72</td>\n",
       "      <td>83.91</td>\n",
       "      <td>83.61</td>\n",
       "      <td>83.91</td>\n",
       "      <td>83.91</td>\n",
       "      <td>171.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.226947</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068315</td>\n",
       "      <td>0.108331</td>\n",
       "      <td>86.5549</td>\n",
       "      <td>77.6601</td>\n",
       "      <td>-0.031521</td>\n",
       "      <td>0.074483</td>\n",
       "      <td>1.9400</td>\n",
       "      <td>7.4191</td>\n",
       "      <td>37.6181</td>\n",
       "      <td>-0.2032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>84.59</td>\n",
       "      <td>84.59</td>\n",
       "      <td>83.89</td>\n",
       "      <td>84.16</td>\n",
       "      <td>84.16</td>\n",
       "      <td>670.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.508334</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080619</td>\n",
       "      <td>0.108847</td>\n",
       "      <td>86.3694</td>\n",
       "      <td>77.4536</td>\n",
       "      <td>-0.026252</td>\n",
       "      <td>0.079686</td>\n",
       "      <td>1.9640</td>\n",
       "      <td>85.2159</td>\n",
       "      <td>67.8172</td>\n",
       "      <td>-0.0140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>84.69</td>\n",
       "      <td>84.69</td>\n",
       "      <td>82.88</td>\n",
       "      <td>83.87</td>\n",
       "      <td>83.87</td>\n",
       "      <td>836.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.968237</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084369</td>\n",
       "      <td>0.108283</td>\n",
       "      <td>86.1165</td>\n",
       "      <td>77.2705</td>\n",
       "      <td>-0.026786</td>\n",
       "      <td>0.078687</td>\n",
       "      <td>1.9758</td>\n",
       "      <td>65.7970</td>\n",
       "      <td>50.4185</td>\n",
       "      <td>-0.0017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>82.98</td>\n",
       "      <td>84.25</td>\n",
       "      <td>82.98</td>\n",
       "      <td>84.04</td>\n",
       "      <td>84.04</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.277416</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066066</td>\n",
       "      <td>0.109343</td>\n",
       "      <td>85.9030</td>\n",
       "      <td>76.9970</td>\n",
       "      <td>-0.022168</td>\n",
       "      <td>0.083805</td>\n",
       "      <td>1.9807</td>\n",
       "      <td>40.9577</td>\n",
       "      <td>35.0399</td>\n",
       "      <td>0.4094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>84.09</td>\n",
       "      <td>84.09</td>\n",
       "      <td>83.50</td>\n",
       "      <td>83.50</td>\n",
       "      <td>83.50</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.701629</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082078</td>\n",
       "      <td>0.114067</td>\n",
       "      <td>85.7418</td>\n",
       "      <td>76.4892</td>\n",
       "      <td>-0.026848</td>\n",
       "      <td>0.083962</td>\n",
       "      <td>1.9740</td>\n",
       "      <td>22.8221</td>\n",
       "      <td>29.1220</td>\n",
       "      <td>0.8754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>83.16</td>\n",
       "      <td>84.03</td>\n",
       "      <td>83.16</td>\n",
       "      <td>84.03</td>\n",
       "      <td>84.03</td>\n",
       "      <td>293.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.046176</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072624</td>\n",
       "      <td>0.115788</td>\n",
       "      <td>85.5207</td>\n",
       "      <td>76.1603</td>\n",
       "      <td>-0.017740</td>\n",
       "      <td>0.093653</td>\n",
       "      <td>1.9608</td>\n",
       "      <td>44.0919</td>\n",
       "      <td>35.4219</td>\n",
       "      <td>1.1910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>83.40</td>\n",
       "      <td>83.40</td>\n",
       "      <td>81.85</td>\n",
       "      <td>82.27</td>\n",
       "      <td>82.27</td>\n",
       "      <td>595.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.354916</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.079449</td>\n",
       "      <td>0.115322</td>\n",
       "      <td>85.1618</td>\n",
       "      <td>75.8762</td>\n",
       "      <td>-0.035150</td>\n",
       "      <td>0.077717</td>\n",
       "      <td>1.9318</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>26.7519</td>\n",
       "      <td>1.3960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>85.11</td>\n",
       "      <td>85.11</td>\n",
       "      <td>81.56</td>\n",
       "      <td>82.70</td>\n",
       "      <td>82.70</td>\n",
       "      <td>2046.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.831630</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101545</td>\n",
       "      <td>0.117071</td>\n",
       "      <td>85.0025</td>\n",
       "      <td>75.6015</td>\n",
       "      <td>-0.027842</td>\n",
       "      <td>0.085834</td>\n",
       "      <td>1.9006</td>\n",
       "      <td>14.9057</td>\n",
       "      <td>53.5039</td>\n",
       "      <td>1.4416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>85.57</td>\n",
       "      <td>85.57</td>\n",
       "      <td>83.38</td>\n",
       "      <td>84.47</td>\n",
       "      <td>84.47</td>\n",
       "      <td>28716.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.285497</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106802</td>\n",
       "      <td>0.118968</td>\n",
       "      <td>84.7831</td>\n",
       "      <td>75.2629</td>\n",
       "      <td>-0.003707</td>\n",
       "      <td>0.108998</td>\n",
       "      <td>1.8308</td>\n",
       "      <td>89.5151</td>\n",
       "      <td>92.1021</td>\n",
       "      <td>1.3827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>84.54</td>\n",
       "      <td>85.34</td>\n",
       "      <td>84.54</td>\n",
       "      <td>84.70</td>\n",
       "      <td>84.70</td>\n",
       "      <td>28981.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.189260</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096835</td>\n",
       "      <td>0.110040</td>\n",
       "      <td>84.0756</td>\n",
       "      <td>75.3064</td>\n",
       "      <td>0.007372</td>\n",
       "      <td>0.110904</td>\n",
       "      <td>1.7232</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>94.6891</td>\n",
       "      <td>1.4245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>84.00</td>\n",
       "      <td>84.50</td>\n",
       "      <td>83.46</td>\n",
       "      <td>84.50</td>\n",
       "      <td>84.50</td>\n",
       "      <td>66920.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093256</td>\n",
       "      <td>0.099948</td>\n",
       "      <td>83.2372</td>\n",
       "      <td>75.3138</td>\n",
       "      <td>0.014944</td>\n",
       "      <td>0.108712</td>\n",
       "      <td>1.6158</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>89.3782</td>\n",
       "      <td>1.5793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>80.47</td>\n",
       "      <td>82.77</td>\n",
       "      <td>80.47</td>\n",
       "      <td>82.66</td>\n",
       "      <td>82.66</td>\n",
       "      <td>39255.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.721511</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055235</td>\n",
       "      <td>0.092521</td>\n",
       "      <td>82.4359</td>\n",
       "      <td>75.1461</td>\n",
       "      <td>0.002711</td>\n",
       "      <td>0.090901</td>\n",
       "      <td>1.5298</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>78.7564</td>\n",
       "      <td>1.8413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>80.58</td>\n",
       "      <td>80.58</td>\n",
       "      <td>79.57</td>\n",
       "      <td>79.90</td>\n",
       "      <td>79.90</td>\n",
       "      <td>20517.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.843882</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060672</td>\n",
       "      <td>0.093917</td>\n",
       "      <td>82.0559</td>\n",
       "      <td>74.6951</td>\n",
       "      <td>-0.026982</td>\n",
       "      <td>0.065143</td>\n",
       "      <td>1.4862</td>\n",
       "      <td>59.7187</td>\n",
       "      <td>57.5127</td>\n",
       "      <td>2.0658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>80.78</td>\n",
       "      <td>80.92</td>\n",
       "      <td>80.27</td>\n",
       "      <td>80.79</td>\n",
       "      <td>80.79</td>\n",
       "      <td>24057.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.012379</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063775</td>\n",
       "      <td>0.109592</td>\n",
       "      <td>82.3089</td>\n",
       "      <td>73.7571</td>\n",
       "      <td>-0.018801</td>\n",
       "      <td>0.087052</td>\n",
       "      <td>1.4725</td>\n",
       "      <td>62.9194</td>\n",
       "      <td>55.3067</td>\n",
       "      <td>2.1899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>80.09</td>\n",
       "      <td>81.00</td>\n",
       "      <td>79.38</td>\n",
       "      <td>80.68</td>\n",
       "      <td>80.68</td>\n",
       "      <td>54845.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.736671</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056889</td>\n",
       "      <td>0.121177</td>\n",
       "      <td>82.3234</td>\n",
       "      <td>72.9176</td>\n",
       "      <td>-0.020369</td>\n",
       "      <td>0.096212</td>\n",
       "      <td>1.4426</td>\n",
       "      <td>61.5570</td>\n",
       "      <td>47.6940</td>\n",
       "      <td>2.2059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>77.15</td>\n",
       "      <td>79.76</td>\n",
       "      <td>77.15</td>\n",
       "      <td>79.50</td>\n",
       "      <td>79.50</td>\n",
       "      <td>35986.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.046014</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022343</td>\n",
       "      <td>0.128068</td>\n",
       "      <td>82.1663</td>\n",
       "      <td>72.2767</td>\n",
       "      <td>-0.033538</td>\n",
       "      <td>0.090859</td>\n",
       "      <td>1.4175</td>\n",
       "      <td>46.3335</td>\n",
       "      <td>33.8310</td>\n",
       "      <td>2.2029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>79.29</td>\n",
       "      <td>79.71</td>\n",
       "      <td>75.39</td>\n",
       "      <td>76.60</td>\n",
       "      <td>76.60</td>\n",
       "      <td>55498.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.392609</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052415</td>\n",
       "      <td>0.140968</td>\n",
       "      <td>82.2362</td>\n",
       "      <td>71.4068</td>\n",
       "      <td>-0.073580</td>\n",
       "      <td>0.067796</td>\n",
       "      <td>1.4048</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>21.3284</td>\n",
       "      <td>2.0583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>80.62</td>\n",
       "      <td>80.62</td>\n",
       "      <td>79.77</td>\n",
       "      <td>79.77</td>\n",
       "      <td>79.77</td>\n",
       "      <td>17510.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.054329</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067360</td>\n",
       "      <td>0.151193</td>\n",
       "      <td>82.3880</td>\n",
       "      <td>70.8070</td>\n",
       "      <td>-0.032819</td>\n",
       "      <td>0.112361</td>\n",
       "      <td>1.3877</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>42.6568</td>\n",
       "      <td>1.9549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>79.83</td>\n",
       "      <td>81.00</td>\n",
       "      <td>79.83</td>\n",
       "      <td>80.57</td>\n",
       "      <td>80.57</td>\n",
       "      <td>22698.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.926970</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058236</td>\n",
       "      <td>0.156392</td>\n",
       "      <td>82.1569</td>\n",
       "      <td>70.2401</td>\n",
       "      <td>-0.019696</td>\n",
       "      <td>0.128210</td>\n",
       "      <td>1.2966</td>\n",
       "      <td>96.8177</td>\n",
       "      <td>85.3137</td>\n",
       "      <td>1.8067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>80.09</td>\n",
       "      <td>80.09</td>\n",
       "      <td>79.11</td>\n",
       "      <td>79.53</td>\n",
       "      <td>79.53</td>\n",
       "      <td>15564.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.699213</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063905</td>\n",
       "      <td>0.152045</td>\n",
       "      <td>81.5808</td>\n",
       "      <td>70.0532</td>\n",
       "      <td>-0.025786</td>\n",
       "      <td>0.119160</td>\n",
       "      <td>1.1806</td>\n",
       "      <td>56.9304</td>\n",
       "      <td>73.8096</td>\n",
       "      <td>1.7504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>79.37</td>\n",
       "      <td>79.99</td>\n",
       "      <td>78.18</td>\n",
       "      <td>79.99</td>\n",
       "      <td>79.99</td>\n",
       "      <td>26589.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.781152</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055867</td>\n",
       "      <td>0.156587</td>\n",
       "      <td>81.2796</td>\n",
       "      <td>69.4764</td>\n",
       "      <td>-0.016122</td>\n",
       "      <td>0.131436</td>\n",
       "      <td>1.0597</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>90.6887</td>\n",
       "      <td>1.6467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>78.97</td>\n",
       "      <td>79.80</td>\n",
       "      <td>78.92</td>\n",
       "      <td>79.80</td>\n",
       "      <td>79.80</td>\n",
       "      <td>29404.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.051032</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052480</td>\n",
       "      <td>0.160162</td>\n",
       "      <td>80.8592</td>\n",
       "      <td>68.8688</td>\n",
       "      <td>-0.013273</td>\n",
       "      <td>0.136982</td>\n",
       "      <td>0.9190</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>81.3775</td>\n",
       "      <td>1.5613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>78.32</td>\n",
       "      <td>79.20</td>\n",
       "      <td>78.29</td>\n",
       "      <td>79.00</td>\n",
       "      <td>79.00</td>\n",
       "      <td>14776.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.868233</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046251</td>\n",
       "      <td>0.163196</td>\n",
       "      <td>80.3887</td>\n",
       "      <td>68.2593</td>\n",
       "      <td>-0.017578</td>\n",
       "      <td>0.135958</td>\n",
       "      <td>0.7741</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>62.7550</td>\n",
       "      <td>1.3673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>78.07</td>\n",
       "      <td>78.07</td>\n",
       "      <td>77.35</td>\n",
       "      <td>77.35</td>\n",
       "      <td>77.35</td>\n",
       "      <td>13666.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.922249</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045280</td>\n",
       "      <td>0.154862</td>\n",
       "      <td>79.7148</td>\n",
       "      <td>68.2572</td>\n",
       "      <td>-0.030573</td>\n",
       "      <td>0.117554</td>\n",
       "      <td>0.6328</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>25.5100</td>\n",
       "      <td>1.2267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>78.22</td>\n",
       "      <td>78.53</td>\n",
       "      <td>75.99</td>\n",
       "      <td>78.00</td>\n",
       "      <td>78.00</td>\n",
       "      <td>9297.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.281258</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047588</td>\n",
       "      <td>0.152687</td>\n",
       "      <td>79.3082</td>\n",
       "      <td>68.0578</td>\n",
       "      <td>-0.016772</td>\n",
       "      <td>0.127464</td>\n",
       "      <td>0.4918</td>\n",
       "      <td>33.3744</td>\n",
       "      <td>51.0200</td>\n",
       "      <td>1.0480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>77.19</td>\n",
       "      <td>77.60</td>\n",
       "      <td>76.67</td>\n",
       "      <td>77.60</td>\n",
       "      <td>77.60</td>\n",
       "      <td>8452.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.531157</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035557</td>\n",
       "      <td>0.144654</td>\n",
       "      <td>78.6863</td>\n",
       "      <td>68.0717</td>\n",
       "      <td>-0.013999</td>\n",
       "      <td>0.122787</td>\n",
       "      <td>0.3234</td>\n",
       "      <td>53.7374</td>\n",
       "      <td>68.6655</td>\n",
       "      <td>0.8923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>77.76</td>\n",
       "      <td>78.05</td>\n",
       "      <td>77.16</td>\n",
       "      <td>77.93</td>\n",
       "      <td>77.93</td>\n",
       "      <td>14063.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.218621</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043598</td>\n",
       "      <td>0.136571</td>\n",
       "      <td>78.0671</td>\n",
       "      <td>68.0869</td>\n",
       "      <td>-0.001759</td>\n",
       "      <td>0.126307</td>\n",
       "      <td>0.1434</td>\n",
       "      <td>80.9558</td>\n",
       "      <td>83.5937</td>\n",
       "      <td>0.7593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>78.00</td>\n",
       "      <td>78.00</td>\n",
       "      <td>77.12</td>\n",
       "      <td>77.12</td>\n",
       "      <td>77.12</td>\n",
       "      <td>21251.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.128205</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048178</td>\n",
       "      <td>0.124744</td>\n",
       "      <td>77.4687</td>\n",
       "      <td>68.3723</td>\n",
       "      <td>-0.004522</td>\n",
       "      <td>0.113430</td>\n",
       "      <td>-0.0487</td>\n",
       "      <td>72.9086</td>\n",
       "      <td>86.2316</td>\n",
       "      <td>0.3780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>77.33</td>\n",
       "      <td>78.63</td>\n",
       "      <td>77.33</td>\n",
       "      <td>77.83</td>\n",
       "      <td>77.83</td>\n",
       "      <td>42023.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.646580</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039884</td>\n",
       "      <td>0.115236</td>\n",
       "      <td>76.9835</td>\n",
       "      <td>68.5955</td>\n",
       "      <td>0.010876</td>\n",
       "      <td>0.118650</td>\n",
       "      <td>-0.2354</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>99.5545</td>\n",
       "      <td>-0.1044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>75.28</td>\n",
       "      <td>76.78</td>\n",
       "      <td>74.85</td>\n",
       "      <td>76.39</td>\n",
       "      <td>76.39</td>\n",
       "      <td>21553.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.474495</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014804</td>\n",
       "      <td>0.100831</td>\n",
       "      <td>76.3111</td>\n",
       "      <td>68.9859</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>0.096925</td>\n",
       "      <td>-0.4185</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>99.1091</td>\n",
       "      <td>-0.4234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>75.10</td>\n",
       "      <td>76.00</td>\n",
       "      <td>74.53</td>\n",
       "      <td>74.81</td>\n",
       "      <td>74.81</td>\n",
       "      <td>19772.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.386152</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013264</td>\n",
       "      <td>0.093703</td>\n",
       "      <td>75.9716</td>\n",
       "      <td>69.1714</td>\n",
       "      <td>-0.015527</td>\n",
       "      <td>0.075372</td>\n",
       "      <td>-0.5633</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>98.2181</td>\n",
       "      <td>-0.7079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>72.57</td>\n",
       "      <td>74.35</td>\n",
       "      <td>72.30</td>\n",
       "      <td>74.35</td>\n",
       "      <td>74.35</td>\n",
       "      <td>26303.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.452804</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020651</td>\n",
       "      <td>0.091637</td>\n",
       "      <td>75.8616</td>\n",
       "      <td>69.2144</td>\n",
       "      <td>-0.020331</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>-0.6732</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>96.4362</td>\n",
       "      <td>-0.9216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>72.38</td>\n",
       "      <td>73.05</td>\n",
       "      <td>71.50</td>\n",
       "      <td>73.05</td>\n",
       "      <td>73.05</td>\n",
       "      <td>17181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.925670</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023748</td>\n",
       "      <td>0.092551</td>\n",
       "      <td>75.9099</td>\n",
       "      <td>69.1951</td>\n",
       "      <td>-0.039150</td>\n",
       "      <td>0.052771</td>\n",
       "      <td>-0.7605</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>92.8725</td>\n",
       "      <td>-1.0976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>71.06</td>\n",
       "      <td>72.61</td>\n",
       "      <td>70.43</td>\n",
       "      <td>72.54</td>\n",
       "      <td>72.54</td>\n",
       "      <td>22322.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.082747</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042705</td>\n",
       "      <td>0.096146</td>\n",
       "      <td>76.1315</td>\n",
       "      <td>69.1475</td>\n",
       "      <td>-0.049511</td>\n",
       "      <td>0.046767</td>\n",
       "      <td>-0.8184</td>\n",
       "      <td>85.4438</td>\n",
       "      <td>85.7449</td>\n",
       "      <td>-1.1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>70.99</td>\n",
       "      <td>73.00</td>\n",
       "      <td>70.62</td>\n",
       "      <td>72.70</td>\n",
       "      <td>72.70</td>\n",
       "      <td>12109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.408790</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044369</td>\n",
       "      <td>0.098549</td>\n",
       "      <td>76.3216</td>\n",
       "      <td>69.1534</td>\n",
       "      <td>-0.049816</td>\n",
       "      <td>0.048784</td>\n",
       "      <td>-0.8606</td>\n",
       "      <td>99.4282</td>\n",
       "      <td>86.0460</td>\n",
       "      <td>-1.3139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>71.50</td>\n",
       "      <td>71.50</td>\n",
       "      <td>71.50</td>\n",
       "      <td>71.50</td>\n",
       "      <td>71.50</td>\n",
       "      <td>9316.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038758</td>\n",
       "      <td>0.105302</td>\n",
       "      <td>76.7351</td>\n",
       "      <td>69.0589</td>\n",
       "      <td>-0.073218</td>\n",
       "      <td>0.034141</td>\n",
       "      <td>-0.8901</td>\n",
       "      <td>63.9631</td>\n",
       "      <td>72.6638</td>\n",
       "      <td>-1.4934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>72.53</td>\n",
       "      <td>72.53</td>\n",
       "      <td>71.86</td>\n",
       "      <td>72.12</td>\n",
       "      <td>72.12</td>\n",
       "      <td>11953.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.565283</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025352</td>\n",
       "      <td>0.104006</td>\n",
       "      <td>76.8020</td>\n",
       "      <td>69.2090</td>\n",
       "      <td>-0.064920</td>\n",
       "      <td>0.040363</td>\n",
       "      <td>-0.8959</td>\n",
       "      <td>84.5120</td>\n",
       "      <td>81.3646</td>\n",
       "      <td>-1.7237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>72.47</td>\n",
       "      <td>72.47</td>\n",
       "      <td>71.00</td>\n",
       "      <td>71.79</td>\n",
       "      <td>71.79</td>\n",
       "      <td>16128.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.938319</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027327</td>\n",
       "      <td>0.103840</td>\n",
       "      <td>76.8028</td>\n",
       "      <td>69.2212</td>\n",
       "      <td>-0.069826</td>\n",
       "      <td>0.035782</td>\n",
       "      <td>-0.8973</td>\n",
       "      <td>77.1726</td>\n",
       "      <td>78.2172</td>\n",
       "      <td>-1.7408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>71.82</td>\n",
       "      <td>72.94</td>\n",
       "      <td>71.82</td>\n",
       "      <td>72.94</td>\n",
       "      <td>72.94</td>\n",
       "      <td>8491.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.559454</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036958</td>\n",
       "      <td>0.103041</td>\n",
       "      <td>76.8856</td>\n",
       "      <td>69.3514</td>\n",
       "      <td>-0.054094</td>\n",
       "      <td>0.049199</td>\n",
       "      <td>-0.8789</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>79.2618</td>\n",
       "      <td>-1.6241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>69.37</td>\n",
       "      <td>71.11</td>\n",
       "      <td>69.00</td>\n",
       "      <td>70.75</td>\n",
       "      <td>70.75</td>\n",
       "      <td>10827.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.989333</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073536</td>\n",
       "      <td>0.103074</td>\n",
       "      <td>76.8826</td>\n",
       "      <td>69.3464</td>\n",
       "      <td>-0.086680</td>\n",
       "      <td>0.019839</td>\n",
       "      <td>-0.8422</td>\n",
       "      <td>91.3892</td>\n",
       "      <td>58.5236</td>\n",
       "      <td>-1.4977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>69.00</td>\n",
       "      <td>70.35</td>\n",
       "      <td>69.00</td>\n",
       "      <td>69.71</td>\n",
       "      <td>69.71</td>\n",
       "      <td>22084.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.028986</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081564</td>\n",
       "      <td>0.098858</td>\n",
       "      <td>76.8266</td>\n",
       "      <td>69.5894</td>\n",
       "      <td>-0.102089</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>-0.7533</td>\n",
       "      <td>38.4738</td>\n",
       "      <td>25.6580</td>\n",
       "      <td>-1.2910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    1. open  2. high  3. low  4. close  5. adjusted close  6. volume  \\\n",
       "1     84.20    84.20   83.01     83.29              83.29      443.0   \n",
       "2     83.21    84.20   83.21     84.04              84.04       60.0   \n",
       "3     82.17    83.75   82.17     83.75              83.75      742.0   \n",
       "4     82.66    83.86   82.66     83.70              83.70      281.0   \n",
       "5     83.50    83.50   82.33     82.65              82.65      657.0   \n",
       "6     83.86    83.86   82.80     82.80              82.80      695.0   \n",
       "7     83.92    84.31   83.53     83.58              83.58      907.0   \n",
       "8     84.96    85.00   83.98     84.18              84.18     1165.0   \n",
       "9     83.95    84.54   83.95     84.54              84.54      733.0   \n",
       "10    82.95    84.62   82.95     84.51              84.51      219.0   \n",
       "11    84.75    84.75   82.84     82.84              82.84      616.0   \n",
       "12    84.72    85.23   84.72     84.85              84.85      776.0   \n",
       "13    85.90    85.90   85.00     85.24              85.24     1162.0   \n",
       "14    85.10    86.00   85.10     86.00              86.00      637.0   \n",
       "15    85.39    85.44   84.86     85.44              85.44      371.0   \n",
       "16    86.70    87.32   84.51     85.40              85.40     2485.0   \n",
       "17    84.99    86.10   84.99     86.00              86.00     1629.0   \n",
       "18    83.45    84.91   83.45     84.63              84.63      970.0   \n",
       "19    83.89    83.89   82.95     83.73              83.73      918.0   \n",
       "20    83.72    83.91   83.61     83.91              83.91      171.0   \n",
       "21    84.59    84.59   83.89     84.16              84.16      670.0   \n",
       "22    84.69    84.69   82.88     83.87              83.87      836.0   \n",
       "23    82.98    84.25   82.98     84.04              84.04      183.0   \n",
       "24    84.09    84.09   83.50     83.50              83.50     1102.0   \n",
       "25    83.16    84.03   83.16     84.03              84.03      293.0   \n",
       "26    83.40    83.40   81.85     82.27              82.27      595.0   \n",
       "27    85.11    85.11   81.56     82.70              82.70     2046.0   \n",
       "28    85.57    85.57   83.38     84.47              84.47    28716.0   \n",
       "29    84.54    85.34   84.54     84.70              84.70    28981.0   \n",
       "30    84.00    84.50   83.46     84.50              84.50    66920.0   \n",
       "31    80.47    82.77   80.47     82.66              82.66    39255.0   \n",
       "32    80.58    80.58   79.57     79.90              79.90    20517.0   \n",
       "33    80.78    80.92   80.27     80.79              80.79    24057.0   \n",
       "34    80.09    81.00   79.38     80.68              80.68    54845.0   \n",
       "35    77.15    79.76   77.15     79.50              79.50    35986.0   \n",
       "36    79.29    79.71   75.39     76.60              76.60    55498.0   \n",
       "37    80.62    80.62   79.77     79.77              79.77    17510.0   \n",
       "38    79.83    81.00   79.83     80.57              80.57    22698.0   \n",
       "39    80.09    80.09   79.11     79.53              79.53    15564.0   \n",
       "40    79.37    79.99   78.18     79.99              79.99    26589.0   \n",
       "41    78.97    79.80   78.92     79.80              79.80    29404.0   \n",
       "42    78.32    79.20   78.29     79.00              79.00    14776.0   \n",
       "43    78.07    78.07   77.35     77.35              77.35    13666.0   \n",
       "44    78.22    78.53   75.99     78.00              78.00     9297.0   \n",
       "45    77.19    77.60   76.67     77.60              77.60     8452.0   \n",
       "46    77.76    78.05   77.16     77.93              77.93    14063.0   \n",
       "47    78.00    78.00   77.12     77.12              77.12    21251.0   \n",
       "48    77.33    78.63   77.33     77.83              77.83    42023.0   \n",
       "49    75.28    76.78   74.85     76.39              76.39    21553.0   \n",
       "50    75.10    76.00   74.53     74.81              74.81    19772.0   \n",
       "51    72.57    74.35   72.30     74.35              74.35    26303.0   \n",
       "52    72.38    73.05   71.50     73.05              73.05    17181.0   \n",
       "53    71.06    72.61   70.43     72.54              72.54    22322.0   \n",
       "54    70.99    73.00   70.62     72.70              72.70    12109.0   \n",
       "55    71.50    71.50   71.50     71.50              71.50     9316.0   \n",
       "56    72.53    72.53   71.86     72.12              72.12    11953.0   \n",
       "57    72.47    72.47   71.00     71.79              71.79    16128.0   \n",
       "58    71.82    72.94   71.82     72.94              72.94     8491.0   \n",
       "59    69.37    71.11   69.00     70.75              70.75    10827.0   \n",
       "60    69.00    70.35   69.00     69.71              69.71    22084.0   \n",
       "\n",
       "    7. dividend amount  8. split coefficient  day_pcent_change  buy_tomorrow  \\\n",
       "1                  0.0                   1.0         -1.080760             0   \n",
       "2                  0.0                   1.0          0.997476             0   \n",
       "3                  0.0                   1.0          1.922843             0   \n",
       "4                  0.0                   1.0          1.258166             1   \n",
       "5                  0.0                   1.0         -1.017964             0   \n",
       "6                  0.0                   1.0         -1.264011             0   \n",
       "7                  0.0                   1.0         -0.405148             0   \n",
       "8                  0.0                   1.0         -0.918079             0   \n",
       "9                  0.0                   1.0          0.702799             0   \n",
       "10                 0.0                   1.0          1.880651             0   \n",
       "11                 0.0                   1.0         -2.253687             1   \n",
       "12                 0.0                   1.0          0.153447             0   \n",
       "13                 0.0                   1.0         -0.768335             0   \n",
       "14                 0.0                   1.0          1.057579             0   \n",
       "15                 0.0                   1.0          0.058555             0   \n",
       "16                 0.0                   1.0         -1.499423             0   \n",
       "17                 0.0                   1.0          1.188375             0   \n",
       "18                 0.0                   1.0          1.414020             0   \n",
       "19                 0.0                   1.0         -0.190726             0   \n",
       "20                 0.0                   1.0          0.226947             0   \n",
       "21                 0.0                   1.0         -0.508334             0   \n",
       "22                 0.0                   1.0         -0.968237             0   \n",
       "23                 0.0                   1.0          1.277416             0   \n",
       "24                 0.0                   1.0         -0.701629             0   \n",
       "25                 0.0                   1.0          1.046176             0   \n",
       "26                 0.0                   1.0         -1.354916             0   \n",
       "27                 0.0                   1.0         -2.831630             0   \n",
       "28                 0.0                   1.0         -1.285497             0   \n",
       "29                 0.0                   1.0          0.189260             0   \n",
       "30                 0.0                   1.0          0.595238             0   \n",
       "31                 0.0                   1.0          2.721511             0   \n",
       "32                 0.0                   1.0         -0.843882             1   \n",
       "33                 0.0                   1.0          0.012379             0   \n",
       "34                 0.0                   1.0          0.736671             0   \n",
       "35                 0.0                   1.0          3.046014             0   \n",
       "36                 0.0                   1.0         -3.392609             1   \n",
       "37                 0.0                   1.0         -1.054329             0   \n",
       "38                 0.0                   1.0          0.926970             0   \n",
       "39                 0.0                   1.0         -0.699213             0   \n",
       "40                 0.0                   1.0          0.781152             0   \n",
       "41                 0.0                   1.0          1.051032             0   \n",
       "42                 0.0                   1.0          0.868233             0   \n",
       "43                 0.0                   1.0         -0.922249             0   \n",
       "44                 0.0                   1.0         -0.281258             0   \n",
       "45                 0.0                   1.0          0.531157             0   \n",
       "46                 0.0                   1.0          0.218621             0   \n",
       "47                 0.0                   1.0         -1.128205             0   \n",
       "48                 0.0                   1.0          0.646580             0   \n",
       "49                 0.0                   1.0          1.474495             0   \n",
       "50                 0.0                   1.0         -0.386152             0   \n",
       "51                 0.0                   1.0          2.452804             0   \n",
       "52                 0.0                   1.0          0.925670             1   \n",
       "53                 0.0                   1.0          2.082747             0   \n",
       "54                 0.0                   1.0          2.408790             1   \n",
       "55                 0.0                   1.0          0.000000             1   \n",
       "56                 0.0                   1.0         -0.565283             0   \n",
       "57                 0.0                   1.0         -0.938319             0   \n",
       "58                 0.0                   1.0          1.559454             0   \n",
       "59                 0.0                   1.0          1.989333             1   \n",
       "60                 0.0                   1.0          1.028986             1   \n",
       "\n",
       "    ...  WMA_80_pcent_diff_to_open  bb_width  bb_upper  bb_lower  \\\n",
       "1   ...                   0.036304  0.046889   86.2293   82.2787   \n",
       "2   ...                   0.025612  0.045698   86.2236   82.3714   \n",
       "3   ...                   0.014958  0.045845   86.2211   82.3569   \n",
       "4   ...                   0.022450  0.045550   86.2235   82.3835   \n",
       "5   ...                   0.034571  0.045899   86.2280   82.3590   \n",
       "6   ...                   0.040249  0.042389   86.1505   82.5745   \n",
       "7   ...                   0.042046  0.044880   86.2285   82.4435   \n",
       "8   ...                   0.055808  0.047423   86.2907   82.2933   \n",
       "9   ...                   0.045531  0.047432   86.3059   82.3071   \n",
       "10  ...                   0.035771  0.047546   86.3189   82.3101   \n",
       "11  ...                   0.060342  0.047541   86.3182   82.3098   \n",
       "12  ...                   0.060161  0.048206   86.3370   82.2730   \n",
       "13  ...                   0.075935  0.066048   86.8334   81.2816   \n",
       "14  ...                   0.068281  0.072998   86.8949   80.7751   \n",
       "15  ...                   0.074706  0.076184   86.7523   80.3857   \n",
       "16  ...                   0.092529  0.084547   86.7922   79.7518   \n",
       "17  ...                   0.074447  0.106937   87.2609   78.4031   \n",
       "18  ...                   0.060145  0.105906   86.8902   78.1508   \n",
       "19  ...                   0.068391  0.105348   86.6535   77.9815   \n",
       "20  ...                   0.068315  0.108331   86.5549   77.6601   \n",
       "21  ...                   0.080619  0.108847   86.3694   77.4536   \n",
       "22  ...                   0.084369  0.108283   86.1165   77.2705   \n",
       "23  ...                   0.066066  0.109343   85.9030   76.9970   \n",
       "24  ...                   0.082078  0.114067   85.7418   76.4892   \n",
       "25  ...                   0.072624  0.115788   85.5207   76.1603   \n",
       "26  ...                   0.079449  0.115322   85.1618   75.8762   \n",
       "27  ...                   0.101545  0.117071   85.0025   75.6015   \n",
       "28  ...                   0.106802  0.118968   84.7831   75.2629   \n",
       "29  ...                   0.096835  0.110040   84.0756   75.3064   \n",
       "30  ...                   0.093256  0.099948   83.2372   75.3138   \n",
       "31  ...                   0.055235  0.092521   82.4359   75.1461   \n",
       "32  ...                   0.060672  0.093917   82.0559   74.6951   \n",
       "33  ...                   0.063775  0.109592   82.3089   73.7571   \n",
       "34  ...                   0.056889  0.121177   82.3234   72.9176   \n",
       "35  ...                   0.022343  0.128068   82.1663   72.2767   \n",
       "36  ...                   0.052415  0.140968   82.2362   71.4068   \n",
       "37  ...                   0.067360  0.151193   82.3880   70.8070   \n",
       "38  ...                   0.058236  0.156392   82.1569   70.2401   \n",
       "39  ...                   0.063905  0.152045   81.5808   70.0532   \n",
       "40  ...                   0.055867  0.156587   81.2796   69.4764   \n",
       "41  ...                   0.052480  0.160162   80.8592   68.8688   \n",
       "42  ...                   0.046251  0.163196   80.3887   68.2593   \n",
       "43  ...                   0.045280  0.154862   79.7148   68.2572   \n",
       "44  ...                   0.047588  0.152687   79.3082   68.0578   \n",
       "45  ...                   0.035557  0.144654   78.6863   68.0717   \n",
       "46  ...                   0.043598  0.136571   78.0671   68.0869   \n",
       "47  ...                   0.048178  0.124744   77.4687   68.3723   \n",
       "48  ...                   0.039884  0.115236   76.9835   68.5955   \n",
       "49  ...                   0.014804  0.100831   76.3111   68.9859   \n",
       "50  ...                   0.013264  0.093703   75.9716   69.1714   \n",
       "51  ...                  -0.020651  0.091637   75.8616   69.2144   \n",
       "52  ...                  -0.023748  0.092551   75.9099   69.1951   \n",
       "53  ...                  -0.042705  0.096146   76.1315   69.1475   \n",
       "54  ...                  -0.044369  0.098549   76.3216   69.1534   \n",
       "55  ...                  -0.038758  0.105302   76.7351   69.0589   \n",
       "56  ...                  -0.025352  0.104006   76.8020   69.2090   \n",
       "57  ...                  -0.027327  0.103840   76.8028   69.2212   \n",
       "58  ...                  -0.036958  0.103041   76.8856   69.3514   \n",
       "59  ...                  -0.073536  0.103074   76.8826   69.3464   \n",
       "60  ...                  -0.081564  0.098858   76.8266   69.5894   \n",
       "\n",
       "    pcent_diff_to_bb_upper  pcent_diff_to_bb_lower  macd_signal  \\\n",
       "1                -0.035290                0.012142       0.6855   \n",
       "2                -0.025983                0.019855       0.7657   \n",
       "3                -0.029506                0.016634       0.8469   \n",
       "4                -0.030149                0.015729       0.9447   \n",
       "5                -0.043291                0.003521       1.0563   \n",
       "6                -0.040465                0.002723       1.1831   \n",
       "7                -0.031688                0.013598       1.3005   \n",
       "8                -0.025074                0.022413       1.4011   \n",
       "9                -0.020888                0.026412       1.4911   \n",
       "10               -0.021405                0.026031       1.5772   \n",
       "11               -0.041987                0.006400       1.6644   \n",
       "12               -0.017525                0.030371       1.7508   \n",
       "13               -0.018693                0.046438       1.7926   \n",
       "14               -0.010406                0.060755       1.8170   \n",
       "15               -0.015359                0.059156       1.8281   \n",
       "16               -0.016302                0.066138       1.8431   \n",
       "17               -0.014662                0.088336       1.8554   \n",
       "18               -0.026707                0.076559       1.8681   \n",
       "19               -0.034916                0.068655       1.9024   \n",
       "20               -0.031521                0.074483       1.9400   \n",
       "21               -0.026252                0.079686       1.9640   \n",
       "22               -0.026786                0.078687       1.9758   \n",
       "23               -0.022168                0.083805       1.9807   \n",
       "24               -0.026848                0.083962       1.9740   \n",
       "25               -0.017740                0.093653       1.9608   \n",
       "26               -0.035150                0.077717       1.9318   \n",
       "27               -0.027842                0.085834       1.9006   \n",
       "28               -0.003707                0.108998       1.8308   \n",
       "29                0.007372                0.110904       1.7232   \n",
       "30                0.014944                0.108712       1.6158   \n",
       "31                0.002711                0.090901       1.5298   \n",
       "32               -0.026982                0.065143       1.4862   \n",
       "33               -0.018801                0.087052       1.4725   \n",
       "34               -0.020369                0.096212       1.4426   \n",
       "35               -0.033538                0.090859       1.4175   \n",
       "36               -0.073580                0.067796       1.4048   \n",
       "37               -0.032819                0.112361       1.3877   \n",
       "38               -0.019696                0.128210       1.2966   \n",
       "39               -0.025786                0.119160       1.1806   \n",
       "40               -0.016122                0.131436       1.0597   \n",
       "41               -0.013273                0.136982       0.9190   \n",
       "42               -0.017578                0.135958       0.7741   \n",
       "43               -0.030573                0.117554       0.6328   \n",
       "44               -0.016772                0.127464       0.4918   \n",
       "45               -0.013999                0.122787       0.3234   \n",
       "46               -0.001759                0.126307       0.1434   \n",
       "47               -0.004522                0.113430      -0.0487   \n",
       "48                0.010876                0.118650      -0.2354   \n",
       "49                0.001033                0.096925      -0.4185   \n",
       "50               -0.015527                0.075372      -0.5633   \n",
       "51               -0.020331                0.069073      -0.6732   \n",
       "52               -0.039150                0.052771      -0.7605   \n",
       "53               -0.049511                0.046767      -0.8184   \n",
       "54               -0.049816                0.048784      -0.8606   \n",
       "55               -0.073218                0.034141      -0.8901   \n",
       "56               -0.064920                0.040363      -0.8959   \n",
       "57               -0.069826                0.035782      -0.8973   \n",
       "58               -0.054094                0.049199      -0.8789   \n",
       "59               -0.086680                0.019839      -0.8422   \n",
       "60               -0.102089                0.001730      -0.7533   \n",
       "\n",
       "    stochrsi_fast_k  stochrsi_fast_d     ppo  \n",
       "1           44.1339          62.9174 -1.2474  \n",
       "2          100.0000          81.7008 -1.1117  \n",
       "3           88.6782          63.4016 -0.8960  \n",
       "4           67.6404          38.1249 -0.7531  \n",
       "5            0.0000           8.6094 -0.7096  \n",
       "6            0.0000          17.2188 -0.6703  \n",
       "7           28.5771          34.4376 -0.7425  \n",
       "8           46.3193          40.2982 -0.7287  \n",
       "9           43.0797          34.2772 -0.7640  \n",
       "10          42.3920          25.4746 -0.7512  \n",
       "11           0.0000           8.5572 -0.8857  \n",
       "12           0.0000          17.1145 -1.0026  \n",
       "13           0.0000          34.2290 -1.1046  \n",
       "14          78.1896          68.4580 -1.0652  \n",
       "15          52.3383          58.7263 -1.0609  \n",
       "16          50.5261          65.1142 -0.9706  \n",
       "17         100.0000          79.7023 -0.7504  \n",
       "18         100.0000          59.4045 -0.4977  \n",
       "19           0.0000          18.8091 -0.3326  \n",
       "20           7.4191          37.6181 -0.2032  \n",
       "21          85.2159          67.8172 -0.0140  \n",
       "22          65.7970          50.4185 -0.0017  \n",
       "23          40.9577          35.0399  0.4094  \n",
       "24          22.8221          29.1220  0.8754  \n",
       "25          44.0919          35.4219  1.1910  \n",
       "26           0.0000          26.7519  1.3960  \n",
       "27          14.9057          53.5039  1.4416  \n",
       "28          89.5151          92.1021  1.3827  \n",
       "29         100.0000          94.6891  1.4245  \n",
       "30         100.0000          89.3782  1.5793  \n",
       "31         100.0000          78.7564  1.8413  \n",
       "32          59.7187          57.5127  2.0658  \n",
       "33          62.9194          55.3067  2.1899  \n",
       "34          61.5570          47.6940  2.2059  \n",
       "35          46.3335          33.8310  2.2029  \n",
       "36           0.0000          21.3284  2.0583  \n",
       "37           0.0000          42.6568  1.9549  \n",
       "38          96.8177          85.3137  1.8067  \n",
       "39          56.9304          73.8096  1.7504  \n",
       "40         100.0000          90.6887  1.6467  \n",
       "41         100.0000          81.3775  1.5613  \n",
       "42         100.0000          62.7550  1.3673  \n",
       "43           0.0000          25.5100  1.2267  \n",
       "44          33.3744          51.0200  1.0480  \n",
       "45          53.7374          68.6655  0.8923  \n",
       "46          80.9558          83.5937  0.7593  \n",
       "47          72.9086          86.2316  0.3780  \n",
       "48         100.0000          99.5545 -0.1044  \n",
       "49         100.0000          99.1091 -0.4234  \n",
       "50         100.0000          98.2181 -0.7079  \n",
       "51         100.0000          96.4362 -0.9216  \n",
       "52         100.0000          92.8725 -1.0976  \n",
       "53          85.4438          85.7449 -1.1820  \n",
       "54          99.4282          86.0460 -1.3139  \n",
       "55          63.9631          72.6638 -1.4934  \n",
       "56          84.5120          81.3646 -1.7237  \n",
       "57          77.1726          78.2172 -1.7408  \n",
       "58         100.0000          79.2618 -1.6241  \n",
       "59          91.3892          58.5236 -1.4977  \n",
       "60          38.4738          25.6580 -1.2910  \n",
       "\n",
       "[60 rows x 29 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = final_data.iloc[1: , :]\n",
    "final_data.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "598d7355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. adjusted close</th>\n",
       "      <th>6. volume</th>\n",
       "      <th>7. dividend amount</th>\n",
       "      <th>8. split coefficient</th>\n",
       "      <th>day_pcent_change</th>\n",
       "      <th>buy_tomorrow</th>\n",
       "      <th>...</th>\n",
       "      <th>WMA_80_pcent_diff_to_open</th>\n",
       "      <th>bb_width</th>\n",
       "      <th>bb_upper</th>\n",
       "      <th>bb_lower</th>\n",
       "      <th>pcent_diff_to_bb_upper</th>\n",
       "      <th>pcent_diff_to_bb_lower</th>\n",
       "      <th>macd_signal</th>\n",
       "      <th>stochrsi_fast_k</th>\n",
       "      <th>stochrsi_fast_d</th>\n",
       "      <th>ppo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4487.000000</td>\n",
       "      <td>4487.000000</td>\n",
       "      <td>4487.000000</td>\n",
       "      <td>4487.000000</td>\n",
       "      <td>4487.000000</td>\n",
       "      <td>4.487000e+03</td>\n",
       "      <td>4487.000000</td>\n",
       "      <td>4487.0</td>\n",
       "      <td>4487.000000</td>\n",
       "      <td>4487.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4487.000000</td>\n",
       "      <td>4487.000000</td>\n",
       "      <td>4487.000000</td>\n",
       "      <td>4487.000000</td>\n",
       "      <td>4487.000000</td>\n",
       "      <td>4487.000000</td>\n",
       "      <td>4487.000000</td>\n",
       "      <td>4487.000000</td>\n",
       "      <td>4487.000000</td>\n",
       "      <td>4487.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.986331</td>\n",
       "      <td>64.655229</td>\n",
       "      <td>63.251593</td>\n",
       "      <td>63.988046</td>\n",
       "      <td>51.927019</td>\n",
       "      <td>1.067083e+05</td>\n",
       "      <td>0.007114</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.025061</td>\n",
       "      <td>0.154446</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217600</td>\n",
       "      <td>0.119015</td>\n",
       "      <td>54.706068</td>\n",
       "      <td>48.881770</td>\n",
       "      <td>0.169230</td>\n",
       "      <td>0.262392</td>\n",
       "      <td>0.095825</td>\n",
       "      <td>51.097660</td>\n",
       "      <td>51.096564</td>\n",
       "      <td>0.188645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21.954073</td>\n",
       "      <td>22.092552</td>\n",
       "      <td>21.767080</td>\n",
       "      <td>21.940089</td>\n",
       "      <td>22.396761</td>\n",
       "      <td>2.338250e+05</td>\n",
       "      <td>0.139861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.726769</td>\n",
       "      <td>0.361416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139273</td>\n",
       "      <td>0.070676</td>\n",
       "      <td>23.384900</td>\n",
       "      <td>21.393248</td>\n",
       "      <td>0.143250</td>\n",
       "      <td>0.127161</td>\n",
       "      <td>0.996802</td>\n",
       "      <td>40.766556</td>\n",
       "      <td>31.355546</td>\n",
       "      <td>2.388457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.500000</td>\n",
       "      <td>17.905000</td>\n",
       "      <td>16.115000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>11.657600</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-12.293578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.538792</td>\n",
       "      <td>0.025871</td>\n",
       "      <td>14.511300</td>\n",
       "      <td>10.639000</td>\n",
       "      <td>-0.734486</td>\n",
       "      <td>-0.054526</td>\n",
       "      <td>-5.475400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110700</td>\n",
       "      <td>-15.330200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>43.400000</td>\n",
       "      <td>43.815000</td>\n",
       "      <td>42.835000</td>\n",
       "      <td>43.405000</td>\n",
       "      <td>28.243850</td>\n",
       "      <td>2.059300e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.882058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109805</td>\n",
       "      <td>0.071784</td>\n",
       "      <td>29.500400</td>\n",
       "      <td>26.781300</td>\n",
       "      <td>0.062726</td>\n",
       "      <td>0.157322</td>\n",
       "      <td>-0.393000</td>\n",
       "      <td>2.335900</td>\n",
       "      <td>21.717950</td>\n",
       "      <td>-1.113700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>68.570000</td>\n",
       "      <td>69.320000</td>\n",
       "      <td>67.830000</td>\n",
       "      <td>68.810000</td>\n",
       "      <td>57.046900</td>\n",
       "      <td>3.915700e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250330</td>\n",
       "      <td>0.102939</td>\n",
       "      <td>61.092300</td>\n",
       "      <td>53.001800</td>\n",
       "      <td>0.204304</td>\n",
       "      <td>0.292289</td>\n",
       "      <td>0.112600</td>\n",
       "      <td>52.158900</td>\n",
       "      <td>51.212000</td>\n",
       "      <td>0.244700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.255000</td>\n",
       "      <td>83.130000</td>\n",
       "      <td>81.400000</td>\n",
       "      <td>82.236500</td>\n",
       "      <td>70.821300</td>\n",
       "      <td>9.639000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.929095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335002</td>\n",
       "      <td>0.142794</td>\n",
       "      <td>73.649050</td>\n",
       "      <td>67.665650</td>\n",
       "      <td>0.286337</td>\n",
       "      <td>0.370367</td>\n",
       "      <td>0.616950</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>80.599450</td>\n",
       "      <td>1.697450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>122.890000</td>\n",
       "      <td>123.699000</td>\n",
       "      <td>120.225000</td>\n",
       "      <td>122.998000</td>\n",
       "      <td>99.650000</td>\n",
       "      <td>5.277522e+06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.092245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507412</td>\n",
       "      <td>0.662782</td>\n",
       "      <td>102.715400</td>\n",
       "      <td>91.049500</td>\n",
       "      <td>0.382821</td>\n",
       "      <td>0.547382</td>\n",
       "      <td>3.382800</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.996200</td>\n",
       "      <td>6.647600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           1. open      2. high       3. low     4. close  5. adjusted close  \\\n",
       "count  4487.000000  4487.000000  4487.000000  4487.000000        4487.000000   \n",
       "mean     63.986331    64.655229    63.251593    63.988046          51.927019   \n",
       "std      21.954073    22.092552    21.767080    21.940089          22.396761   \n",
       "min      17.500000    17.905000    16.115000    17.400000          11.657600   \n",
       "25%      43.400000    43.815000    42.835000    43.405000          28.243850   \n",
       "50%      68.570000    69.320000    67.830000    68.810000          57.046900   \n",
       "75%      82.255000    83.130000    81.400000    82.236500          70.821300   \n",
       "max     122.890000   123.699000   120.225000   122.998000          99.650000   \n",
       "\n",
       "          6. volume  7. dividend amount  8. split coefficient  \\\n",
       "count  4.487000e+03         4487.000000                4487.0   \n",
       "mean   1.067083e+05            0.007114                   1.0   \n",
       "std    2.338250e+05            0.139861                   0.0   \n",
       "min    0.000000e+00            0.000000                   1.0   \n",
       "25%    2.059300e+04            0.000000                   1.0   \n",
       "50%    3.915700e+04            0.000000                   1.0   \n",
       "75%    9.639000e+04            0.000000                   1.0   \n",
       "max    5.277522e+06            4.000000                   1.0   \n",
       "\n",
       "       day_pcent_change  buy_tomorrow  ...  WMA_80_pcent_diff_to_open  \\\n",
       "count       4487.000000   4487.000000  ...                4487.000000   \n",
       "mean           0.025061      0.154446  ...                   0.217600   \n",
       "std            1.726769      0.361416  ...                   0.139273   \n",
       "min          -12.293578      0.000000  ...                  -0.538792   \n",
       "25%           -0.882058      0.000000  ...                   0.109805   \n",
       "50%            0.040239      0.000000  ...                   0.250330   \n",
       "75%            0.929095      0.000000  ...                   0.335002   \n",
       "max           16.092245      1.000000  ...                   0.507412   \n",
       "\n",
       "          bb_width     bb_upper     bb_lower  pcent_diff_to_bb_upper  \\\n",
       "count  4487.000000  4487.000000  4487.000000             4487.000000   \n",
       "mean      0.119015    54.706068    48.881770                0.169230   \n",
       "std       0.070676    23.384900    21.393248                0.143250   \n",
       "min       0.025871    14.511300    10.639000               -0.734486   \n",
       "25%       0.071784    29.500400    26.781300                0.062726   \n",
       "50%       0.102939    61.092300    53.001800                0.204304   \n",
       "75%       0.142794    73.649050    67.665650                0.286337   \n",
       "max       0.662782   102.715400    91.049500                0.382821   \n",
       "\n",
       "       pcent_diff_to_bb_lower  macd_signal  stochrsi_fast_k  stochrsi_fast_d  \\\n",
       "count             4487.000000  4487.000000      4487.000000      4487.000000   \n",
       "mean                 0.262392     0.095825        51.097660        51.096564   \n",
       "std                  0.127161     0.996802        40.766556        31.355546   \n",
       "min                 -0.054526    -5.475400         0.000000         0.110700   \n",
       "25%                  0.157322    -0.393000         2.335900        21.717950   \n",
       "50%                  0.292289     0.112600        52.158900        51.212000   \n",
       "75%                  0.370367     0.616950       100.000000        80.599450   \n",
       "max                  0.547382     3.382800       100.000000        99.996200   \n",
       "\n",
       "               ppo  \n",
       "count  4487.000000  \n",
       "mean      0.188645  \n",
       "std       2.388457  \n",
       "min     -15.330200  \n",
       "25%      -1.113700  \n",
       "50%       0.244700  \n",
       "75%       1.697450  \n",
       "max       6.647600  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4d9bc0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = final_data\n",
    "label = 'buy_tomorrow'\n",
    "save_path = './autogluon_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "0390bb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./autogluon_models\"\n",
      "Presets specified: ['best_quality']\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{'auto_stack': True, 'num_bag_folds': 20, 'num_stack_levels': 3}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': True,\n",
      " 'calibrate': 'auto',\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'keep_only_best': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': 20,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': 3,\n",
      " 'pseudo_data': None,\n",
      " 'refit_full': False,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Stack configuration (auto_stack=True): num_stack_levels=3, num_bag_folds=20, num_bag_sets=20\n",
      "Saving ./autogluon_models/learner.pkl\n",
      "Saving ./autogluon_models/predictor.pkl\n",
      "Beginning AutoGluon training ... Time limit = 15000s\n",
      "AutoGluon will save models to \"./autogluon_models/\"\n",
      "AutoGluon Version:  0.6.1\n",
      "Python Version:     3.7.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Mar 2 19:14:12 UTC 2022\n",
      "Train Data Rows:    4487\n",
      "Train Data Columns: 28\n",
      "Label Column: buy_tomorrow\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29404.9 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t27 features in original data used to generate 27 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t27 features in original data used to generate 27 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t27 features in original data used to generate 27 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t27 features in original data used to generate 27 features in processed data.\n",
      "\tUseless Original Features (Count: 1): ['8. split coefficient']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t27 features in original data used to generate 27 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.97 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'precision'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving ./autogluon_models/learner.pkl\n",
      "Saving ./autogluon_models/utils/data/X.pkl\n",
      "Saving ./autogluon_models/utils/data/y.pkl\n",
      "AutoGluon will fit 4 stack levels (L1 to L4) ...\n",
      "Model configs that will be trained (in order):\n",
      "\tKNeighborsUnif_BAG_L1: \t{'weights': 'uniform', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Unif', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tKNeighborsDist_BAG_L1: \t{'weights': 'distance', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Dist', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tRandomForestEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesGini_BAG_L1: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tExtraTreesEntr_BAG_L1: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 4998.72s of the 14999.91s of remaining time.\n",
      "\tFitting KNeighborsUnif_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/KNeighborsUnif_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsUnif_BAG_L1/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/KNeighborsUnif_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "\t0.152\t = Validation score   (precision)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.71s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 4997.96s of the 14999.15s of remaining time.\n",
      "\tFitting KNeighborsDist_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/KNeighborsDist_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsDist_BAG_L1/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/KNeighborsDist_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "\t0.1228\t = Validation score   (precision)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 4997.31s of the 14998.5s of remaining time.\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t0.4651\t = Validation score   (precision)\n",
      "\t15.61s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 4978.71s of the 14979.9s of remaining time.\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/LightGBM_BAG_L1/model.pkl\n",
      "\t0.5577\t = Validation score   (precision)\n",
      "\t17.65s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 4957.84s of the 14959.03s of remaining time.\n",
      "\tFitting RandomForestGini_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L1/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/RandomForestGini_BAG_L1/model.pkl\n",
      "\t0.2245\t = Validation score   (precision)\n",
      "\t1.3s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 4955.09s of the 14956.28s of remaining time.\n",
      "\tFitting RandomForestEntr_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/RandomForestEntr_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L1/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "\t0.2088\t = Validation score   (precision)\n",
      "\t2.1s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 4951.76s of the 14952.94s of remaining time.\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/CatBoost_BAG_L1/model.pkl\n",
      "\t1.0\t = Validation score   (precision)\n",
      "\t19.76s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 4929.06s of the 14930.25s of remaining time.\n",
      "\tFitting ExtraTreesGini_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/ExtraTreesGini_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L1/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "\t0.1809\t = Validation score   (precision)\n",
      "\t0.91s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 4925.94s of the 14927.13s of remaining time.\n",
      "\tFitting ExtraTreesEntr_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/ExtraTreesEntr_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L1/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "\t0.2024\t = Validation score   (precision)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 4922.99s of the 14924.18s of remaining time.\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t0.3681\t = Validation score   (precision)\n",
      "\t30.3s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 4889.7s of the 14890.89s of remaining time.\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/XGBoost_BAG_L1/model.pkl\n",
      "\t0.4769\t = Validation score   (precision)\n",
      "\t31.95s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 4854.45s of the 14855.64s of remaining time.\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving ./autogluon_models/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t0.0\t = Validation score   (precision)\n",
      "\t23.86s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 4827.57s of the 14828.76s of remaining time.\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t0.4912\t = Validation score   (precision)\n",
      "\t36.72s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Repeating k-fold bagging: 2/20\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 4787.34s of the 14788.53s of remaining time.\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L1/model.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 4787.33s of the 14788.52s of remaining time.\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "\tWarning: Exception caused LightGBM_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L1/model.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 4787.32s of the 14788.51s of remaining time.\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "\tWarning: Exception caused CatBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 4787.31s of the 14788.5s of remaining time.\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L1/model.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 4787.31s of the 14788.5s of remaining time.\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "\tWarning: Exception caused XGBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 4787.3s of the 14788.49s of remaining time.\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 4787.29s of the 14788.48s of remaining time.\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L1 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Repeating k-fold bagging: 3/20\n",
      "Repeating k-fold bagging: 4/20\n",
      "Repeating k-fold bagging: 5/20\n",
      "Repeating k-fold bagging: 6/20\n",
      "Repeating k-fold bagging: 7/20\n",
      "Repeating k-fold bagging: 8/20\n",
      "Repeating k-fold bagging: 9/20\n",
      "Repeating k-fold bagging: 10/20\n",
      "Repeating k-fold bagging: 11/20\n",
      "Repeating k-fold bagging: 12/20\n",
      "Repeating k-fold bagging: 13/20\n",
      "Repeating k-fold bagging: 14/20\n",
      "Repeating k-fold bagging: 15/20\n",
      "Repeating k-fold bagging: 16/20\n",
      "Repeating k-fold bagging: 17/20\n",
      "Repeating k-fold bagging: 18/20\n",
      "Repeating k-fold bagging: 19/20\n",
      "Repeating k-fold bagging: 20/20\n",
      "Completed 20/20 k-fold bagging repeats ...\n",
      "Loading: ./autogluon_models/models/KNeighborsUnif_BAG_L1/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsDist_BAG_L1/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 499.87s of the 14788.45s of remaining time.\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Ensemble size: 16\n",
      "Ensemble weights: \n",
      "[0.25   0.125  0.3125 0.25   0.     0.0625]\n",
      "Saving ./autogluon_models/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/WeightedEnsemble_L2/model.pkl\n",
      "\t0.2667\t = Validation score   (precision)\n",
      "\t1.9s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestGini_BAG_L2: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tRandomForestEntr_BAG_L2: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesGini_BAG_L2: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tExtraTreesEntr_BAG_L2: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 11 L2 models ...\n",
      "Loading: ./autogluon_models/models/KNeighborsUnif_BAG_L1/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsDist_BAG_L1/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L1/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L1/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L1/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L1/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 6570.14s of the 14786.5s of remaining time.\n",
      "\tFitting LightGBMXT_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/LightGBMXT_BAG_L2/model.pkl\n",
      "\t0.6552\t = Validation score   (precision)\n",
      "\t17.06s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 6549.98s of the 14766.34s of remaining time.\n",
      "\tFitting LightGBM_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/LightGBM_BAG_L2/model.pkl\n",
      "\t0.7586\t = Validation score   (precision)\n",
      "\t19.51s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 6527.29s of the 14743.64s of remaining time.\n",
      "\tFitting RandomForestGini_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/RandomForestGini_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L2/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/RandomForestGini_BAG_L2/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/RandomForestGini_BAG_L2/model.pkl\n",
      "\t0.3438\t = Validation score   (precision)\n",
      "\t1.42s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 6525.53s of the 14741.89s of remaining time.\n",
      "\tFitting RandomForestEntr_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/RandomForestEntr_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L2/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/RandomForestEntr_BAG_L2/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/RandomForestEntr_BAG_L2/model.pkl\n",
      "\t0.5556\t = Validation score   (precision)\n",
      "\t2.0s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 6523.19s of the 14739.55s of remaining time.\n",
      "\tFitting CatBoost_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving ./autogluon_models/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/CatBoost_BAG_L2/model.pkl\n",
      "\t0.0\t = Validation score   (precision)\n",
      "\t21.64s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 6498.55s of the 14714.91s of remaining time.\n",
      "\tFitting ExtraTreesGini_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/ExtraTreesGini_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L2/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/ExtraTreesGini_BAG_L2/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/ExtraTreesGini_BAG_L2/model.pkl\n",
      "\t0.4545\t = Validation score   (precision)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 6497.5s of the 14713.86s of remaining time.\n",
      "\tFitting ExtraTreesEntr_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/ExtraTreesEntr_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L2/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/ExtraTreesEntr_BAG_L2/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/ExtraTreesEntr_BAG_L2/model.pkl\n",
      "\t0.5455\t = Validation score   (precision)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 6496.34s of the 14712.7s of remaining time.\n",
      "\tFitting NeuralNetFastAI_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "\t0.5921\t = Validation score   (precision)\n",
      "\t32.61s\t = Training   runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 6460.68s of the 14677.04s of remaining time.\n",
      "\tFitting XGBoost_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/XGBoost_BAG_L2/model.pkl\n",
      "\t0.6471\t = Validation score   (precision)\n",
      "\t30.7s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 6426.74s of the 14643.1s of remaining time.\n",
      "\tFitting NeuralNetTorch_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "\t0.0\t = Validation score   (precision)\n",
      "\t23.98s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 6399.68s of the 14616.04s of remaining time.\n",
      "\tFitting LightGBMLarge_BAG_L2 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "\t0.6875\t = Validation score   (precision)\n",
      "\t44.38s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Repeating k-fold bagging: 2/20\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 6351.84s of the 14568.2s of remaining time.\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L2/model.pkl\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 6351.83s of the 14568.18s of remaining time.\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "\tWarning: Exception caused LightGBM_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L2/model.pkl\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 6351.81s of the 14568.17s of remaining time.\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "\tWarning: Exception caused CatBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 6351.8s of the 14568.16s of remaining time.\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L2/model.pkl\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 6351.79s of the 14568.15s of remaining time.\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "\tWarning: Exception caused XGBoost_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 6351.78s of the 14568.13s of remaining time.\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 6351.77s of the 14568.12s of remaining time.\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L2 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Repeating k-fold bagging: 3/20\n",
      "Repeating k-fold bagging: 4/20\n",
      "Repeating k-fold bagging: 5/20\n",
      "Repeating k-fold bagging: 6/20\n",
      "Repeating k-fold bagging: 7/20\n",
      "Repeating k-fold bagging: 8/20\n",
      "Repeating k-fold bagging: 9/20\n",
      "Repeating k-fold bagging: 10/20\n",
      "Repeating k-fold bagging: 11/20\n",
      "Repeating k-fold bagging: 12/20\n",
      "Repeating k-fold bagging: 13/20\n",
      "Repeating k-fold bagging: 14/20\n",
      "Repeating k-fold bagging: 15/20\n",
      "Repeating k-fold bagging: 16/20\n",
      "Repeating k-fold bagging: 17/20\n",
      "Repeating k-fold bagging: 18/20\n",
      "Repeating k-fold bagging: 19/20\n",
      "Repeating k-fold bagging: 20/20\n",
      "Completed 20/20 k-fold bagging repeats ...\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L2/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L2/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L2/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L2/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L3: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 657.01s of the 14568.1s of remaining time.\n",
      "\tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "Ensemble size: 14\n",
      "Ensemble weights: \n",
      "[0.07142857 0.92857143 0.         0.        ]\n",
      "Saving ./autogluon_models/models/WeightedEnsemble_L3/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/WeightedEnsemble_L3/model.pkl\n",
      "\t0.5769\t = Validation score   (precision)\n",
      "\t1.29s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L3: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestGini_BAG_L3: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tRandomForestEntr_BAG_L3: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesGini_BAG_L3: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tExtraTreesEntr_BAG_L3: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L3: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 11 L3 models ...\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L2/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L2/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L2/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L2/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 9708.76s of the 14566.77s of remaining time.\n",
      "\tFitting LightGBMXT_BAG_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/LightGBMXT_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L3/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/LightGBMXT_BAG_L3/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/LightGBMXT_BAG_L3/model.pkl\n",
      "\t0.5\t = Validation score   (precision)\n",
      "\t16.83s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L3 ... Training model for up to 9688.82s of the 14546.83s of remaining time.\n",
      "\tFitting LightGBM_BAG_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/LightGBM_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L3/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/LightGBM_BAG_L3/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/LightGBM_BAG_L3/model.pkl\n",
      "\t0.5738\t = Validation score   (precision)\n",
      "\t17.29s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: RandomForestGini_BAG_L3 ... Training model for up to 9668.38s of the 14526.39s of remaining time.\n",
      "\tFitting RandomForestGini_BAG_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/RandomForestGini_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L3/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/RandomForestGini_BAG_L3/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/RandomForestGini_BAG_L3/model.pkl\n",
      "\t0.3412\t = Validation score   (precision)\n",
      "\t1.61s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: RandomForestEntr_BAG_L3 ... Training model for up to 9666.43s of the 14524.44s of remaining time.\n",
      "\tFitting RandomForestEntr_BAG_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/RandomForestEntr_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L3/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/RandomForestEntr_BAG_L3/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/RandomForestEntr_BAG_L3/model.pkl\n",
      "\t0.3425\t = Validation score   (precision)\n",
      "\t2.11s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L3 ... Training model for up to 9663.99s of the 14521.99s of remaining time.\n",
      "\tFitting CatBoost_BAG_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/CatBoost_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L3/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/CatBoost_BAG_L3/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/CatBoost_BAG_L3/model.pkl\n",
      "\t0.3333\t = Validation score   (precision)\n",
      "\t22.64s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: ExtraTreesGini_BAG_L3 ... Training model for up to 9638.34s of the 14496.34s of remaining time.\n",
      "\tFitting ExtraTreesGini_BAG_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/ExtraTreesGini_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L3/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/ExtraTreesGini_BAG_L3/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/ExtraTreesGini_BAG_L3/model.pkl\n",
      "\t0.3291\t = Validation score   (precision)\n",
      "\t0.9s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: ExtraTreesEntr_BAG_L3 ... Training model for up to 9637.07s of the 14495.08s of remaining time.\n",
      "\tFitting ExtraTreesEntr_BAG_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/ExtraTreesEntr_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L3/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/ExtraTreesEntr_BAG_L3/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/ExtraTreesEntr_BAG_L3/model.pkl\n",
      "\t0.3429\t = Validation score   (precision)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L3 ... Training model for up to 9636.02s of the 14494.03s of remaining time.\n",
      "\tFitting NeuralNetFastAI_BAG_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/NeuralNetFastAI_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L3/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/NeuralNetFastAI_BAG_L3/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "\t0.5269\t = Validation score   (precision)\n",
      "\t31.64s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L3 ... Training model for up to 9601.33s of the 14459.33s of remaining time.\n",
      "\tFitting XGBoost_BAG_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/XGBoost_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L3/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/XGBoost_BAG_L3/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/XGBoost_BAG_L3/model.pkl\n",
      "\t0.5222\t = Validation score   (precision)\n",
      "\t28.81s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L3 ... Training model for up to 9569.27s of the 14427.27s of remaining time.\n",
      "\tFitting NeuralNetTorch_BAG_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/NeuralNetTorch_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L3/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/NeuralNetTorch_BAG_L3/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "\t0.0526\t = Validation score   (precision)\n",
      "\t24.44s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L3 ... Training model for up to 9541.75s of the 14399.76s of remaining time.\n",
      "\tFitting LightGBMLarge_BAG_L3 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/LightGBMLarge_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L3/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/LightGBMLarge_BAG_L3/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "\t0.5455\t = Validation score   (precision)\n",
      "\t35.69s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Repeating k-fold bagging: 2/20\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L3 ... Training model for up to 9502.82s of the 14360.83s of remaining time.\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L3/utils/model_template.pkl\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L3 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L3/model.pkl\n",
      "Fitting model: LightGBM_BAG_L3 ... Training model for up to 9502.81s of the 14360.82s of remaining time.\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L3/utils/model_template.pkl\n",
      "\tWarning: Exception caused LightGBM_BAG_L3 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L3/model.pkl\n",
      "Fitting model: CatBoost_BAG_L3 ... Training model for up to 9502.8s of the 14360.81s of remaining time.\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L3/utils/model_template.pkl\n",
      "\tWarning: Exception caused CatBoost_BAG_L3 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L3 ... Training model for up to 9502.79s of the 14360.8s of remaining time.\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L3/utils/model_template.pkl\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L3 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L3/model.pkl\n",
      "Fitting model: XGBoost_BAG_L3 ... Training model for up to 9502.78s of the 14360.79s of remaining time.\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L3/utils/model_template.pkl\n",
      "\tWarning: Exception caused XGBoost_BAG_L3 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L3 ... Training model for up to 9502.77s of the 14360.77s of remaining time.\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L3/utils/model_template.pkl\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L3 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L3 ... Training model for up to 9502.76s of the 14360.76s of remaining time.\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L3/utils/model_template.pkl\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L3 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Repeating k-fold bagging: 3/20\n",
      "Repeating k-fold bagging: 4/20\n",
      "Repeating k-fold bagging: 5/20\n",
      "Repeating k-fold bagging: 6/20\n",
      "Repeating k-fold bagging: 7/20\n",
      "Repeating k-fold bagging: 8/20\n",
      "Repeating k-fold bagging: 9/20\n",
      "Repeating k-fold bagging: 10/20\n",
      "Repeating k-fold bagging: 11/20\n",
      "Repeating k-fold bagging: 12/20\n",
      "Repeating k-fold bagging: 13/20\n",
      "Repeating k-fold bagging: 14/20\n",
      "Repeating k-fold bagging: 15/20\n",
      "Repeating k-fold bagging: 16/20\n",
      "Repeating k-fold bagging: 17/20\n",
      "Repeating k-fold bagging: 18/20\n",
      "Repeating k-fold bagging: 19/20\n",
      "Repeating k-fold bagging: 20/20\n",
      "Completed 20/20 k-fold bagging repeats ...\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L3/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L3/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L3/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L3/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L4: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L4 ... Training model for up to 970.88s of the 14360.74s of remaining time.\n",
      "\tFitting WeightedEnsemble_L4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/WeightedEnsemble_L4/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L4/utils/model_template.pkl\n",
      "Ensemble size: 12\n",
      "Ensemble weights: \n",
      "[0.08333333 0.16666667 0.         0.75      ]\n",
      "Saving ./autogluon_models/models/WeightedEnsemble_L4/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/WeightedEnsemble_L4/model.pkl\n",
      "\t0.3443\t = Validation score   (precision)\n",
      "\t1.27s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L4: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestGini_BAG_L4: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tRandomForestEntr_BAG_L4: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesGini_BAG_L4: \t{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tExtraTreesEntr_BAG_L4: \t{'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L4: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 11 L4 models ...\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L3/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L3/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L3/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L3/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L4 ... Training model for up to 14359.34s of the 14359.33s of remaining time.\n",
      "\tFitting LightGBMXT_BAG_L4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/LightGBMXT_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L4/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/LightGBMXT_BAG_L4/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/LightGBMXT_BAG_L4/model.pkl\n",
      "\t0.6552\t = Validation score   (precision)\n",
      "\t16.7s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L4 ... Training model for up to 14339.58s of the 14339.57s of remaining time.\n",
      "\tFitting LightGBM_BAG_L4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/LightGBM_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L4/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/LightGBM_BAG_L4/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/LightGBM_BAG_L4/model.pkl\n",
      "\t0.6\t = Validation score   (precision)\n",
      "\t20.94s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: RandomForestGini_BAG_L4 ... Training model for up to 14315.54s of the 14315.52s of remaining time.\n",
      "\tFitting RandomForestGini_BAG_L4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/RandomForestGini_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L4/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/RandomForestGini_BAG_L4/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/RandomForestGini_BAG_L4/model.pkl\n",
      "\t0.3571\t = Validation score   (precision)\n",
      "\t1.4s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: RandomForestEntr_BAG_L4 ... Training model for up to 14313.79s of the 14313.78s of remaining time.\n",
      "\tFitting RandomForestEntr_BAG_L4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/RandomForestEntr_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L4/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/RandomForestEntr_BAG_L4/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/RandomForestEntr_BAG_L4/model.pkl\n",
      "\t0.38\t = Validation score   (precision)\n",
      "\t2.11s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L4 ... Training model for up to 14311.36s of the 14311.34s of remaining time.\n",
      "\tFitting CatBoost_BAG_L4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/CatBoost_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L4/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/CatBoost_BAG_L4/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/CatBoost_BAG_L4/model.pkl\n",
      "\t0.2857\t = Validation score   (precision)\n",
      "\t21.33s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: ExtraTreesGini_BAG_L4 ... Training model for up to 14287.04s of the 14287.03s of remaining time.\n",
      "\tFitting ExtraTreesGini_BAG_L4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/ExtraTreesGini_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L4/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/ExtraTreesGini_BAG_L4/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/ExtraTreesGini_BAG_L4/model.pkl\n",
      "\t0.3721\t = Validation score   (precision)\n",
      "\t0.8s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: ExtraTreesEntr_BAG_L4 ... Training model for up to 14285.8s of the 14285.79s of remaining time.\n",
      "\tFitting ExtraTreesEntr_BAG_L4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/ExtraTreesEntr_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L4/utils/model_template.pkl\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./autogluon_models/models/ExtraTreesEntr_BAG_L4/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/ExtraTreesEntr_BAG_L4/model.pkl\n",
      "\t0.3714\t = Validation score   (precision)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L4 ... Training model for up to 14284.75s of the 14284.73s of remaining time.\n",
      "\tFitting NeuralNetFastAI_BAG_L4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/NeuralNetFastAI_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L4/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/NeuralNetFastAI_BAG_L4/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "\t0.625\t = Validation score   (precision)\n",
      "\t31.66s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L4 ... Training model for up to 14250.03s of the 14250.02s of remaining time.\n",
      "\tFitting XGBoost_BAG_L4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/XGBoost_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L4/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/XGBoost_BAG_L4/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/XGBoost_BAG_L4/model.pkl\n",
      "\t0.6818\t = Validation score   (precision)\n",
      "\t28.89s\t = Training   runtime\n",
      "\t0.39s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L4 ... Training model for up to 14217.84s of the 14217.83s of remaining time.\n",
      "\tFitting NeuralNetTorch_BAG_L4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/NeuralNetTorch_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L4/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/NeuralNetTorch_BAG_L4/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "\t0.0\t = Validation score   (precision)\n",
      "\t24.19s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L4 ... Training model for up to 14190.47s of the 14190.46s of remaining time.\n",
      "\tFitting LightGBMLarge_BAG_L4 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/LightGBMLarge_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L4/utils/model_template.pkl\n",
      "\tFitting 20 child models (S1F1 - S1F20) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Saving ./autogluon_models/models/LightGBMLarge_BAG_L4/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "\t0.619\t = Validation score   (precision)\n",
      "\t40.94s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Repeating k-fold bagging: 2/20\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L4/model.pkl\n",
      "Fitting model: LightGBMXT_BAG_L4 ... Training model for up to 14146.08s of the 14146.07s of remaining time.\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L4/utils/model_template.pkl\n",
      "\tWarning: Exception caused LightGBMXT_BAG_L4 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L4/model.pkl\n",
      "Fitting model: LightGBM_BAG_L4 ... Training model for up to 14146.07s of the 14146.06s of remaining time.\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L4/utils/model_template.pkl\n",
      "\tWarning: Exception caused LightGBM_BAG_L4 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L4/model.pkl\n",
      "Fitting model: CatBoost_BAG_L4 ... Training model for up to 14146.06s of the 14146.05s of remaining time.\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L4/utils/model_template.pkl\n",
      "\tWarning: Exception caused CatBoost_BAG_L4 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L4 ... Training model for up to 14146.05s of the 14146.03s of remaining time.\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L4/utils/model_template.pkl\n",
      "\tWarning: Exception caused NeuralNetFastAI_BAG_L4 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L4/model.pkl\n",
      "Fitting model: XGBoost_BAG_L4 ... Training model for up to 14146.04s of the 14146.02s of remaining time.\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L4/utils/model_template.pkl\n",
      "\tWarning: Exception caused XGBoost_BAG_L4 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L4 ... Training model for up to 14146.03s of the 14146.01s of remaining time.\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L4/utils/model_template.pkl\n",
      "\tWarning: Exception caused NeuralNetTorch_BAG_L4 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L4 ... Training model for up to 14146.01s of the 14146.0s of remaining time.\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L4/utils/model_template.pkl\n",
      "\tWarning: Exception caused LightGBMLarge_BAG_L4 to fail during training... Skipping this model.\n",
      "\t\t'NoneType' object has no attribute '_user_params_aux'\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1422, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1367, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 688, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 428, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 539, in _preprocess_fit_resources\n",
      "    k_fold=k_fold\n",
      "  File \"/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 488, in _process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble\n",
      "    user_specified_model_level_resource = self.model_base._user_params_aux.get(resource_type, None)\n",
      "AttributeError: 'NoneType' object has no attribute '_user_params_aux'\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Repeating k-fold bagging: 3/20\n",
      "Repeating k-fold bagging: 4/20\n",
      "Repeating k-fold bagging: 5/20\n",
      "Repeating k-fold bagging: 6/20\n",
      "Repeating k-fold bagging: 7/20\n",
      "Repeating k-fold bagging: 8/20\n",
      "Repeating k-fold bagging: 9/20\n",
      "Repeating k-fold bagging: 10/20\n",
      "Repeating k-fold bagging: 11/20\n",
      "Repeating k-fold bagging: 12/20\n",
      "Repeating k-fold bagging: 13/20\n",
      "Repeating k-fold bagging: 14/20\n",
      "Repeating k-fold bagging: 15/20\n",
      "Repeating k-fold bagging: 16/20\n",
      "Repeating k-fold bagging: 17/20\n",
      "Repeating k-fold bagging: 18/20\n",
      "Repeating k-fold bagging: 19/20\n",
      "Repeating k-fold bagging: 20/20\n",
      "Completed 20/20 k-fold bagging repeats ...\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L4/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L4/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L4/utils/oof.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L4/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L5: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L5 ... Training model for up to 1435.93s of the 14145.97s of remaining time.\n",
      "\tFitting WeightedEnsemble_L5 with 'num_gpus': 0, 'num_cpus': 8\n",
      "Saving ./autogluon_models/models/WeightedEnsemble_L5/utils/model_template.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L5/utils/model_template.pkl\n",
      "Ensemble size: 3\n",
      "Ensemble weights: \n",
      "[0.         0.33333333 0.         0.66666667]\n",
      "Saving ./autogluon_models/models/WeightedEnsemble_L5/utils/oof.pkl\n",
      "Saving ./autogluon_models/models/WeightedEnsemble_L5/model.pkl\n",
      "\t0.4074\t = Validation score   (precision)\n",
      "\t1.31s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 855.37s ... Best model: \"WeightedEnsemble_L3\"\n",
      "Loading: ./autogluon_models/models/trainer.pkl\n",
      "Saving ./autogluon_models/models/trainer.pkl\n",
      "Saving ./autogluon_models/learner.pkl\n",
      "Saving ./autogluon_models/predictor.pkl\n",
      "Saving ./autogluon_models/__version__ with contents \"0.6.1\"\n",
      "Saving ./autogluon_models/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./autogluon_models/\")\n"
     ]
    }
   ],
   "source": [
    "# there is currently a bug where num_bag_sets >1 produces an error with various algos - waiting on fix\n",
    "# https://github.com/autogluon/autogluon/issues/2581\n",
    "\n",
    "predictor = TabularPredictor(label=label, path=save_path, verbosity=3, eval_metric='precision').fit(\n",
    "    train_data, presets='best_quality', time_limit=15000, num_bag_folds=20, num_stack_levels=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c5645b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./autogluon_models/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L5/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                      model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           CatBoost_BAG_L1   1.000000       0.028020  19.758722                0.028020          19.758722            1       True          7\n",
      "1           LightGBM_BAG_L2   0.758621       2.482328  24.534868                0.106126          19.512355            2       True         16\n",
      "2      LightGBMLarge_BAG_L2   0.687500       2.515875  49.400836                0.139673          44.378322            2       True         25\n",
      "3            XGBoost_BAG_L4   0.681818       4.935526  44.152152                0.387177          28.890719            4       True         47\n",
      "4         LightGBMXT_BAG_L2   0.655172       2.496622  22.081645                0.120420          17.059132            2       True         15\n",
      "5         LightGBMXT_BAG_L4   0.655172       4.682258  31.960919                0.133908          16.699486            4       True         39\n",
      "6            XGBoost_BAG_L2   0.647059       2.747867  35.724406                0.371665          30.701892            2       True         23\n",
      "7    NeuralNetFastAI_BAG_L4   0.625000       5.177690  46.918955                0.629340          31.657522            4       True         46\n",
      "8      LightGBMLarge_BAG_L4   0.619048       4.729132  56.203698                0.180783          40.942265            4       True         49\n",
      "9           LightGBM_BAG_L4   0.600000       4.703117  36.204757                0.154767          20.943324            4       True         40\n",
      "10   NeuralNetFastAI_BAG_L2   0.592105       3.065826  37.636348                0.689624          32.613834            2       True         22\n",
      "11      WeightedEnsemble_L3   0.576923       2.919105   9.734679                0.008428           1.293525            3       True         26\n",
      "12          LightGBM_BAG_L3   0.573770       3.551551  27.237962                0.094569          17.293293            3       True         28\n",
      "13          LightGBM_BAG_L1   0.557692       0.092479  17.649890                0.092479          17.649890            1       True          4\n",
      "14  RandomForestEntr_BAG_L2   0.555556       2.641812   7.025552                0.265610           2.003038            2       True         18\n",
      "15    ExtraTreesEntr_BAG_L2   0.545455       2.647543   5.824564                0.271341           0.802051            2       True         21\n",
      "16     LightGBMLarge_BAG_L3   0.545455       3.592900  45.637333                0.135918          35.692664            3       True         37\n",
      "17   NeuralNetFastAI_BAG_L3   0.526882       3.980477  41.588726                0.523495          31.644057            3       True         34\n",
      "18           XGBoost_BAG_L3   0.522222       3.827672  38.755360                0.370691          28.810691            3       True         35\n",
      "19        LightGBMXT_BAG_L3   0.500000       3.585666  26.770352                0.128684          16.825683            3       True         27\n",
      "20     LightGBMLarge_BAG_L1   0.491228       0.161006  36.715800                0.161006          36.715800            1       True         13\n",
      "21           XGBoost_BAG_L1   0.476923       0.389956  31.946066                0.389956          31.946066            1       True         11\n",
      "22        LightGBMXT_BAG_L1   0.465116       0.110265  15.611301                0.110265          15.611301            1       True          3\n",
      "23    ExtraTreesGini_BAG_L2   0.454545       2.651165   5.723978                0.274963           0.701465            2       True         20\n",
      "24      WeightedEnsemble_L5   0.407407       5.097492  19.379652                0.008218           1.312049            5       True         50\n",
      "25  RandomForestEntr_BAG_L4   0.380000       4.814547  17.367158                0.266197           2.105725            4       True         42\n",
      "26    ExtraTreesGini_BAG_L4   0.372093       4.824049  16.064256                0.275699           0.802823            4       True         44\n",
      "27    ExtraTreesEntr_BAG_L4   0.371429       4.823078  15.961878                0.274728           0.700445            4       True         45\n",
      "28   NeuralNetFastAI_BAG_L1   0.368098       0.483325  30.296918                0.483325          30.296918            1       True         10\n",
      "29  RandomForestGini_BAG_L4   0.357143       4.820721  16.665362                0.272372           1.403929            4       True         41\n",
      "30      WeightedEnsemble_L4   0.344262       4.281361  15.628512                0.008453           1.269353            4       True         38\n",
      "31  RandomForestGini_BAG_L2   0.343750       2.645067   6.438115                0.268865           1.415602            2       True         17\n",
      "32    ExtraTreesEntr_BAG_L3   0.342857       3.732960  10.644395                0.275978           0.699726            3       True         33\n",
      "33  RandomForestEntr_BAG_L3   0.342466       3.723411  12.050984                0.266429           2.106315            3       True         30\n",
      "34  RandomForestGini_BAG_L3   0.341176       3.730501  11.553118                0.273519           1.608449            3       True         29\n",
      "35          CatBoost_BAG_L3   0.333333       3.490634  32.584258                0.033652          22.639589            3       True         31\n",
      "36    ExtraTreesGini_BAG_L3   0.329114       3.732424  10.846943                0.275442           0.902274            3       True         32\n",
      "37          CatBoost_BAG_L4   0.285714       4.578872  36.590702                0.030522          21.329268            4       True         43\n",
      "38      WeightedEnsemble_L2   0.266667       2.120806   6.019157                0.010700           1.902386            2       True         14\n",
      "39  RandomForestGini_BAG_L1   0.224490       0.266957   1.301742                0.266957           1.301742            1       True          5\n",
      "40  RandomForestEntr_BAG_L1   0.208791       0.256319   2.100045                0.256319           2.100045            1       True          6\n",
      "41    ExtraTreesEntr_BAG_L1   0.202381       0.269624   0.697529                0.269624           0.697529            1       True          9\n",
      "42    ExtraTreesGini_BAG_L1   0.180851       0.266096   0.905742                0.266096           0.905742            1       True          8\n",
      "43    KNeighborsUnif_BAG_L1   0.152000       0.709356   0.008894                0.709356           0.008894            1       True          1\n",
      "44    KNeighborsDist_BAG_L1   0.122807       0.607851   0.008561                0.607851           0.008561            1       True          2\n",
      "45    NeuralNetTorch_BAG_L3   0.052632       3.776145  34.386559                0.319163          24.441890            3       True         36\n",
      "46    NeuralNetTorch_BAG_L1   0.000000       0.248370  23.858209                0.248370          23.858209            1       True         12\n",
      "47          CatBoost_BAG_L2   0.000000       2.412805  26.661134                0.036603          21.638621            2       True         19\n",
      "48    NeuralNetTorch_BAG_L2   0.000000       2.735929  29.006363                0.359727          23.983850            2       True         24\n",
      "49    NeuralNetTorch_BAG_L4   0.000000       4.873152  39.454084                0.324802          24.192651            4       True         48\n",
      "Number of models trained: 50\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_XT', 'WeightedEnsembleModel', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_TabularNeuralNetTorch', 'StackerEnsembleModel_KNN', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_XGBoost'}\n",
      "Bagging used: True  (with 20 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 5 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', []) : 27 | ['1. open', '2. high', '3. low', '4. close', '5. adjusted close', ...]\n",
      "Plot summary of models saved to file: ./autogluon_models/SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "source": [
    "results = predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9bd868b4-db7c-4f97-b674-8fe059ac7e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./autogluon_models/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMXT_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBM_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/CatBoost_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/XGBoost_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L5/model.pkl\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038095</td>\n",
       "      <td>0.028020</td>\n",
       "      <td>19.758722</td>\n",
       "      <td>0.038095</td>\n",
       "      <td>0.028020</td>\n",
       "      <td>19.758722</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.214824</td>\n",
       "      <td>0.092479</td>\n",
       "      <td>17.649890</td>\n",
       "      <td>0.214824</td>\n",
       "      <td>0.092479</td>\n",
       "      <td>17.649890</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.208791</td>\n",
       "      <td>0.224058</td>\n",
       "      <td>0.256319</td>\n",
       "      <td>2.100045</td>\n",
       "      <td>0.224058</td>\n",
       "      <td>0.256319</td>\n",
       "      <td>2.100045</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.224490</td>\n",
       "      <td>0.225853</td>\n",
       "      <td>0.266957</td>\n",
       "      <td>1.301742</td>\n",
       "      <td>0.225853</td>\n",
       "      <td>0.266957</td>\n",
       "      <td>1.301742</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTreesGini_BAG_L1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.180851</td>\n",
       "      <td>0.235512</td>\n",
       "      <td>0.266096</td>\n",
       "      <td>0.905742</td>\n",
       "      <td>0.235512</td>\n",
       "      <td>0.266096</td>\n",
       "      <td>0.905742</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202381</td>\n",
       "      <td>0.236475</td>\n",
       "      <td>0.269624</td>\n",
       "      <td>0.697529</td>\n",
       "      <td>0.236475</td>\n",
       "      <td>0.269624</td>\n",
       "      <td>0.697529</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.304072</td>\n",
       "      <td>0.110265</td>\n",
       "      <td>15.611301</td>\n",
       "      <td>0.304072</td>\n",
       "      <td>0.110265</td>\n",
       "      <td>15.611301</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.476923</td>\n",
       "      <td>0.350253</td>\n",
       "      <td>0.389956</td>\n",
       "      <td>31.946066</td>\n",
       "      <td>0.350253</td>\n",
       "      <td>0.389956</td>\n",
       "      <td>31.946066</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.517237</td>\n",
       "      <td>0.161006</td>\n",
       "      <td>36.715800</td>\n",
       "      <td>0.517237</td>\n",
       "      <td>0.161006</td>\n",
       "      <td>36.715800</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.122807</td>\n",
       "      <td>0.605458</td>\n",
       "      <td>0.607851</td>\n",
       "      <td>0.008561</td>\n",
       "      <td>0.605458</td>\n",
       "      <td>0.607851</td>\n",
       "      <td>0.008561</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1.907706</td>\n",
       "      <td>2.120806</td>\n",
       "      <td>6.019157</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>1.902386</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBMLarge_BAG_L4</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>4.463961</td>\n",
       "      <td>4.729132</td>\n",
       "      <td>56.203698</td>\n",
       "      <td>0.471781</td>\n",
       "      <td>0.180783</td>\n",
       "      <td>40.942265</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LightGBM_BAG_L4</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>4.237496</td>\n",
       "      <td>4.703117</td>\n",
       "      <td>36.204757</td>\n",
       "      <td>0.245316</td>\n",
       "      <td>0.154767</td>\n",
       "      <td>20.943324</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoost_BAG_L4</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>4.359276</td>\n",
       "      <td>4.935526</td>\n",
       "      <td>44.152152</td>\n",
       "      <td>0.367097</td>\n",
       "      <td>0.387177</td>\n",
       "      <td>28.890719</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestEntr_BAG_L4</td>\n",
       "      <td>0.918699</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>4.216813</td>\n",
       "      <td>4.814547</td>\n",
       "      <td>17.367158</td>\n",
       "      <td>0.224633</td>\n",
       "      <td>0.266197</td>\n",
       "      <td>2.105725</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>WeightedEnsemble_L5</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>4.456093</td>\n",
       "      <td>5.097492</td>\n",
       "      <td>19.379652</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>0.008218</td>\n",
       "      <td>1.312049</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ExtraTreesEntr_BAG_L4</td>\n",
       "      <td>0.909910</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>4.227871</td>\n",
       "      <td>4.823078</td>\n",
       "      <td>15.961878</td>\n",
       "      <td>0.235692</td>\n",
       "      <td>0.274728</td>\n",
       "      <td>0.700445</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomForestGini_BAG_L4</td>\n",
       "      <td>0.860294</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>4.218492</td>\n",
       "      <td>4.820721</td>\n",
       "      <td>16.665362</td>\n",
       "      <td>0.226312</td>\n",
       "      <td>0.272372</td>\n",
       "      <td>1.403929</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ExtraTreesGini_BAG_L4</td>\n",
       "      <td>0.844828</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>4.227990</td>\n",
       "      <td>4.824049</td>\n",
       "      <td>16.064256</td>\n",
       "      <td>0.235810</td>\n",
       "      <td>0.275699</td>\n",
       "      <td>0.802823</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ExtraTreesEntr_BAG_L3</td>\n",
       "      <td>0.773196</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>3.299826</td>\n",
       "      <td>3.732960</td>\n",
       "      <td>10.644395</td>\n",
       "      <td>0.235620</td>\n",
       "      <td>0.275978</td>\n",
       "      <td>0.699726</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ExtraTreesEntr_BAG_L2</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>2.375258</td>\n",
       "      <td>2.647543</td>\n",
       "      <td>5.824564</td>\n",
       "      <td>0.236929</td>\n",
       "      <td>0.271341</td>\n",
       "      <td>0.802051</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>WeightedEnsemble_L4</td>\n",
       "      <td>0.756477</td>\n",
       "      <td>0.344262</td>\n",
       "      <td>3.759978</td>\n",
       "      <td>4.281361</td>\n",
       "      <td>15.628512</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>0.008453</td>\n",
       "      <td>1.269353</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RandomForestEntr_BAG_L3</td>\n",
       "      <td>0.752381</td>\n",
       "      <td>0.342466</td>\n",
       "      <td>3.291384</td>\n",
       "      <td>3.723411</td>\n",
       "      <td>12.050984</td>\n",
       "      <td>0.227178</td>\n",
       "      <td>0.266429</td>\n",
       "      <td>2.106315</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ExtraTreesGini_BAG_L3</td>\n",
       "      <td>0.751269</td>\n",
       "      <td>0.329114</td>\n",
       "      <td>3.300402</td>\n",
       "      <td>3.732424</td>\n",
       "      <td>10.846943</td>\n",
       "      <td>0.236196</td>\n",
       "      <td>0.275442</td>\n",
       "      <td>0.902274</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ExtraTreesGini_BAG_L2</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>2.375422</td>\n",
       "      <td>2.651165</td>\n",
       "      <td>5.723978</td>\n",
       "      <td>0.237093</td>\n",
       "      <td>0.274963</td>\n",
       "      <td>0.701465</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RandomForestGini_BAG_L3</td>\n",
       "      <td>0.695853</td>\n",
       "      <td>0.341176</td>\n",
       "      <td>3.293186</td>\n",
       "      <td>3.730501</td>\n",
       "      <td>11.553118</td>\n",
       "      <td>0.228980</td>\n",
       "      <td>0.273519</td>\n",
       "      <td>1.608449</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.368098</td>\n",
       "      <td>1.462972</td>\n",
       "      <td>0.483325</td>\n",
       "      <td>30.296918</td>\n",
       "      <td>1.462972</td>\n",
       "      <td>0.483325</td>\n",
       "      <td>30.296918</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LightGBMLarge_BAG_L3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>3.414721</td>\n",
       "      <td>3.592900</td>\n",
       "      <td>45.637333</td>\n",
       "      <td>0.350515</td>\n",
       "      <td>0.135918</td>\n",
       "      <td>35.692664</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.610973</td>\n",
       "      <td>0.709356</td>\n",
       "      <td>0.008894</td>\n",
       "      <td>0.610973</td>\n",
       "      <td>0.709356</td>\n",
       "      <td>0.008894</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LightGBMXT_BAG_L3</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.344395</td>\n",
       "      <td>3.585666</td>\n",
       "      <td>26.770352</td>\n",
       "      <td>0.280189</td>\n",
       "      <td>0.128684</td>\n",
       "      <td>16.825683</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LightGBM_BAG_L3</td>\n",
       "      <td>0.530303</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>3.262111</td>\n",
       "      <td>3.551551</td>\n",
       "      <td>27.237962</td>\n",
       "      <td>0.197905</td>\n",
       "      <td>0.094569</td>\n",
       "      <td>17.293293</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>XGBoost_BAG_L3</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>3.432372</td>\n",
       "      <td>3.827672</td>\n",
       "      <td>38.755360</td>\n",
       "      <td>0.368166</td>\n",
       "      <td>0.370691</td>\n",
       "      <td>28.810691</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RandomForestGini_BAG_L2</td>\n",
       "      <td>0.482014</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>2.364306</td>\n",
       "      <td>2.645067</td>\n",
       "      <td>6.438115</td>\n",
       "      <td>0.225977</td>\n",
       "      <td>0.268865</td>\n",
       "      <td>1.415602</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>2.596576</td>\n",
       "      <td>2.919105</td>\n",
       "      <td>9.734679</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>0.008428</td>\n",
       "      <td>1.293525</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RandomForestEntr_BAG_L2</td>\n",
       "      <td>0.465753</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>2.364207</td>\n",
       "      <td>2.641812</td>\n",
       "      <td>7.025552</td>\n",
       "      <td>0.225878</td>\n",
       "      <td>0.265610</td>\n",
       "      <td>2.003038</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NeuralNetTorch_BAG_L3</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>3.672942</td>\n",
       "      <td>3.776145</td>\n",
       "      <td>34.386559</td>\n",
       "      <td>0.608737</td>\n",
       "      <td>0.319163</td>\n",
       "      <td>24.441890</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NeuralNetFastAI_BAG_L3</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.526882</td>\n",
       "      <td>4.599478</td>\n",
       "      <td>3.980477</td>\n",
       "      <td>41.588726</td>\n",
       "      <td>1.535272</td>\n",
       "      <td>0.523495</td>\n",
       "      <td>31.644057</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NeuralNetFastAI_BAG_L4</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>5.529272</td>\n",
       "      <td>5.177690</td>\n",
       "      <td>46.918955</td>\n",
       "      <td>1.537092</td>\n",
       "      <td>0.629340</td>\n",
       "      <td>31.657522</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466661</td>\n",
       "      <td>0.248370</td>\n",
       "      <td>23.858209</td>\n",
       "      <td>0.466661</td>\n",
       "      <td>0.248370</td>\n",
       "      <td>23.858209</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.179135</td>\n",
       "      <td>2.412805</td>\n",
       "      <td>26.661134</td>\n",
       "      <td>0.040806</td>\n",
       "      <td>0.036603</td>\n",
       "      <td>21.638621</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>2.382574</td>\n",
       "      <td>2.482328</td>\n",
       "      <td>24.534868</td>\n",
       "      <td>0.244245</td>\n",
       "      <td>0.106126</td>\n",
       "      <td>19.512355</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>2.406039</td>\n",
       "      <td>2.496622</td>\n",
       "      <td>22.081645</td>\n",
       "      <td>0.267709</td>\n",
       "      <td>0.120420</td>\n",
       "      <td>17.059132</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>XGBoost_BAG_L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>2.519325</td>\n",
       "      <td>2.747867</td>\n",
       "      <td>35.724406</td>\n",
       "      <td>0.380996</td>\n",
       "      <td>0.371665</td>\n",
       "      <td>30.701892</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>LightGBMLarge_BAG_L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>2.538507</td>\n",
       "      <td>2.515875</td>\n",
       "      <td>49.400836</td>\n",
       "      <td>0.400177</td>\n",
       "      <td>0.139673</td>\n",
       "      <td>44.378322</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NeuralNetTorch_BAG_L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.786907</td>\n",
       "      <td>2.735929</td>\n",
       "      <td>29.006363</td>\n",
       "      <td>0.648578</td>\n",
       "      <td>0.359727</td>\n",
       "      <td>23.983850</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>CatBoost_BAG_L3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.105183</td>\n",
       "      <td>3.490634</td>\n",
       "      <td>32.584258</td>\n",
       "      <td>0.040977</td>\n",
       "      <td>0.033652</td>\n",
       "      <td>22.639589</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>3.672685</td>\n",
       "      <td>3.065826</td>\n",
       "      <td>37.636348</td>\n",
       "      <td>1.534356</td>\n",
       "      <td>0.689624</td>\n",
       "      <td>32.613834</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>CatBoost_BAG_L4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>4.032390</td>\n",
       "      <td>4.578872</td>\n",
       "      <td>36.590702</td>\n",
       "      <td>0.040210</td>\n",
       "      <td>0.030522</td>\n",
       "      <td>21.329268</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>LightGBMXT_BAG_L4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>4.270675</td>\n",
       "      <td>4.682258</td>\n",
       "      <td>31.960919</td>\n",
       "      <td>0.278495</td>\n",
       "      <td>0.133908</td>\n",
       "      <td>16.699486</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NeuralNetTorch_BAG_L4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.787262</td>\n",
       "      <td>4.873152</td>\n",
       "      <td>39.454084</td>\n",
       "      <td>0.795082</td>\n",
       "      <td>0.324802</td>\n",
       "      <td>24.192651</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  score_test  score_val  pred_time_test  \\\n",
       "0           CatBoost_BAG_L1    1.000000   1.000000        0.038095   \n",
       "1           LightGBM_BAG_L1    1.000000   0.557692        0.214824   \n",
       "2   RandomForestEntr_BAG_L1    1.000000   0.208791        0.224058   \n",
       "3   RandomForestGini_BAG_L1    1.000000   0.224490        0.225853   \n",
       "4     ExtraTreesGini_BAG_L1    1.000000   0.180851        0.235512   \n",
       "5     ExtraTreesEntr_BAG_L1    1.000000   0.202381        0.236475   \n",
       "6         LightGBMXT_BAG_L1    1.000000   0.465116        0.304072   \n",
       "7            XGBoost_BAG_L1    1.000000   0.476923        0.350253   \n",
       "8      LightGBMLarge_BAG_L1    1.000000   0.491228        0.517237   \n",
       "9     KNeighborsDist_BAG_L1    1.000000   0.122807        0.605458   \n",
       "10      WeightedEnsemble_L2    1.000000   0.266667        1.907706   \n",
       "11     LightGBMLarge_BAG_L4    0.983607   0.619048        4.463961   \n",
       "12          LightGBM_BAG_L4    0.947368   0.600000        4.237496   \n",
       "13           XGBoost_BAG_L4    0.931818   0.681818        4.359276   \n",
       "14  RandomForestEntr_BAG_L4    0.918699   0.380000        4.216813   \n",
       "15      WeightedEnsemble_L5    0.913793   0.407407        4.456093   \n",
       "16    ExtraTreesEntr_BAG_L4    0.909910   0.371429        4.227871   \n",
       "17  RandomForestGini_BAG_L4    0.860294   0.357143        4.218492   \n",
       "18    ExtraTreesGini_BAG_L4    0.844828   0.372093        4.227990   \n",
       "19    ExtraTreesEntr_BAG_L3    0.773196   0.342857        3.299826   \n",
       "20    ExtraTreesEntr_BAG_L2    0.772727   0.545455        2.375258   \n",
       "21      WeightedEnsemble_L4    0.756477   0.344262        3.759978   \n",
       "22  RandomForestEntr_BAG_L3    0.752381   0.342466        3.291384   \n",
       "23    ExtraTreesGini_BAG_L3    0.751269   0.329114        3.300402   \n",
       "24    ExtraTreesGini_BAG_L2    0.702703   0.454545        2.375422   \n",
       "25  RandomForestGini_BAG_L3    0.695853   0.341176        3.293186   \n",
       "26   NeuralNetFastAI_BAG_L1    0.687500   0.368098        1.462972   \n",
       "27     LightGBMLarge_BAG_L3    0.666667   0.545455        3.414721   \n",
       "28    KNeighborsUnif_BAG_L1    0.620690   0.152000        0.610973   \n",
       "29        LightGBMXT_BAG_L3    0.580645   0.500000        3.344395   \n",
       "30          LightGBM_BAG_L3    0.530303   0.573770        3.262111   \n",
       "31           XGBoost_BAG_L3    0.523810   0.522222        3.432372   \n",
       "32  RandomForestGini_BAG_L2    0.482014   0.343750        2.364306   \n",
       "33      WeightedEnsemble_L3    0.466667   0.576923        2.596576   \n",
       "34  RandomForestEntr_BAG_L2    0.465753   0.555556        2.364207   \n",
       "35    NeuralNetTorch_BAG_L3    0.360000   0.052632        3.672942   \n",
       "36   NeuralNetFastAI_BAG_L3    0.310345   0.526882        4.599478   \n",
       "37   NeuralNetFastAI_BAG_L4    0.181818   0.625000        5.529272   \n",
       "38    NeuralNetTorch_BAG_L1    0.000000   0.000000        0.466661   \n",
       "39          CatBoost_BAG_L2    0.000000   0.000000        2.179135   \n",
       "40          LightGBM_BAG_L2    0.000000   0.758621        2.382574   \n",
       "41        LightGBMXT_BAG_L2    0.000000   0.655172        2.406039   \n",
       "42           XGBoost_BAG_L2    0.000000   0.647059        2.519325   \n",
       "43     LightGBMLarge_BAG_L2    0.000000   0.687500        2.538507   \n",
       "44    NeuralNetTorch_BAG_L2    0.000000   0.000000        2.786907   \n",
       "45          CatBoost_BAG_L3    0.000000   0.333333        3.105183   \n",
       "46   NeuralNetFastAI_BAG_L2    0.000000   0.592105        3.672685   \n",
       "47          CatBoost_BAG_L4    0.000000   0.285714        4.032390   \n",
       "48        LightGBMXT_BAG_L4    0.000000   0.655172        4.270675   \n",
       "49    NeuralNetTorch_BAG_L4    0.000000   0.000000        4.787262   \n",
       "\n",
       "    pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0        0.028020  19.758722                 0.038095                0.028020   \n",
       "1        0.092479  17.649890                 0.214824                0.092479   \n",
       "2        0.256319   2.100045                 0.224058                0.256319   \n",
       "3        0.266957   1.301742                 0.225853                0.266957   \n",
       "4        0.266096   0.905742                 0.235512                0.266096   \n",
       "5        0.269624   0.697529                 0.236475                0.269624   \n",
       "6        0.110265  15.611301                 0.304072                0.110265   \n",
       "7        0.389956  31.946066                 0.350253                0.389956   \n",
       "8        0.161006  36.715800                 0.517237                0.161006   \n",
       "9        0.607851   0.008561                 0.605458                0.607851   \n",
       "10       2.120806   6.019157                 0.004889                0.010700   \n",
       "11       4.729132  56.203698                 0.471781                0.180783   \n",
       "12       4.703117  36.204757                 0.245316                0.154767   \n",
       "13       4.935526  44.152152                 0.367097                0.387177   \n",
       "14       4.814547  17.367158                 0.224633                0.266197   \n",
       "15       5.097492  19.379652                 0.003588                0.008218   \n",
       "16       4.823078  15.961878                 0.235692                0.274728   \n",
       "17       4.820721  16.665362                 0.226312                0.272372   \n",
       "18       4.824049  16.064256                 0.235810                0.275699   \n",
       "19       3.732960  10.644395                 0.235620                0.275978   \n",
       "20       2.647543   5.824564                 0.236929                0.271341   \n",
       "21       4.281361  15.628512                 0.003994                0.008453   \n",
       "22       3.723411  12.050984                 0.227178                0.266429   \n",
       "23       3.732424  10.846943                 0.236196                0.275442   \n",
       "24       2.651165   5.723978                 0.237093                0.274963   \n",
       "25       3.730501  11.553118                 0.228980                0.273519   \n",
       "26       0.483325  30.296918                 1.462972                0.483325   \n",
       "27       3.592900  45.637333                 0.350515                0.135918   \n",
       "28       0.709356   0.008894                 0.610973                0.709356   \n",
       "29       3.585666  26.770352                 0.280189                0.128684   \n",
       "30       3.551551  27.237962                 0.197905                0.094569   \n",
       "31       3.827672  38.755360                 0.368166                0.370691   \n",
       "32       2.645067   6.438115                 0.225977                0.268865   \n",
       "33       2.919105   9.734679                 0.006393                0.008428   \n",
       "34       2.641812   7.025552                 0.225878                0.265610   \n",
       "35       3.776145  34.386559                 0.608737                0.319163   \n",
       "36       3.980477  41.588726                 1.535272                0.523495   \n",
       "37       5.177690  46.918955                 1.537092                0.629340   \n",
       "38       0.248370  23.858209                 0.466661                0.248370   \n",
       "39       2.412805  26.661134                 0.040806                0.036603   \n",
       "40       2.482328  24.534868                 0.244245                0.106126   \n",
       "41       2.496622  22.081645                 0.267709                0.120420   \n",
       "42       2.747867  35.724406                 0.380996                0.371665   \n",
       "43       2.515875  49.400836                 0.400177                0.139673   \n",
       "44       2.735929  29.006363                 0.648578                0.359727   \n",
       "45       3.490634  32.584258                 0.040977                0.033652   \n",
       "46       3.065826  37.636348                 1.534356                0.689624   \n",
       "47       4.578872  36.590702                 0.040210                0.030522   \n",
       "48       4.682258  31.960919                 0.278495                0.133908   \n",
       "49       4.873152  39.454084                 0.795082                0.324802   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           19.758722            1       True          7  \n",
       "1           17.649890            1       True          4  \n",
       "2            2.100045            1       True          6  \n",
       "3            1.301742            1       True          5  \n",
       "4            0.905742            1       True          8  \n",
       "5            0.697529            1       True          9  \n",
       "6           15.611301            1       True          3  \n",
       "7           31.946066            1       True         11  \n",
       "8           36.715800            1       True         13  \n",
       "9            0.008561            1       True          2  \n",
       "10           1.902386            2       True         14  \n",
       "11          40.942265            4       True         49  \n",
       "12          20.943324            4       True         40  \n",
       "13          28.890719            4       True         47  \n",
       "14           2.105725            4       True         42  \n",
       "15           1.312049            5       True         50  \n",
       "16           0.700445            4       True         45  \n",
       "17           1.403929            4       True         41  \n",
       "18           0.802823            4       True         44  \n",
       "19           0.699726            3       True         33  \n",
       "20           0.802051            2       True         21  \n",
       "21           1.269353            4       True         38  \n",
       "22           2.106315            3       True         30  \n",
       "23           0.902274            3       True         32  \n",
       "24           0.701465            2       True         20  \n",
       "25           1.608449            3       True         29  \n",
       "26          30.296918            1       True         10  \n",
       "27          35.692664            3       True         37  \n",
       "28           0.008894            1       True          1  \n",
       "29          16.825683            3       True         27  \n",
       "30          17.293293            3       True         28  \n",
       "31          28.810691            3       True         35  \n",
       "32           1.415602            2       True         17  \n",
       "33           1.293525            3       True         26  \n",
       "34           2.003038            2       True         18  \n",
       "35          24.441890            3       True         36  \n",
       "36          31.644057            3       True         34  \n",
       "37          31.657522            4       True         46  \n",
       "38          23.858209            1       True         12  \n",
       "39          21.638621            2       True         19  \n",
       "40          19.512355            2       True         16  \n",
       "41          17.059132            2       True         15  \n",
       "42          30.701892            2       True         23  \n",
       "43          44.378322            2       True         25  \n",
       "44          23.983850            2       True         24  \n",
       "45          22.639589            3       True         31  \n",
       "46          32.613834            2       True         22  \n",
       "47          21.329268            4       True         43  \n",
       "48          16.699486            4       True         39  \n",
       "49          24.192651            4       True         48  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(train_data, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "30f1411d-b62e-4f84-b7d2-566c670df9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['8. split coefficient']\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L3/model.pkl\n",
      "Computing feature importance via permutation shuffling for 27 features using 4487 rows with 5 shuffle sets...\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L3/model.pkl\n",
      "\t367.04s\t= Expected runtime (73.41s per shuffle set)\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/ExtraTreesGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L1/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestEntr_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/RandomForestGini_BAG_L2/model.pkl\n",
      "Loading: ./autogluon_models/models/WeightedEnsemble_L3/model.pkl\n",
      "\t161.8s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7. dividend amount</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_pcent_change</th>\n",
       "      <td>-0.003655</td>\n",
       "      <td>0.039270</td>\n",
       "      <td>0.577358</td>\n",
       "      <td>5</td>\n",
       "      <td>0.077203</td>\n",
       "      <td>-0.084514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ppo</th>\n",
       "      <td>-0.021273</td>\n",
       "      <td>0.043738</td>\n",
       "      <td>0.831031</td>\n",
       "      <td>5</td>\n",
       "      <td>0.068784</td>\n",
       "      <td>-0.111329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bb_width</th>\n",
       "      <td>-0.071032</td>\n",
       "      <td>0.078455</td>\n",
       "      <td>0.943542</td>\n",
       "      <td>5</td>\n",
       "      <td>0.090507</td>\n",
       "      <td>-0.232571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMA_20_pcent_diff_to_close</th>\n",
       "      <td>-0.094851</td>\n",
       "      <td>0.030117</td>\n",
       "      <td>0.998928</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.032839</td>\n",
       "      <td>-0.156863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMA_5_pcent_diff_to_close</th>\n",
       "      <td>-0.103003</td>\n",
       "      <td>0.028470</td>\n",
       "      <td>0.999366</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.044384</td>\n",
       "      <td>-0.161623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stochrsi_fast_k</th>\n",
       "      <td>-0.106143</td>\n",
       "      <td>0.015855</td>\n",
       "      <td>0.999942</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.073498</td>\n",
       "      <td>-0.138789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stochrsi_fast_d</th>\n",
       "      <td>-0.119357</td>\n",
       "      <td>0.058997</td>\n",
       "      <td>0.994686</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>-0.240833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMA_20_pcent_diff_to_open</th>\n",
       "      <td>-0.120010</td>\n",
       "      <td>0.039272</td>\n",
       "      <td>0.998800</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.039148</td>\n",
       "      <td>-0.200871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMA_10_pcent_diff_to_open</th>\n",
       "      <td>-0.125198</td>\n",
       "      <td>0.022575</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.078717</td>\n",
       "      <td>-0.171679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMA_40_pcent_diff_to_open</th>\n",
       "      <td>-0.133004</td>\n",
       "      <td>0.044597</td>\n",
       "      <td>0.998686</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.041178</td>\n",
       "      <td>-0.224830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMA_5_pcent_diff_to_open</th>\n",
       "      <td>-0.151980</td>\n",
       "      <td>0.032895</td>\n",
       "      <td>0.999752</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.084249</td>\n",
       "      <td>-0.219711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMA_10_pcent_diff_to_close</th>\n",
       "      <td>-0.152803</td>\n",
       "      <td>0.027813</td>\n",
       "      <td>0.999874</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.095535</td>\n",
       "      <td>-0.210071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4. close</th>\n",
       "      <td>-0.158597</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.998068</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.037065</td>\n",
       "      <td>-0.280129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMA_40_pcent_diff_to_close</th>\n",
       "      <td>-0.161622</td>\n",
       "      <td>0.035110</td>\n",
       "      <td>0.999749</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.089329</td>\n",
       "      <td>-0.233914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bb_lower</th>\n",
       "      <td>-0.166882</td>\n",
       "      <td>0.050118</td>\n",
       "      <td>0.999131</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.063687</td>\n",
       "      <td>-0.270076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1. open</th>\n",
       "      <td>-0.170281</td>\n",
       "      <td>0.051054</td>\n",
       "      <td>0.999136</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.065160</td>\n",
       "      <td>-0.275401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macd_signal</th>\n",
       "      <td>-0.171061</td>\n",
       "      <td>0.025323</td>\n",
       "      <td>0.999944</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.118921</td>\n",
       "      <td>-0.223200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bb_upper</th>\n",
       "      <td>-0.176250</td>\n",
       "      <td>0.029448</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.115616</td>\n",
       "      <td>-0.236884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMA_80_pcent_diff_to_open</th>\n",
       "      <td>-0.184043</td>\n",
       "      <td>0.026644</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.129182</td>\n",
       "      <td>-0.238904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. low</th>\n",
       "      <td>-0.184812</td>\n",
       "      <td>0.061701</td>\n",
       "      <td>0.998707</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.057769</td>\n",
       "      <td>-0.311856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6. volume</th>\n",
       "      <td>-0.190259</td>\n",
       "      <td>0.008961</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.171808</td>\n",
       "      <td>-0.208710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcent_diff_to_bb_upper</th>\n",
       "      <td>-0.197353</td>\n",
       "      <td>0.038306</td>\n",
       "      <td>0.999838</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.118481</td>\n",
       "      <td>-0.276225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pcent_diff_to_bb_lower</th>\n",
       "      <td>-0.199883</td>\n",
       "      <td>0.036637</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.124446</td>\n",
       "      <td>-0.275320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WMA_80_pcent_diff_to_close</th>\n",
       "      <td>-0.200297</td>\n",
       "      <td>0.021005</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.157048</td>\n",
       "      <td>-0.243547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. high</th>\n",
       "      <td>-0.202716</td>\n",
       "      <td>0.046872</td>\n",
       "      <td>0.999680</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.106206</td>\n",
       "      <td>-0.299225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5. adjusted close</th>\n",
       "      <td>-0.237494</td>\n",
       "      <td>0.055932</td>\n",
       "      <td>0.999657</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.122330</td>\n",
       "      <td>-0.352658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            importance    stddev   p_value  n  p99_high  \\\n",
       "7. dividend amount            0.000000  0.000000  0.500000  5  0.000000   \n",
       "day_pcent_change             -0.003655  0.039270  0.577358  5  0.077203   \n",
       "ppo                          -0.021273  0.043738  0.831031  5  0.068784   \n",
       "bb_width                     -0.071032  0.078455  0.943542  5  0.090507   \n",
       "WMA_20_pcent_diff_to_close   -0.094851  0.030117  0.998928  5 -0.032839   \n",
       "WMA_5_pcent_diff_to_close    -0.103003  0.028470  0.999366  5 -0.044384   \n",
       "stochrsi_fast_k              -0.106143  0.015855  0.999942  5 -0.073498   \n",
       "stochrsi_fast_d              -0.119357  0.058997  0.994686  5  0.002118   \n",
       "WMA_20_pcent_diff_to_open    -0.120010  0.039272  0.998800  5 -0.039148   \n",
       "WMA_10_pcent_diff_to_open    -0.125198  0.022575  0.999878  5 -0.078717   \n",
       "WMA_40_pcent_diff_to_open    -0.133004  0.044597  0.998686  5 -0.041178   \n",
       "WMA_5_pcent_diff_to_open     -0.151980  0.032895  0.999752  5 -0.084249   \n",
       "WMA_10_pcent_diff_to_close   -0.152803  0.027813  0.999874  5 -0.095535   \n",
       "4. close                     -0.158597  0.059024  0.998068  5 -0.037065   \n",
       "WMA_40_pcent_diff_to_close   -0.161622  0.035110  0.999749  5 -0.089329   \n",
       "bb_lower                     -0.166882  0.050118  0.999131  5 -0.063687   \n",
       "1. open                      -0.170281  0.051054  0.999136  5 -0.065160   \n",
       "macd_signal                  -0.171061  0.025323  0.999944  5 -0.118921   \n",
       "bb_upper                     -0.176250  0.029448  0.999910  5 -0.115616   \n",
       "WMA_80_pcent_diff_to_open    -0.184043  0.026644  0.999949  5 -0.129182   \n",
       "3. low                       -0.184812  0.061701  0.998707  5 -0.057769   \n",
       "6. volume                    -0.190259  0.008961  0.999999  5 -0.171808   \n",
       "pcent_diff_to_bb_upper       -0.197353  0.038306  0.999838  5 -0.118481   \n",
       "pcent_diff_to_bb_lower       -0.199883  0.036637  0.999870  5 -0.124446   \n",
       "WMA_80_pcent_diff_to_close   -0.200297  0.021005  0.999986  5 -0.157048   \n",
       "2. high                      -0.202716  0.046872  0.999680  5 -0.106206   \n",
       "5. adjusted close            -0.237494  0.055932  0.999657  5 -0.122330   \n",
       "\n",
       "                             p99_low  \n",
       "7. dividend amount          0.000000  \n",
       "day_pcent_change           -0.084514  \n",
       "ppo                        -0.111329  \n",
       "bb_width                   -0.232571  \n",
       "WMA_20_pcent_diff_to_close -0.156863  \n",
       "WMA_5_pcent_diff_to_close  -0.161623  \n",
       "stochrsi_fast_k            -0.138789  \n",
       "stochrsi_fast_d            -0.240833  \n",
       "WMA_20_pcent_diff_to_open  -0.200871  \n",
       "WMA_10_pcent_diff_to_open  -0.171679  \n",
       "WMA_40_pcent_diff_to_open  -0.224830  \n",
       "WMA_5_pcent_diff_to_open   -0.219711  \n",
       "WMA_10_pcent_diff_to_close -0.210071  \n",
       "4. close                   -0.280129  \n",
       "WMA_40_pcent_diff_to_close -0.233914  \n",
       "bb_lower                   -0.270076  \n",
       "1. open                    -0.275401  \n",
       "macd_signal                -0.223200  \n",
       "bb_upper                   -0.236884  \n",
       "WMA_80_pcent_diff_to_open  -0.238904  \n",
       "3. low                     -0.311856  \n",
       "6. volume                  -0.208710  \n",
       "pcent_diff_to_bb_upper     -0.276225  \n",
       "pcent_diff_to_bb_lower     -0.275320  \n",
       "WMA_80_pcent_diff_to_close -0.243547  \n",
       "2. high                    -0.299225  \n",
       "5. adjusted close          -0.352658  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(train_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Sep 26 2022, 11:37:49) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
